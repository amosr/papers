%!TEX root = ../Main.tex
\section{Icicle Source}
\label{s:Source}

In this section we describe the grammar and evaluation semantics of the Icicle language.
\ben{The running example here should be driven by solving the stated problem introduced in the introduction.}

Icicle queries execute over a single table, which must at least contain an entity identifier and a date. \ben{Why does the fact that it's a date matter? Could we also use any other data type that has an ordering?}

Each query implicitly groups the data by entity and sorts it by date, before iterating through the data and computing some aggregate.
We define the stocks table as follows, leaving out the company code (entity identifier) and date.

\ben{If this table really has a data field as well then why do we leave it implicit? That's a bit confusing}.
\begin{tabbing}
MM \= MM \= MMMMMMMMMMM \= \kill
$@table@~\mi{stocks}$    \\
$\{$ \> $\mi{open}$ \> $:~\NN$ \\
$~,$ \> $\mi{close}$ \> $:~\NN$ \\
$\}$
\end{tabbing}

This defines the columns as natural numbers, and allows them to be referred to by name.
In the definitions and queries below, any reference to these names means the column itself, with the entire data for a given entity.
This is annotated with the mode @Element@, meaning that it exists for every element of the input.
\ben{What is annotated with the mode? The column itself or the type of the column?}

We now define some useful functions and other definitions that can be used in the queries themselves.

First we define a function to compute the sum of some input data.
While traditionally sum would take just an input stream of numbers, we separate this into two distinct parameters.
The first parameter is the clock for the input stream, which defines the parts of the input stream to sample.
This can be thought of as a stream of boolean flags, where true denotes that the input stream should be sampled at this time.
The second parameter is the actual value to sample at the clock.
In Icicle this has type $\Elm{\NN}$, meaning it is available as a number at any part of the stream.
\ben{Maybe hold off the description of @Element@ and @Aggregate@ until later so we can introduce them both at the same time. At this point in the text it's not clear why we need the modal types.}

By separating the clock from the element values, we guarantee that any references to elements denote the same point in the stream, and can always be used together.
For example, computing the difference between the two fields above ($\mi{open} - \mi{close}$) refers to the open and close fields at the same point.
The clock is used when performing a fold, and determine at which points to sample the elements and update the accumulator.
This is in constrast to traditional streaming dataflow languages, where the element data and the clock are intertwined.
This requires clock analysis\CITE to tell whether two element streams can be used together with a bounded buffer. \ben{The need for clock analysis needs to be backup up with an example. Readers that aren't familiar with the semantics of data flow languages won't understand the phrase ``the element and the clock are intertwined''}

We denote clocks in brackets as they are a different universe to normal expressions.
\ben{Explain the syntax. What are $v$ $s$ and @then@ about?} \ben{Mention that $s$ is a stream. What is its type? Where are $c$ and $s$ bound?}

\begin{tabbing}
MM \= MM \= MMMMMMMMMMM \= \kill
@function@ 
$\mi{sum}[c]~(v~:~\NN)$    \\
\> $=$  \> $@fold@[c]~s~=~0~@then@~s~+~v$. \\
\end{tabbing}

The result of $\mi{sum}$ above has type $\Agg{\NN}$. 

\ben{Does the concrete syntax support this annotation, eg:}
\begin{tabbing}
MM \= MM \= MMMMMMMMMMM \= \kill
@function@ 
$\mi{sum}[c]~(v~:~\NN) : \Agg{\NN}$    \\
\> $=$  \> $@fold@[c]~s~=~0~@then@~s~+~v$. \\
\end{tabbing}



Aggregate types denote that their value is only available after the entire input stream has been seen. 
By restricting the bodies of folds to be element types, and their output to be aggregate types, it means no reference to the result of folds can be made in the body of a fold. \ben{Give a counter-example of what can go wrong it we don't have this restriction}

We can define a query that computes the sum of each company's open prices.
Query definitions are similar to function definitions, except they only take one argument: the clock describing all available input.
They also must return aggregates, as an element query could be unbounded in size.
\ben{The above describes the syntax of the query, but what is the essential reason for defining functions and queries with different language constructs? Could we just say that a query is a function with some particular restrictions?}
\ben{Can we also provide the aggregate result type on the query definition itself?}

\begin{tabbing}
MM \= MM \= MMMMMMMMMMM \= \kill
@query@ 
$\mi{opensum}[c]$    \\
\> $=$  \> $\mi{sum}[c]~\mi{open}$. \\
\end{tabbing}

We can run $\mi{opensum}$ over some example data.
This example data has the company code and date for each entry, as well as the stock's open and close prices.
Note that the sum only becomes available at the end of each entity, and only applies to a particular entity's elements.

\begin{code}
CODE, OPEN, CLOSE, DATE,        OPENSUM
ABC,    10,    12, 2015-01-01,       10
IAG,    11,    12, 2015-01-01
IAG,    12,    10, 2015-01-02,       23
\end{code}
\ben{The fact that there is also an implicit group-by operation being performed is not made explicit in the query code. The operation being performed above is a segmented fold over the data, rather than a complete fold. Suppose there was also a @VOLUME@ field for the number of shares traded per day for each stock, and we wanted to compute the total volume of all shares traded on every day we have on record? How would we express that in the query language?}

Next, we can define functions $\mi{count}$ and $\mi{mean}$ in terms of $\mi{sum}$.
Count passes the argument $1$ to sum, and this is interpreted as an element containing all ones. 

\ben{It's interpreted as an element containing all ones, but not a \emph{stream} containing all ones. The fact that the input data is implicitly partitioned by the key need to be stated up front, at it seems like a key part of the language design. Suppose we go back to the @VOLUME@ example and want to broadcast the value @1@ to \emph{all} the rows in the entire data set. How would we do that?}

The input clocks are passed along as-is.
\begin{tabbing}
MM \= MM \= MMMMMMMMMMM \= \kill
@function@ 
$\mi{count}[c]$                                     \\
 \> $=$  \> $\mi{sum}[c]~1$.                           \\
                                                    \\
@function@ 
$\mi{mean}[c]~(v~:~\NN)$                                       \\
 \> $=$  \> $\mi{sum}[c]~v~/~\mi{count}[c]$.              \\
\end{tabbing}

Clocks can be reduced to filter out certain elements using @where@.
In this query, we use @where@ to count the number of days where the close price is higher than the open price.
\begin{tabbing}
MM \= MM \= MMMMMMMMMMM \= \kill
@query@ 
$\mi{gap}[c]$                                        \\
 \> $=$  \> $\mi{count}[c~@where@~\mi{close}~>~\mi{open}]$.       \\
\end{tabbing}

In the example below we have shown the result of the element expression $\mi{close}~>~\mi{open}$ for clarity only; this is not included in the output of the $\mi{gap}$ query.

\ben{That's not what \emph{gap} means. A stock price has ``gapped up'' when it closes at some price $c$ on day 0, opens at some price $o$ on day 1, and $o > c$. The point is that there is a price discontinuity between trading days, and there was no opportunity to buy and sell at any price between $c$ and $o$.}

\begin{code}
CODE, OPEN, CLOSE, CLOSE > OPEN, GAP
ABC,    10,    12,            T,   1
IAG,    11,    12,            T
IAG,    12,    10,            F,   1
\end{code}

\TODO{Mention resumables and bubblegum?}

We formally define the grammar of the language in figure~\ref{fig:source:grammar}.
Note that general application is not allowed: arguments can only be applied to primitives and named functions.
Similarly, functions and primitives must be fully applied.
This, combined with the lack of lambda construction, means that higher order functions are outlawed.
While a first-order language (one lacking higher order functions) offers somewhat less abstraction, it simplifies the typing rules and makes it easier to support our performance guarantees.

While the examples shown allow user defined functions, there is no recursion allowed.
This means that all function definitions can be inlined into the user query with guaranteed termination.
When converting to the intermediate language, we assume that this inlining has occurred.


\subsection{Evaluation}

\input{figures/Source-Grammar.tex}
\ben{Should the set of types also include @Date@? In the first example the table also contained dates}.

In figure~\ref{fig:source:eval} we describe the bigstep evaluation semantics of the language.

The judgment $\Bigstep{f}{x}{v}$ takes the list of defined functions, $f$, and the expression to evaluate, $x$, and returns the result value $v$.

\ben{The previous section states that ``all function definitions can be inlined into the user query''. If this is true then why not always inline them? Why does the evaluation semantics need an environment containing a separate set of functions?}

The evaluation works on a single entity's data at a time, and the column values, such as $\mi{open}$ and $\mi{close}$ in the examples above, must be substituted into the functions and expression beforehand. \ben{What is a ``column value''?}
The clock is initially set to true for all values in the input stream.

Substitution is denoted by $x[n~:=~v]$, where $x$ is the expression to substitute into, $n$ is the variable name to replace, and $v$ is the replacement payload.

For example, for the $\mi{opensum}$ query we would have two evaluations:
\begin{tabbing}
MMMM \= M \= \kill
$\mi{clock}_1$ \> $=$ \> $@Elements@~[@T@]$ \\
$\mi{open}_1$  \> $=$ \> $@Elements@~[10]$ \\
$\Bigstep{\mi{sum}}{\mi{opensum}[c~:=~\mi{clock}_1,~\mi{open}~:=~\mi{open}_1]}{@Scalar@~10} $ \\
\\
$\mi{clock}_2$ \> $=$ \> $@Elements@~[@T@,~@T@]$ \\
$\mi{open}_2$  \> $=$ \> $@Elements@~[11,~12]$ \\
$\Bigstep{\mi{sum}}{\mi{opensum}[c~:=~\mi{clock}_2,~\mi{open}~:=~\mi{open}_2]}{@Scalar@~23} $
\end{tabbing}

\ben{The syntax @Elements@ looks similar to @Element@, which was a type. Can we usual list or set syntax to present these?} \ben{I think it would look cleaner to have an overall construct to express the combination of input data expression to execute. The examples feel like they're setting up the big-step judgement in a particular way to get around the lack of an overall program/module construct.}

\ben{I don't follow the following paragraph.} In the evaluation rules we make the distinction between @Scalar@ and @Elements@ explicit, but in the source grammar we omit the @Scalar@ qualifier, and do not allow @Elements@ as values, except when substituted in for evaluation.
For example, the definition of $\mi{sum}$ would actually have $@Scalar@~0$ as its initialiser.
Scalars can also be thought of as a repeated stream of the same value, of the same length as the input stream.

The first rule (EvValue) simply returns its value unchanged.

The next two rules, (EvPrimScalar) and (EvPrimElements) are for primitive binary operators (as the only primitives are binary).
When both arguments are scalars, we simply apply the operator to both arguments.
If both arguments are element streams, we pair the streams together and apply the operator to each pair.
If only one of the arguments is an element stream, the other argument must be a scalar, and the function $\mi{elements}$ is used to extend the scalar to a repeated stream before applying the operator.

Next, (EvFunApp) performs named function application.
The function environment $f$ is searched for a function named $n$, and we find the names of the arguments $\mi{args}$ and the function definition $\mi{exp}$.
The function definitions are non-recursive, and the function definition can only refer to functions defined before it.
We use $f'$ as the new list of available function bindings.
All arguments are evaluated to values, then each argument value is substituted into the function body, using the names of the arguments.

For (EvLet) the let-definition is evaluated, then substituted into the let-body.

For (EvWhere), used in clocks, both arguments are streams of booleans.
We evaluate both arguments and perform a pairwise and of the two, where the result clock is only true for an element if it is true for both inputs on that element.

The final evaluation rule, (EvFold), is the most important and most complex.
It evaluates a reduction over the stream.
First the clock and the initial value are evaluated, then a secondary judgment form is used to evaluate the fold.

The fold judgment form takes a list of functions, the index of the current fold value, the stream of boolean clock values, the non-empty list of fold results so far, and the expression to evaluate.
For (EvFoldNil) the clock is finished, so the last value in the fold result must be the final fold value.

For the other cases, we inspect the first element of the clock stream.
If the clock is true, we perform the fold with the fold results so far, and compute the rest of the clock stream.
If the clock is false, we reuse the last value in the fold results, as any elements for this index will not be used.

For (EvFoldClockTrue) we evaluate $k$ with the fold results so far substituted into the accumulator as an element stream.
The result will be an element stream of at least length $i$, as the result of the fold so far.
We then get the result at index $i$ and add it as the latest accumulator value, and continue computing the rest of the stream with this new accumulator.

For (EvFoldClockFalse) we can re-use the previous accumulator value, which is the last value of the fold results.
We add the last fold result to the accumulator, and compute the rest of the stream.


\input{figures/Source-Eval.tex}
