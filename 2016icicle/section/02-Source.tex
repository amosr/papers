%!TEX root = ../Main.tex
\section{Icicle Source}
\label{s:Source}

In this section we describe the grammar and evaluation semantics of the Icicle language.

Icicle queries execute over a single table, which must at least contain an entity identifier and a date.
Each query implicitly groups the data by entity and sorts it by date, before iterating through the data and computing some aggregate.
We define the stocks table as follows, leaving out the company code (entity identifier) and date.

\begin{tabbing}
MM \= MM \= MMMMMMMMMMM \= \kill
$@table@~\mi{stocks}$    \\
$\{$ \> $\mi{open}$ \> $:~\NN$ \\
$~,$ \> $\mi{close}$ \> $:~\NN$ \\
$\}$
\end{tabbing}

This defines the columns as natural numbers, and allows them to be referred to by name.
In the definitions and queries below, any reference to these names means the column itself, with the entire data for a given entity.
This is annotated with the mode @Element@, meaning that it exists for every element of the input.

We now define some useful functions and other definitions that can be used in the queries themselves.

First we define a function to compute the sum of some input data.
While traditionally sum would take just an input stream of numbers, we separate this into two distinct parameters.
The first parameter is the clock for the input stream, which defines the parts of the input stream to sample.
This can be thought of as a stream of boolean flags, where true denotes that the input stream should be sampled at this time.
The second parameter is the actual value to sample at the clock.
In Icicle this has type $\Elm{\NN}$, meaning it is available as a number at any part of the stream.

By separating the clock from the element values, we guarantee that any references to elements denote the same point in the stream, and can always be used together.
For example, computing the difference between the two fields above ($\mi{open} - \mi{close}$) refers to the open and close fields at the same point.
The clock is used when performing a fold, and determine at which points to sample the elements and update the accumulator.
This is in constrast to traditional streaming dataflow languages, where the element data and the clock are intertwined.
This requires clock analysis\CITE to tell whether two element streams can be used together with a bounded buffer.

We denote clocks in brackets as they are a different universe to normal expressions.
\begin{tabbing}
MM \= MM \= MMMMMMMMMMM \= \kill
@function@ 
$\mi{sum}[c]~v$    \\
\> $=$  \> $@fold@[c]~s~=~0~@then@~s~+~v$ \\
\> @in@ \> $s$. \\
\end{tabbing}

The result of $\mi{sum}$ above has type $\Agg{\NN}$.
Aggregate types denote that their value is only available after the entire input stream has been seen.
By restricting the bodies of folds to be element types, and their output to be aggregate types, it means no reference to the result of folds can be made in the body of a fold.

We can define a query that computes the sum of each company's open prices.
Query definitions are similar to function definitions, except they only take one argument: the clock describing all available input.
They also must return aggregates, as an element query could be unbounded in size.
\begin{tabbing}
MM \= MM \= MMMMMMMMMMM \= \kill
@query@ 
$\mi{opensum}[c]$    \\
\> $=$  \> $\mi{sum}[c]~\mi{open}$. \\
\end{tabbing}

We can run $\mi{opensum}$ over some example data.
This example data has the company code and date for each entry, as well as the stock's open and close prices.
Note that the sum only becomes available at the end of each entity, and only applies to a particular entity's elements.

\begin{code}
CODE, OPEN, CLOSE, DATE,        OPENSUM
ABC,    10,    12, 2015-01-01,       10
IAG,    11,    12, 2015-01-01
IAG,    12,    10, 2015-01-02,       23
\end{code}


Next, we can define functions $\mi{count}$ and $\mi{mean}$ in terms of $\mi{sum}$.
Count passes the argument $1$ to sum, and this is interpreted as an element containing all ones.
The input clocks are passed along as-is.
\begin{tabbing}
MM \= MM \= MMMMMMMMMMM \= \kill
@function@ 
$\mi{count}[c]$                                     \\
 \> $=$  \> $\mi{sum}[c]~1$.                           \\
                                                    \\
@function@ 
$\mi{mean}[c]~v$                                       \\
 \> $=$  \> $\mi{sum}[c]~v~/~\mi{count}[c]$.              \\
\end{tabbing}

Clocks can be reduced to filter out certain elements using @where@.
In this query, we use @where@ to count the number of days where the close price is higher than the open price.
\begin{tabbing}
MM \= MM \= MMMMMMMMMMM \= \kill
@query@ 
$\mi{gap}[c]$                                        \\
 \> $=$  \> $\mi{count}[c~@where@~\mi{close}~>~\mi{open}]$.       \\
\end{tabbing}

In the example below we have shown the result of the element expression $\mi{close}~>~\mi{open}$ for clarity only; this is not included in the output of the $\mi{gap}$ query.
\begin{code}
CODE, OPEN, CLOSE, CLOSE > OPEN, GAP
ABC,    10,    12,            T,   1
IAG,    11,    12,            T
IAG,    12,    10,            F,   1
\end{code}

\TODO{Mention resumables and bubblegum?}

\TODO{Talk about scan}

We formally define the grammar of the language in figure~\ref{fig:source:grammar}.
Note that general application is not allowed: arguments can only be applied to primitives and named functions.
Similarly, functions and primitives must be fully applied.
This, combined with the lack of lambda construction, means that higher order functions are outlawed.
While a first-order language (one lacking higher order functions) offers somewhat less abstraction, it simplifies the typing rules and makes it easier to support our performance guarantees.

While the examples shown allow user defined functions, there is no recursion allowed.
This means that all function definitions can be inlined into the user query with guaranteed termination.
When converting to the intermediate language, we assume that this inlining has occurred.

\subsection{Evaluation}

\input{figures/Source-Grammar.tex}

In figure~\ref{fig:source:eval} we describe the bigstep evaluation semantics of the language.
We use the shorthand $\ov{\Gamma}$ to mean a list of $\Gamma$, and this same overline syntax is used as a variable containing a list.
The judgment $\BigstepG{x}{\ov{v}}{v}$ uses a list $\ov{\Gamma}$, with one environment for each element of the input stream.
The environment $\Gamma$ is used for scalar variables that are not associated with any particular input element.
Next is the expression $x$ that is to be evaluated.
The last two are outputs $\ov{v}$ and $v$.
The output $\ov{v}$ is the intermediate result of the computation for each part of the input stream.
That is, each element of $\ov{v}$ is the result of evaluating $x$ on the input stream up to that element.
The final output, $v$, is the result at the end of the stream.
In most cases it is the same as the last element of $\ov{v}$, unless $\ov{v}$ is empty or for a variable lookup.

The reason for returning the result list $\ov{v}$ is to make implementing the @scan@ primitive easier.
This allows @scan@ itself to be evalauted effectively as a no-op, but does mean that each other rule has to implement its own @scan@ as well.


\TODO{It seems like we should be able to get rid of the single element return $v$, but then would it be strange with the return value being of length $max~1~|\ov{v}|$?}

When evaluating on an input such as our @stocks@ table, we would create an environment for each row, with open and close as the variables.
The rule (EvTop) simply uses the empty environment for the scalar environment, and ignores the stream output.

For variables, the rules (EvVar) and (EvVarInput) look up the variable in the contexts.
In the case of direct inputs as introduced by (EvTop), there is no corresponding entry in the scalar environment, so (EvVarInput) is used which returns an error as the scalar output.
In this way, if the input stream is used as an aggregate it will be an evaluation error, but if it is used as an element value and folded upon, the error value will be thrown away.
For normal variables, there should be a binding in all environments.

Let bindings are handled by rule (EvLet), which evaluates its definition, adds part of the stream result to each stream environments, and adds the scalar result to the scalar environment.

For the rule (EvFold), first the zero or initial value of the fold is computed, using only its scalar value.
The extra rules (ScanNil) and (ScanCons) are then used to repeatedly apply the fold computation to each stream input, starting from the initial value.
The list of fold values are added to the stream environments, and the last of the fold values, or the initial value if none, is added to the scalar environment.

In (EvFilter) the predicate is evaluated to a list of results. 
The stream environments are filtered according to this predicate list using $\mit{pack}$, and the rest of the expression is computed.
However, the result list of the rest of the expression is only the scan of the filtered stream inputs.
We use $\mit{extend}$ to add back parts of the stream that have been filtered out, but must first find the initial value of the scan to start from.

The primitive operator rules (EvAdd) and (EvGt) apply their operator to each element of the inputs.
The primitive (EvNat) returns a list of constant numbers, one for each stream element.
Finally, (EvScan) is a no-op since the hard work of computing the @scan@s is actually implemented in the rest of the rules.


\input{figures/Source-Eval.tex}
