%!TEX root = ../Main.tex
\section{Introduction}
\label{s:Introduction}

Despite the years of work on array combinator fusion, scheduling dataflow networks and streaming languages, it seems one combinator has been cast aside as jetsam: the humble merge join.
Unlike the simple access patterns of append or zip, the merge join consumes from each of its inputs in a value-dependent order, always pulling from the input with the lowest associated key.
Most dataflow language optimisations tend to focus on fully static networks where the exact access pattern is known at compile time\cite{thies2002streamit}, but disallowing combinators like merge join, append and filter.
At the other side of the spectrum, some dataflow languages such as Lucid\cite{stephens1997survey} focus on expressivity, forgoing any kind of static analyses for optimisations.

Merge joins, appends, and filters are not typically necessary for the bulk kind of operations such as audio transforms, video compression and so on, that regular dataflow has found its applications in\cite{johnston2004advances}.
However, for querying large data sets, these kind of combinators are essential.
The ``MapReduce'' framework has been touted as a solution to easy distribution of workloads, but has been found to be lacking in flexibility\cite{vrba2009kahn}, in favour of Kahn process networks.
Kahn process networks alone are too flexible: many interesting properties we would like to assure, such as the absence of deadlocks, and ability to run in bounded memory, are undecidable.
Regular dataflow languages correspond to a subset of Kahn process networks, restricted to the point of keeping these desired properties\cite{thies2009language}.

In functional languages, fusion systems such as stream fusion\cite{coutts2007stream} and fold/build fusion\cite{jones2001playing} rely on the inliner to move producers into their consumers, after which rewrite rules can remove intermediate allocations.
This short-cut fusion works well for vertical fusion when producers have only single consumers, but when a producer is used by multiple consumers it cannot be inlined without duplicating work, so fusion will not occur.
Our earlier work on flow fusion\cite{lippmeier2013data} is able to fuse these multiple consumer cases, but only for a small set of combinators; neither @append@ nor @merge@ are handled.

Our goal is to extend the regular dataflow languages enough to allow this subset of dynamic combinators, while keeping the desired properties, for the purpose of compilation and optimisation.

\subsection{Buffering}

Fusion for array programs is important for removing intermediate arrays, reducing memory traffic as well as allocations.
However, when dealing with data too large to fit in memory such as tables on disk, removing intermediate arrays becomes essential rather than just desirable.
Attempting to create an intermediate array of such amounts of data would lead to thrashing and swapping to disk, or perhaps even running out of swap.
For these situations, some sort of assurance of total fusion is required: either the program can be fused with no intermediate arrays or unbounded buffers, or it will not compile at all.

Consider the following program.
Suppose we have two sources of integers from disk, wish to filter each and pair them together, then perform some action for each pair:

\begin{code}
zip1 :: [Int] -> [Int] -> IO ()
zip1 xs ys
 = let xs'  = filter (>0) xs
       ys'  = filter (<0) ys
       zz   = zip xs' ys'
   in  mapM_ print        zz
\end{code}

This program can be executed with no buffering of either input or any intermediate arrays.
Now suppose wish to perform another action over the first source:

\begin{code}
zip2 :: [Int] -> [Int] -> IO ()
zip2 xs ys
 = let xs'  = filter (>0) xs
       ys'  = filter (<0) ys
       xs2  = map    (+1) xs
       zz   = zip xs' ys'
   in  do   mapM_ print   zz
            mapM_ print   xs2
\end{code}

If we were to execute this program either strictly or lazily, we must buffer the entire @xs@ source in memory while performing the first actions, then looping through the buffered @xs@ and performing the second action afterwards.
However, we could execute this with no buffering if the relative ordering of the two @mapM_@s were not important, and could be reordered and interspersed as the data is read.
We change the input lists to @Source@s and the @mapM_@s to @Perform@s, to denote that the IO actions are reorderable and to execute whenever data is available, and use @:&@ to join performs together.

\begin{code}
zip3 :: Source Int -> Source Int -> Perform
zip3 xs ys
 = let xs'  = filter (>0) xs
       ys'  = filter (<0) ys
       xs2  = map    (+1) xs
       zz   = zip xs' ys'
   in  Perform print      zz
   :&  Perform print      xs2
\end{code}

As a final example, suppose we removed the second data source and filtered the same source according to different predicates, then paired them together.
Can we still execute this with no buffer, and only iteration over @xs@?

\begin{code}
zip4 :: [Int] -> IO ()
zip4 xs
 = let xs'  = filter (>0) xs
       xs'' = filter (<0) xs
       zz   = zip xs' xs''
   in  mapM_ print        zz
\end{code}

Sadly this last program requires an unbounded buffer or two iterations over @xs@, as we do not know anything about the contents of @xs@.
Suppose that the entire list were made of a hundred positive numbers, followed by a hundred negative numbers: the first positive number would need to be kept around until the first negative number was reached, and likewise for the second and subsequent positive numbers -- so all one hundred positive numbers would need to be stored in memory until the negative numbers were reached.
Now consider if, instead of a hundred positive numbers, there were a thousand: now it is necessary to buffer the thousand numbers in memory instead.
The important part here is that one cannot compute, just by looking at the program, an adequate buffer size that works for all inputs.
We wish to disallow this program and others like it, where we cannot ensure execution with a bounded buffer.

In this paper, we present:
\begin{itemize}
\item a kind of deterministic finite automata, for expressing streaming computations with value-dependent rates (\S\ref{s:Machines});
\item some common combinators implemented with such machines (\S\ref{s:Machines:Combinators});
\item invariants required of such machines (\S\ref{s:Machines:Invariants});
\item and an algorithm for merging non-recursive pairs of these machines (\S\ref{s:Merging}).
\end{itemize}


