%!TEX root = ../Main.tex
\section{Introduction}
\label{s:Introduction}

Despite the years of work on array combinator fusion, scheduling dataflow networks and streaming languages, it seems one combinator has been cast aside as jetsam: the humble merge join.
Unlike the simple access patterns of append or zip, the merge join consumes from each of its inputs in a value-dependent order, always pulling from the input with the lowest associated key.
Most dataflow language optimisations tend to focus on fully static networks where the exact access pattern is known at compile time\cite{thies2002streamit}, but disallowing combinators like merge join, append and filter.
At the other side of the spectrum, some dataflow languages such as Lucid\cite{stephens1997survey} focus on expressivity, forgoing any kind of static analyses for optimisations.

Merge joins, appends, and filters are not typically necessary for the bulk kind of operations such as audio transforms, video compression and so on, that regular dataflow has found its applications in\cite{johnston2004advances}.
However, for querying large data sets, these kind of combinators are essential.
The ``MapReduce'' framework has been touted as a solution to easy distribution of workloads, but has been found to be lacking in flexibility\cite{vrba2009kahn}, in favour of Kahn process networks.
Kahn process networks alone are too flexible: many interesting properties we would like to assure, such as the absence of deadlocks, and ability to run in bounded memory, are undecidable.
Regular dataflow languages correspond to a subset of Kahn process networks, restricted to the point of keeping these desired properties\cite{thies2009language}.

In functional languages, fusion systems such as stream fusion\cite{coutts2007stream} and fold/build fusion\cite{jones2001playing} rely on the inliner to move producers into their consumers, after which rewrite rules can remove intermediate allocations.
This short-cut fusion works well for vertical fusion when producers have only single consumers, but when a producer is used by multiple consumers it cannot be inlined without duplicating work, so fusion will not occur.
Our earlier work on flow fusion\cite{lippmeier2013data} is able to fuse these multiple consumer cases, but only for a small set of combinators; neither @append@ nor @merge@ are handled.

Our goal is to extend the regular dataflow languages enough to allow this subset of dynamic combinators, while keeping the desired properties, for the purpose of compilation and optimisation.

\subsection{Buffering}

Fusion for array programs is important for removing intermediate arrays, reducing memory traffic as well as allocations.
However, when dealing with data too large to fit in memory such as tables on disk, removing intermediate arrays becomes essential rather than just desirable.
Attempting to create an intermediate array of such amounts of data would lead to thrashing and swapping to disk, or perhaps even running out of swap.
For these situations, some sort of assurance of total fusion are required: either the program can be fused with no intermediate arrays or unbounded buffers, or it will not compile at all.

Consider the following program.
Suppose we have two sources of integers from disk, wish to filter each and pair them together, then perform some action for each pair:

\begin{code}
zip1 :: Source Int -> Source Int -> IO ()
zip1 xs ys
 = let xs'  = filter (>0) xs
       ys'  = filter (<0) ys
       zz   = zip xs' ys'
   in  mapM_ fire_missile zz
\end{code}

This program can be executed with no buffering of either input or any intermediate arrays.
Now suppose wish to perform another action over the first source:

\begin{code}
zip2 :: Source Int -> Source Int -> IO ()
zip2 xs ys
 = let xs'  = filter (>0) xs
       ys'  = filter (<0) ys
       xs2  = map    (+1) xs
       zz   = zip xs' ys'
   in  do   mapM_ fire_missile zz
            mapM_ fortify      xs2
\end{code}

Sadly, this program requires buffering the entire @xs@ source in memory while performing the first actions, then looping through the buffered @xs@ and performing the second action afterwards.
However, we could execute this with no buffering if the relative ordering of the two @mapM_@s was not important, and could be reordered and interspersed as the data is read.
We use the following @When@ syntax to denote performing a reorderable IO action \emph{when}ever data is available.

\begin{code}
zip3 :: Source Int -> Source Int -> IO ()
zip3 xs ys
 = let xs'  = filter (>0) xs
       ys'  = filter (<0) ys
       xs2  = map    (+1) xs
       zz   = zip xs' ys'
   in  When fire_missile zz
   :&  When fortify      xs2
\end{code}

As a final example, suppose we removed the second data source and filtered the same source according to different predicates, then paired them together.
Can we still execute this with no buffer, and only iteration over @xs@?

\begin{code}
zip4 :: Source Int -> IO ()
zip4 xs
 = let xs'  = filter (>0) xs
       xs'' = filter (<0) xs
       zz   = zip xs' xs''
   in  mapM_ fire_missile zz
\end{code}

Sadly this last program requires an unbounded buffer or two iterations over @xs@, so we would like to disallow it.
It may not be immediately obvious just looking at the program that it requires two iterations, which is why we would like this to be automated.

In summary, the purpose of this work is to determine which programs can be executed with no buffering, and offer an efficient compilation strategy for these.

