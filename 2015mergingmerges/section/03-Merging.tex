%!TEX root = ../Main.tex
\section{Merging machines}
\label{s:Merging}

This section describes how machines can be merged together to form a single machine that computes both.

The idea is to create a new machine with the product of the two states; at each state, one or the other of the machines may be able to take a step.
If so, we update that machine's state and leave the other one as-is.
For shared inputs or outputs, both machines must take the steps at the same time: if they both pull from the same input, they must pull at the same time.
Similarly, if one machine produces an input and the other reads it, the first machine can only produce its output if the second is pulling on it.

If neither machine can make a move, the program is disallowed.
For example, if the first machine is trying to read from a shared input while the second tries to read from the first machine's input, executing it may require buffering the input until the second machine catches up.

However, the above explanation is too strict and outlaws programs such as @zip xs ys@ merged with @zip ys xs@, as neither machine can progress until the other does, leading to deadlock.
To resolve this, we add to the resulting machine's state a set of pending events for each machine.
The first machine may read from a shared input as long as there is not already a ``read'' event pending for the other machine to deal with.
Reading from a shared input adds a pending ``read'' event to the other machine, and the other machine may then skip past a @Pull@ for that source, as it is known that the other machine has already pulled on it.

\subsection{General merging}
Let us define the potential pending events on a machine.
One machine may have read from a shared input, but the other has not.
Similarly, if one machine has tried to read from a shared input but the input is empty, when the other machine attempts to read it can skip directly to the @None@ case.

Shared outputs, when one machine produces a value and the other consumes it.
Here, events are used to indicate that the producer has written a value, and cannot write another until the consumer has dealt with it, or that the producer has finished and the consumer's next read will skip to the @None@ case.

Finally, if one machine closes a shared input but the other is still reading, we do not close the input but instead treat the input as a local input, allowing the reading machine to continue reading at any rate. 

\begin{tabbing}
MM \= MM \= MMMMMM \= M\kill
$\Psi$ \> $=$  \> @Value@     \> $n$         \\
       \> $~|$ \> @Finished@  \> $n$         \\
       \> $~|$ \> @Closed@    \> $n$         \\
\end{tabbing}

The @merge@ function takes two machines with states $l_1$ and $l_2$, and produces a new machine with state $l_1 \times \{\Psi\} \times l_2 \times \{\Psi\}$.
It starts by creating an empty machine, and inserting states one by one, starting from the initial state as the initial state of each machine, and empty pending sets.
Then, for each output transition of the input machines, states are recursively added.

\begin{tabbing}
MMMMMMM \= MM \= MMMMMM \= M\kill
@merge@ \> $:$ \> $@Machine @l_1 \times @Machine @l_2$ \\
        \> $\to$ \> $@Machine @(l_1 \times \{\Psi\} \times l_2 \times \{\Psi\})$ \\
\\
@merge @$m_1~m_2$ \> $=$ \> $@merge@'~(@init @m_1)~(@init @m_2)~\{\}~@empty@$ \\
\\
$@merge@'$ \> $:$ \> $l_1 \times \{\Psi\} \times l_2 \times \{\Psi\}$               \\
           \> $\times$ \> $@Machine @(l_1 \times \{\Psi\} \times l_2 \times \{\Psi\})$ \\
           \> $\to$ \> $@Machine @(l_1 \times \{\Psi\} \times l_2 \times \{\Psi\})$ \\
\\
MMM \= M \= MMMMMMMMMM \= M \=\kill
$@merge@'~s_1~\psi_1~s_2~\psi_2~m$ \\
 \> $~|$ \> $(s_1, \psi_1, s_2, \psi_2) \in m$  \\
 \> $=$  \> $m$ \\
 \> $~|$ \> $(\gamma,\delta) \in @move@~s_1~\psi_1~s_2~\psi_2$ \\
 \> $=$  \> $@fold@~@merge@'~(m \cup \gamma \cup \delta)~\delta$ \\
\end{tabbing}

The $@merge@'$ function adds the given state and recursively adds the successor states to the given machine.
If the given state has already been added --- for example the state is reachable by multiple states --- the state need not be added.

\begin{tabbing}
MMM \= M \= MMMMMMM\kill
$@move@$ \> $:$ \> $l_1 \times \{\Psi\} \times l_2 \times \{\Psi\}$ \\
           \> $\to$ \> $\Gamma \times \{\Sigma \times (l_1 \times \{\Psi\} \times l_2 \times \{\Psi\})\}$ \\
\end{tabbing}

The @move@ function computes the states and transitions of the merged machine.
These are added to the machine by $@merge@'$ above.

\input{figures/MergeGen.tex}

\subsubsection{Non-interfering states}
If either of the machines are attempting to update their local state, this can be done easily without interfering with the other machine.

Skips are dealt with in the same way, affecting only one machine.

Similarly, @If@s only affect one of the machines, leaving the other in its original state.
If we had an oracle for checking functional equivalence, we could check whether two @If@s had the same function and inputs and potentially allow more programs.
However, lacking an oracle, even if both machines have @If@s with the same predicate, we generate a machine for all possible result combinations (all four of them).

If both machines are @Done@, the resulting machine will also be @Done@.

\subsubsection{Output and finishing}
The previous cases have been rather trivial as they require no synchronisation between the machines, but the remaining cases of @Out@, @OutFinished@, @Pull@, @Release@ and @Close@ are more complicated.

If the first machine is producing an output on channel $n$ and the second machine uses $n$, the first machine would usually have to wait until the second machine is ready to accept new data.
However, if the second machine has closed $n$, it will never pull on $n$ again, so the first machine may output to the channel as frequently as it likes.
Note that the output channels may have multiple consumers, so continuing to output after a consumer has finished is not as futile as it may seem at first.

Again, if the first machine is producing and the second is consuming, the first machine may only produce if there is no unhandled value on the channel.
This is what $\psi$ and $\phi$ are for.
If there is a value in the other machine's event set, $\phi$, a later case may allow the second machine to pull from it.

The final case for @Out@ is when the second machine does not use this output, allowing the first machine to output at any time.

The cases for @OutFinished@ proceed similarly to @Out@.

\subsubsection{Pull}
When the channel is a local input, @Pull@ing proceeds as normal.
Likewise with a shared input that has been closed by the other machine - the other machine will no longer attempt to pull, so no synchronisation is required.

If there is a @Value@ in the current machine's event set, the channel must either be a shared input, or an output channel on the other machine.
If it is a shared input, the presence of a @Value@ means the other machine has already executed a @Pull@ and has succeeded.
Otherwise, for an output channel, the @Value@ means the other machine has produced a value which must be used before another can be produced.
In either case, we simply proceed to the @Some@ branch of the @Pull@, safe in the knowledge that there is a value to use.

If there is a @Finished@ in either machine's event set, and neither machine has a pending @Value@s to deal with, we know that the other machine has had either an @OutFinished@ or an empty @Pull@.
We proceed to the @None@ case of the @Pull@.

Finally, if there are no pending @Value@ or @Finished@ events in either machine and it is a shared input, this machine can safely pull on the input, adding pending events for the other machine to deal with.


\subsubsection{Release}
Pulled values must be released.
This is used for synchronisation, so that one machine cannot pull on a shared input until after both machines have released the value.
Otherwise, one machine could pull while the other machine is still using the value, requiring a larger buffer.

For local channels, the release is performed as usual.

If the channel is an output of the other machine, the release is emitted as a skip, but the @Value@ is removed from the event set, which will allow the other machine's @Out@ to proceed.

For shared inputs, there will be two releases of the one value, but only the second should be emitted as an actual release.

For the first release, both machines will have a @Value@ event, and we emit a skip, removing this machine's @Value@.

For the second release, the other machine has already removed its @Value@ event, so we remove this machine's @Value@ and emit a real release.
At this stage, neither machine will have a @Value@ event, which will allow another @Pull@ to execute.

\subsubsection{Close}
For @Close@, if the channel is neither an input nor an output of the other machine, then closing the channel does not affect the other machine and acts as a normal @Close@.

If the channel is an output of the other machine, we skip past.
Because the channel may have other consumers, we do not stop it.
So that further outputs on this channel do not wait on this machine, we add a @Closed@ event to $\psi$.



If none of the above cases apply, it means the machines cannot be fused.
Either they require more than one element of buffering, or reasoning about function equality would be required to prove that they do not.
The only unhandled cases above are where the two machines share input or outputs, and there are existing values buffered in $\psi$.
In which case, we give a compile time error indicating that these two machines cannot be fused.

\subsubsection{Example}
Let us merge a @map@ (figure~\ref{fig:com:map}) and a @filter@ (figure~\ref{fig:com:filter}).
The actual program would be
\begin{code}
fun xs
 = let m  = map    (+1) xs
       f  = filter (>0) xs
   in (m, f)
\end{code}

We need to name each state.
While the graphical form is easier to understand, a textual form makes looking up a particular state's transitions easier.
The @map@ state types and transitions are below, with initial state being @m1@.

\begin{code}
m1 : Pull xs     { Some => m2; None => m4 }
m2 : Out m (x+1) { Unit => m3 }
m3 : Release x   { Unit => m1 }
m4 : OutFinished m{ Unit => m5 }
m5 : Done
\end{code}

Likewise, the filter has initial state @f1@.

\begin{code}
f1 : Pull xs     { Some => f2; None  => f5 }
f2 : If (x>0)    { True => f3; False => f4 }
f3 : Out f x     { Unit => f4 }
f4 : Release x   { Unit => f1 }
f5 : OutFinished f{ Unit => f6 }
f6 : Done
\end{code}

We start by computing $@merge@'$ of an empty machine, empty $\psi$ sets, and initial states of each machine:
$$
@merge@'~@m1@~\emptyset~@f1@~\emptyset~@empty@
$$

In this case, there are two possible moves: either @m@ may take a step, or @f@ may take a step, but both steps are @Pull xs@. When two moves are possible, we will take the @m@ one, but this decision has no effect on the outcome \TODO{(prove it)}.
\begin{code}
move m f m1 {} f1 {} =
    Pull xs,
    { Some => m2, {Value xs},    f1, {Value xs}
    ; None => m4, {Finished xs}, f1, {Finished xs} }
(Shared pull, no pending values)
\end{code}

We insert this state and transitions into the empty machine, noting that the transitions to undefined states will be defined by later moves.

\begin{code}
m1,{},f1,{}
    : Pull xs
    { Some => m2, {Value xs},    f1, {Value xs}
    ; None => m4, {Finished xs}, f1, {Finished xs} }
\end{code}

Now, calculate the first undefined move.
Again, either machine may move: @m@ could compute its output, or @f@ could skip past the @Pull xs@, since this has been performed by @m@, witnessed by the @Value xs@ in @f@'s $\psi$ set.

\begin{code}
move m f m2 {Value xs} f1 {Value xs} =
    Out m (x+1)
    { Unit => m3, {Value xs}, f1, {Value xs} }
(Local output, free to write)
\end{code}

This puts @m@ at a @Release@, which is changed to a skip as the later release by @f@ will be the real release.

\begin{code}
move m f m3 {Value xs} f1 {Value xs} =
    Skip
    { Unit => m1, {}, f1, {Value xs} }
(Shared release: first release is skip)
\end{code}

Now machine @m@ is back at a @Pull xs@, but it is unable to execute the pull itself as the other machine @f@ still has a pending @Value xs@ to deal with.
The machine @f@ is also at a @Pull xs@, and is able to skip past since it already has a value.

\begin{code}
move m f m1 {} f1 {Value xs} =
    Skip
    { Unit => m1, {}, f2, {Value xs} }
(Pull has value)
\end{code}

Now @f@ is at an @If@, and @m@ still cannot run.

\begin{code}
move m f m1 {} f2 {Value xs} =
    If (x>0)
    { True  => m1, {}, f3, {Value xs}
    , False => m1, {}, f4, {Value xs} }
(If)
\end{code}

The first case of the @If@ is a local output. 
\begin{code}
move m f m1 {} f3 {Value xs} =
    Out f x
    { Unit => m1, {}, f4, {Value xs} }
(Local output, free to write)
\end{code}

Next is a release.
In this case, the input is shared and the other machine has already released, since there is no @Value xs@ in its set.
We emit an actual release in this case, since we are sure both machines are finished using it.

\begin{code}
move m f m1 {} f4 {Value xs} =
    Release x
    { Unit => m1, {}, f1, {} }
(Shared release: other machine already released)
\end{code}

Now the only missing state is @m4, {Finished xs}, f1, {Finished xs}@ after the @m@'s pull is empty.

\begin{code}
move m f m4 {Finished xs} f1 {Finished xs} =
    OutFinished m
    { Unit => m5, {Finished xs}, f1, {Finished xs} }
(Finish local output)
\end{code}

Now @m@ is @Done@, and cannot move, while @f@ is at a @Pull xs@ that it already knows is finished.
\begin{code}
move m f m5 {Finished xs} f1 {Finished xs} =
    Skip
    { Unit => m5, {Finished xs}, f5, {Finished xs} }
(Pull of finished)
\end{code}

Now @m@ is @Done@, and cannot move, while @f@ is at a @Pull xs@ that it already knows is finished.
\begin{code}
move m f m5 {Finished xs} f5 {Finished xs} =
    OutFinished f
    { Unit => m5, {Finished xs}, f6, {Finished xs} }
(Finish local output)
\end{code}

Both machines are now done.
\begin{code}
move m f m5 {Finished xs} f6 {Finished xs} =
    Done
(Both machines done)
\end{code}

The entire machine at the end is:
\begin{code}
m1,{},f1,{}
    : Pull xs
    { Some => m2, {Value xs},    f1, {Value xs}
    ; None => m4, {Finished xs}, f1, {Finished xs} }
m2,{Value xs},f1,{Value xs}
    : Out m (x+1)
    { Unit => m3, {Value xs},    f1, {Value xs}    }
m3,{Value xs},f1,{Value xs}
    : Skip
    { Unit => m1, {},            f1, {Value xs}    }
m1,{},f1,{Value xs}
    : Skip
    { Unit => m1, {},            f2, {Value xs}    }
m1,{},f2,{Value xs}
    : If (x>0)
    { True => m1, {},            f3, {Value xs}
    , False=> m1, {},            f4, {Value xs}    }
m1,{},f3,{Value xs}
    : Out f x
    { Unit => m1, {},            f4, {Value xs}    }
m1,{},f4,{Value xs}
    : Release x
    { Unit => m1, {},            f1, {}            }
m4,{Finished xs},f1,{Finished xs}
    : OutFinished m
    { Unit => m5, {Finished xs}, f1, {Finished xs} }
m5,{Finished xs},f1,{Finished xs}
    : Skip
    { Unit => m5, {Finished xs}, f5, {Finished xs} }
m5,{Finished xs},f5,{Finished xs}
    : OutFinished f
    { Unit => m5, {Finished xs}, f6, {Finished xs} }
m5,{Finished xs},f6,{Finished xs}
    : Done
\end{code}

The @Skip@s can then be removed quite easily, leading to the graph below.

\begin{dot2tex}[scale=0.5]
digraph {
    rankdir=LR;
    mindist=0.1
    nodesep=0.1;
    ranksep=0.1;
    node [shape="circle", margin=0];
    10 [label="Pull xs"];
    20 [label="Out m (x+1)"];
    50 [label="If"];
    60 [label="Out f x"];
    70 [label="Release x"];
    900[label="OutFinished m"];
    920[label="OutFinished f"];
    930[label="Done"];

    10 -> 20 [label="Some x"];
    10 -> 900 [label="None"];

    50 -> 60 [label="True"];
    50 -> 70 [label="False"];

    20 -> 50;
    60 -> 70;
    70 -> 10;
    900 -> 920;
    920 -> 930;
}
\end{dot2tex}



\subsection{Producer-consumer}
The general case above is sufficient, but in some cases can generate larger machines than necessary.
Talk about special case for producer-consumers.

\begin{code}
data Which = LeftExec | RightExec

mergeV :: Machine l1 -> Machine l2
       -> Machine (l1, l2, Which)
\end{code}


\subsection{Theorems we want to prove}

As we do not wish to handle recursive combinators, we also do not need to handle merging cyclic machines.
This is one case that regular dataflow handles but we do not.
The predicate below checks if either of the machines does not use the other's input; if both used the other's input, it would create a cycle.

\begin{tabbing}
MMMMMMM \= MM \= \kill
$@acyclic@~a~b$
\> $:=$
\> $\outputs{a}~\cap~\inputs{b}~=~\emptyset$
\\
\> $~\vee$ \> $\outputs{b}~\cap~\inputs{a}~=~\emptyset$
\end{tabbing}

Two machines cannot be merged if they both provide the same output, or write to the same output channel.

\begin{tabbing}
MMMMMMM \= MM \= \kill
$@distinct@~a~b$
\> $:=$
\> $\outputs{a}~\cap~\outputs{b}~=\emptyset$
\end{tabbing}

For the special case of vertical fusion, we require there be one output used as the other machine's sole input, and no other sharing.
Both machines may have multiple outputs, and the producer may have multiple inputs, but the consumer can only have one input.

\begin{tabbing}
MMMMMMM \= MM \= MM \= \kill
$@vertical@~a~b$
\> $:=$
\> $\exists n.$
\> $(n \in \outputs{a} \wedge \sgl{n} = \inputs{b})$
\\
\>
\> $~\vee$
\> $(n \in \outputs{b} \wedge \sgl{n} = \inputs{a})$
\end{tabbing}

\subsubsection{General preservation}
The result of merging two machines should maintain the pull invariants (\S~\ref{s:Machines:Invariants}), provided that the input machines also maintain their invariants.

\begin{tabbing}
MMMMMMM \= MM \= MM \= \kill
$\forall a~b.$
\>
\> $a~@ok@~\wedge~b~@ok@$
\\
\> $\wedge$
\> $@acyclic@~a~b$
\\
\> $\wedge$
\> $@distinct@~a~b$
\\
\> $\implies$
\> $\forall c \in (@merge@~a~b).\ c~@ok@$
\end{tabbing}

\paragraph{Lemma transitions:} for each state $u$ of $@merge@~a~b$ and corresponding states $s$ and $t$ of $a$ and $b$, any output transitions from $u$ either move along $s$'s output transitions or $t$'s output transitions, but not both.
Similarly, the state type of $u$ will either be the type of $s$, the type of $t$, or a @Skip@.

\paragraph{Lemma appears:} for all states $s$ in $a$, if there is a path from $@initial@~a$ to $s$, then:
\begin{itemize}
\item if $s$ is a @Close@, either $s$ or a @Finish@ or a @Close@ from the other machine $b$ will appear in the output ($@merge@~a~b$);
\item if $s$ is an @Out@, @Update@, @If@, $s$ will appear in the output;
\item otherwise, $s$ 
\end{itemize}
ACTUALLY, \textbf{appears} isn't true.


\paragraph{Proof sketch:} each state in $a$ and $b$ has an associated set of $\Psi$.
If we deconstruct each state of $c$, it has a state of $a$, a state of $b$, and a $\Psi$ set for each.

Show that in this $(\sptpC)$, the $\psi$ and $\phi$ is something similar to $s$ and $t$'s $\Psi$ set.

Total $\Psi$ is the union of $\psi$ and $\phi$, except if one set has @Closed@ but the other doesn't, that channel is still open.

Then, look at each rule in @move@, and the preconditions should translate to sufficient preconditions on $\Psi$:

@Skip@, @Update@ and @If@ are trivial.

If both machines are @Done@, since both machines are also @ok@, all their inputs and outputs must be closed..

\subsubsection{Vertical preservation}

\begin{tabbing}
MMMMMMM \= MM \= MM \= \kill
$\forall a~b.$
\>
\> $a~@ok@~\wedge~b~@ok@$
\\
\> $\wedge$
\> $@acyclic@~a~b$
\\
\> $\wedge$
\> $@vertical@~a~b$
\\
\> $\wedge$
\> $@distinct@~a~b$
\\
\> $\implies$
\> $\forall c \in (@mergeV@~a~b).\ c~@ok@$
\end{tabbing}


\subsubsection{Vertical progress}

\begin{tabbing}
MMMMMMM \= MM \= MM \= \kill
$\forall a~b.$
\>
\> $a~@ok@~\wedge~b~@ok@$
\\
\> $\wedge$
\> $@acyclic@~a~b$
\\
\> $\wedge$
\> $@vertical@~a~b$
\\
\> $\wedge$
\> $@distinct@~a~b$
\\
\> $\implies$
\> $\exists c.\ c \in @mergeV@~a~b$
\end{tabbing}



