%!TEX root = ../Main.tex
\section{Benchmarks}
\label{s:Benchmarks}
\input{figures/Bench-All.tex}

At Ambiata, we are currently using Icicle in production over medium-sized datasets that fit on a single disk.
These initial results have been very promising, and we are currently implementing distribution across multiple machines to handle datasets that are tens of terabytes compressed, and do not fit on a single disk.
Incremental computation is even more important for this distributed case, as we can avoid copying terabytes of data over the network.

We evaluated Icicle by replacing an R script which ran weekly in production.
This R script works over around three hundred gigabytes of pipe-separated values (PSV) data.
It computes twelve queries over each of the thirty-one input tables, computing 372 queries in total.

The R script for this takes fifteen hours to run and is 3,566 lines of code.
In contrast, our Icicle queries take seven minutes to run, and the dictionary describing the queries is 191 lines of code.

The table in figure~\ref{fig:bench:other} shows the throughput in megabytes per second.
We compared the throughput of several programs over the same 317GB dataset:
\begin{itemize}
\item our original R implementation (R);
\item Icicle running single-threaded (1 CPU);
\item Icicle running on multiple processors (32 CPU);
\item finding empty lines with @grep "^$"@;
\item counting characters, words and lines with @wc@;
\item reading and throwing away the results with @cat > /dev/null@.
\end{itemize}

We ran all of the Unix utilities with unicode disabled using @LANG=C LC_COLLATE@ for maximum performance.
The computer we used for most of these was an Amazon EC2 @c3.8xlarge@ with 32 CPUs, 60GB of RAM, and striped, RAIDed SSD storage.
The R code requires an @i2.8xlarge@ with 244GB of memory, but we were unable to perform our other benchmarks on such a large machine.
Icicle significantly outperformed R, and the single-threaded version was on par with @wc@, while only a little slower than @grep@.
This is despite doing conceptually more work than @wc@ and @grep@.
By using multiple processors, we were able to scale up to perform as well as @cat@, approaching the disk speed.
The R code is single threaded and would require at least 150 processors to reach similar speeds, assuming perfect scaling.
These results give us confidence that our distributed implementation will be fast as well as scalable~\cite{mcsherry2015scalability}.

We have been able to achieve such good results by generating parsing code specialised to the schema, and using data-only flattening~\cite{bergstrom2013data} as an efficient representation of structures such as arrays of sum types and tuples.
By using a query plan that is close to a functional language, we are able to apply many standard optimisations such as common subexpression elimination and dead code removal.




\input{figures/Bench-Queries.tex}

Figure~\ref{fig:bench:queries} shows how Icicle scales in throughput as more queries are added.
We ran two versions with each number of queries; one version writing output to disk, and the other throwing away the result to @/dev/null@ rather than spending time writing.
The graph shows the disk version decreasing roughly linearly in the number of queries, while the version ignoring the output stays constant.
This suggests that the output code is the bottleneck, which is unsurprising given the output format is text-based PSV.
The upshot of this is that the time spent computing the queries appears constant as hundreds of queries are added, which suggests that many more queries can be handled if a better output format is used.

