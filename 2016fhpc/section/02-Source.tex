%!TEX root = ../Main.tex

\eject
% ---------------------------------------------------------
\section{Elements and Aggregates}
\label{s:ElementsAndAggregates}
To allow incremental computation all Icicle queries must execute in a single pass over the input stream.
Sadly, not all queries \emph{can} be executed in a single pass: the key examples are queries that require random access indexing, or otherwise need to access data in an order different to what the stream provides.
However, as we saw in the introduction, although a particular \emph{algorithm} may be impossible to evaluate in a streaming fashion, the desired \emph{value} may well be computable, if only we had a different algorithm.
Here is the unstreamable example from the introduction again:
\begin{code}
  table kvs { key : Date; value : Real }
  query avg = let k = last key
              in  filter (key == k) of mean value;
\end{code}

The problem is that the value of @last key@ is only available once we have reached the end of the stream, but @filter@ needs this value to process the very first element in the same stream.
We distinguish between these two access patterns by giving them different names: we say that @last key@ is an \emph{aggregate}, because to compute it we must have consumed the \emph{entire stream}, whereas the filter predicate is an \emph{element}-wise computation because it only needs access to the current element in the stream.

The trick to compute our average in a streaming fashion is to recognize that @filter@ is selecting a particular subset of values from the input, but the value computed from this subset depends only on the values in that subset, and no other information. Instead of computing the mean of a single subset whose identity is only known at the end of the stream, we can instead compute the mean of \emph{all possible subsets}, and return the required one once we know what that is:
\begin{code}
  table kvs { key : Date; value : Real } 
  query avg = let k    = last  key in
              let avgs = group key of mean value
              in  lookup k avgs
\end{code}

Here we use the @group@ construct to assign key-value pairs to groups as we obtain them, and compute the running mean of the values of each group. The @avgs@ value becomes a map of group keys to their running means. Once we reach the end of the stream we will have access to the last key and can lookup the final result.
%% Review #1:
%% In Section 3 I kept looking for a definition of the “last” function, which takes an important role in the Introduction.
%% In Section 4, I found the definition. It would help the reader to give a small note early in Section 2 or 3 that “last”, “mean”, “sum” are user-level (i.e. non-primitive) functions whose definition will be given in Section 4.
Evaluation and typing rules are defined in~\S\ref{s:IcicleSource}, while the user functions @last@ and @mean@ are defined in~\S\ref{s:IcicleCore}.


% ---------------------------------------------------------
\subsection{The Stage Restriction}
To ensure that Icicle queries can be evaluated in a single pass, we use a modal type system inspired by staged computation~\cite{davies2001modal}. We use two modalities, @Element@ and @Aggregate@. Values of type @Element@~$\tau$ are taken from input stream on a per-element basis, whereas values of type @Aggregate@~$\tau$ are available only once the entire stream has been consumed. In the expression @(filter (key == k) of mean value)@, the variable @key@ has type @Element Date@ while @k@ has type @Aggregate Date@. Attempting to compile the unstreamable query in Icicle will produce a type error complaining that elements cannot be compared with aggregates.

Note that the types of pure values such as constants are automatically promoted to the required modality. For example, if we have @open == 1@ and @open : Element Int@ then the constant @1@ is automatically promoted to have type @Element Int@ as well.


% ---------------------------------------------------------
\subsection{Finite Streams and Synchronous Data Flow}
In contrast to synchronous data flow languages such as {\sc Lustre}~\cite{halbwachs1991synchronous}, the streams processed by Icicle are conceptually finite in length. Icicle is fundamentally a query language, which queries finite tables of data held in a non-volatile store, but does so in a streaming manner. Lustre operates on conceptually infinite streams, such as those found in real-time control systems (like to fly airplanes). In Icicle, the ``last'' element in a stream is the last one that appears in the table on disk. In Lustre, the ``last'' element in a stream is the one that was most recently received. If the unstreamable query from \S2 was converted to Lustre syntax then it would execute, but the filter predicate would compare the last key with the most recent key from the stream, which is the key itself. The filter predicate would always be true, and the query would return the mean of the entire stream. Applying the Icicle type system to our queries imposes the natural stage restriction associated with finite streams, so there are distinct ``during'' (element) and ``after'' (aggregate) stages.


% ---------------------------------------------------------
\subsection{Incremental Update}
Suppose we query a large table and record the result. Tomorrow morning we receive more data and add it to the table. We would like to update the result without needing to process all data from the start of the table. We can do this by remembering the values of all intermediate aggregates that were computed in the query, and updating them as new data arrives. In the @avg@ example from \S2 these aggregates are @k@ and @avgs@. 

We also provide impure contextual information to the query such as the current date, by assigning it an aggregate type. As element-wise computations cannot depend on aggregate computations we ensure that reused parts of an incremental computation are the same regardless of which day they are executed.


% ---------------------------------------------------------
\subsection{Bounded Buffer Restriction}
\label{s:IcicleSource:bounded}
Icicle queries process tables of arbitrary size that may not fit in memory. Due to this, each query must execute without requiring buffer space proportional to the size of the input. As a counter example, here is a simple function which cannot be applied without reserving a buffer of the same size as the input:
\begin{code}
    unbounded (xs : Stream Int)
     = zip (filter (> 0) xs) (filter (< 0) xs)
\end{code}

This function takes an input stream @xs@, and pairs the elements that are greater than zero with those that are less than zero.
This computation requires an unbounded buffer because if the stream contains $n$ positive values followed by $n$ negative values, then all positive values must be buffered until we reach the negative ones, which allow output to be produced.

%% Review #1
%% It’s not clear what’s meant by “In Icicle, queries that would require unbounded buffering cannot be written”.
%% My understanding is that they can be written, but we would get a runtime error because the buffer would eventually become too big to fit the memory. Is this right?
% change to "statically outlawed by the typesystem": I think that's unambiguous.

In Icicle, queries that would require unbounded buffering are statically outlawed by the typesystem, with one major caveat that we will discuss in a moment. In Icicle, the stream being processed (such as @xs@ above) is implicit in each query. Constructs such as @filter@ and @fold@ do not take the name of the stream as an argument, but instead operate on the stream defined in the context. Icicle language constructs describe \emph{how elements from the stream should be aggregated}, but the order in which those elements are aggregated is implicit, rather than being definable by the body of the query. In the expression @(filter p of mean value)@, the term @mean value@ is applied to stream values which satisfy the predicate @p@, but the values to consider are supplied by the context.

Finally, our major caveat is that the @group@ construct we used in \S2 uses space proportional to the number of distinct \emph{keys} in the input stream.
For our applications the keys are commonly company names, customer names, and days of the year.
Our production system knows that these types are bounded in size and that maps from keys to values will fit easily in memory.
Attempting to group by values of a type with an unbounded number of members, such as a @Real@ or @String@ results in a compile-time warning.

% Grouping by types with an unbounded number of members, such as @Real@ or @String@ can be undesirable, and we wish to outlaw this in a future version of our production compiler.

% BEN: "Can be undesirable" is too imprecise. What will happen is that an entry will be added to the map for every key, and if there are more keys than will fit in memory then the query will run out of memory. Surely adding the mentioned warning to the compiler would not be difficult? If it's easy then saying it's done sounds much better than "we intend to". We need to have a solid story about this point. One of the key contributions of Icicle is that it does not require ``unbounded buffering'', but if you're grouping by arbitrary values from the input stream then it clearly does.


\eject
% ---------------------------------------------------------
\section{Source Language}
\label{s:IcicleSource}

\input{figures/Source-Grammar.tex}
\input{figures/Source-Type.tex}
\input{figures/Source-Eval.tex}

The grammar for Icicle is given in Figure~\ref{fig:source:grammar}.
Value types $T$ include numbers, booleans and maps.
Modal types $\TauMode$ include the pure value types, and modalities associated with a value type.
%% Review 3:
%% In Section 3, the description of function types is confusing.
%% The authors state, "Function types F include non-function modal types, and functions from modal type to function type."
%% It appears from Figure 1 that function types do not include non-function modal types (syntactic category M), and include only functions from modal type(s) to *modal* type.
Function types $\TauFun$ include functions with any number of modal type arguments to a modal return type.
As Icicle is a first-order language, function types are not value types.

Table definitions $\mi{Table}$ define a table name and the names and types of columns.
Expressions $\mi{Exp}$ include variable names, constants, applications of primitives and functions.
The @fold@ construct defines the name of an accumulator, the expression for the initial value, and the expression used to update the accumulator for each element of the stream.
The @filter@ construct defines a predicate and an expression to accumulate values for which the predicate is true.
The @group@ construct defines an expression used to determine the key for each element of the stream, and an expression to accumulate the values that share a common key.

$\mi{Prim}$ defines the primitive operators.
$\mi{V}$ defines values.
$\mi{Def}$ contains both function and query definitions.
$\mi{Top}$ is the top-level program, which specifies a table, the set of function bindings, and the set of queries.
All queries in a top-level program process the same table.


% ---------------------------------------------------------
\subsection{Type System}
The typing rules for Icicle are given in Figure~\ref{fig:source:type:exp}.
The judgment form $\Typecheck{\Gamma}{\mi{e}}{\TauMode}$ associates an expression $\mi{e}$ with its type $M$ under context $\Gamma$.
The judgment form $\TypecheckP{\mi{p}}{\TauFun}$ associates a primitive with its function type.
The judgment form $\TypecheckApp{\TauFun}{\ov{\TauMode}}{\TauMode}$ is used to lift function application to modal types: a function type applied to a list of modal argument types produces a result type and matching mode.
The judgment form $\TypecheckS{\Gamma}{\mi{Def}}{\Gamma}$ takes an input environment and function or query, and produces an environment containing the function or query name and its type.
Finally, $\TypecheckS{}{\mi{Top}}{\Gamma}$ takes a top-level definition with a table, functions and queries, and produces a context containing the types of all the definitions.

Rules TcNat, TcBool, TcMap and TcPair assign types to literal values.
Rule TcVar performs variable lookup in the context.
Rule TcBox assigns an expression either @Element@ or @Aggregate@ type. 

Rules TcPrimApp and TcFunApp produce the type of a primitive or function applied to its arguments. Rule TcLet is standard.

In rule TcFold the initial value has value type $T$. The type of the current element from the stream is added to the context of $e_k$ as an @Element@, and the result of the overall fold is an @Aggregate@. Rules TcFilter and TcGroup are similar.

Rules PrimArith, PrimRel, PrimLookup, PrimFst and \mbox{PrimSnd} assign types to primitives.
Rule AppArgs produces the type of a function or primitive applied to its arguments.
Rule AppRebox is used when the arguments have modal type $m$ --- applying a function to arguments of mode $m$ produces a result of the same mode.

Rule CheckFun builds the type of a user defined function, returning it as an element of the output context. Rule CheckQuery is similar, noting that all queries return values of @Aggregate@ type. Finally, rule CheckTop checks a whole top-level program.


% ---------------------------------------------------------
\subsection{Evaluation}
Evaluation rules for Icicle are given in Figure~\ref{fig:source:eval}.
Grammar $N$ defines the modes of evaluation, including pure computation.
Grammar $\Sigma$ defines a heap containing stream values.
Grammar $V'$ defines the results that can be produced by evaluation, depending on the mode:
\begin{itemize}
\item
@Pure@ computation results are a single value;
\item
@Element@ computation results are stream transformers, which are represented by meta functions that take a value and produces a new value; and
\item
@Aggregate@ computation results consist of an initial (zero) state, an update (konstrukt) meta function to be applied to each stream element and current state, and an eject meta function to be applied to the final state.
\end{itemize}

In the grammar $V'$ we write $\stackrel{\bullet}{\to}$ to highlight that the objects in those positions are meta-functions, rather than abstract syntax. To actually process data from the input table we will need to apply the produced meta-functions to this data.

The judgment form $\SourceStepX{N}{\Sigma}{e}{V'}$ defines a big-step evaluation relation: under evaluation mode $N$ with heap $\Sigma$, expression $e$ evaluates to result $V'$.
The evaluation mode $N$ controls whether pure values should be promoted to element (stream) or aggregate (fold) results. 
We assume that all functions have been inlined into the expression before evaluation.

Rule EVal applies when the expression is already a completed result.
Rule EVar performs variable lookup in the heap.
Rule ELet evaluates the bound expression under the given mode.

% uses the bound expression's type to find the evaluation mode, then evaluates the bound expression under that mode.

% The bound expression's value is added to the heap, and the rest of the expression is evaluated in the original evaluation mode.

Rules EBoxStream and EBoxFold lift constant values to stream results and aggregate results respectively. To lift a constant to a stream result we produce a meta-function that always returns the value. To lift a constant to an aggregate result we set the update meta-function to return a dummy value, and have the eject meta-function return the value of interest.

%   a pure value to a stream and fold respectively, when the evaluation mode is not pure.
% Conversion to a stream transformer ignores the input stream and returns the pure value.
% Conversion to a fold has no state, and the eject function returns the pure value.

Rules EPrimValue, EPrimStream and EPrimFold apply primitive operators to constant values, streams and aggregations respectively. In EPrimStream the result is a new stream transformer that applies the primitive to each of the elements gained from the input streams. In EPrimFold the result consists of new update and eject functions that get their input values by applying the update and eject functions gained by evaluating the arguments.

% For pure values, the values are unboxed and the primitive is applied.
% For streams, a new stream is created and the input heap applied to all streams before applying the primitive.
% For folds, the states of all the argument folds are joined together as tuples.
% At each step, the states of the input folds are updated using their own update function.
% The eject function extracts the ejected values of the input folds, and applies the primitive.

Rule EFilter first evaluates the predicate $e$ to a stream transformer $f$, and the body $e'$ to an aggregation. The result is a new aggregation where the update function applies the predicate stream transformer $f$ to the input element $s$ to yield a boolean flag which specifies whether the current aggregation state should be updated.

Rule EGroup is similar to EFilter, except that the stream transformer $f$ produces group keys rather than boolean flags, and we maintain a finite map of aggregation states for each key. In the result aggregation the update function updates the appropriate element in the map, and the eject function is applied to every accumulator. 

% Rule EFold introduces recursion and memory to the streams.
% It evaluates its initial to a pure value, $z'$, which is used as the initial state for the fold.
% The update expression has mode @Element@, so it must be evaluated to a stream.
% This stream expects the stream element as an argument, but we need to give it the current fold state as well.
% In order to pass both as a pair, we modify all streams in the heap to use the second half of the pair.
% We also add a stream for the fold state to the heap; this uses the first half of the pair.
% The update function then calls the stream transformer with a pair of the state and the input element.
% The eject function is the identity function.

Rule EFold introduces a new accumulator which is visible in the context of the body $k$. Evaluating the body $k$ produces a body stream transformer $k'$ whose job is to update this new accumulator each time it is applied. In the conclusion of EFold we pass this stream transformer a tuple $(v, s)$ where $v$ is the new accumulator and $s$ is the current element of the stream we get from the context of the overall @fold@ expression. The heap used when evaluating $k$ is updated so that references to either the stream elements or new accumulator access the appropriate side of the tuple.

The judgment form $t~|~e~\Downarrow~V$ evaluates an expression over a table input: on input table $t$, aggregate expression $e$ evaluates to value $V$.
The input table $t$ is a map from column name to a list of all the values for that column.
Rule ETable creates an initial heap where each column name $x_i$ is bound to an expression which projects out the appropriate element from a single row in the input table. Evaluating the expression $e$ produces an aggregation result where the update function $k$ accepts each row from the table and updates all the accumulators defined by $e$. The actual computation is driven by the $\mi{fold}$ meta-function.

% column is a stream transformer that pulls out the $n$th element of a nested tuple.
% Tuples are constructed correspondingly, so that each row becomes a nested tuple where the $n$th element contains the value of the $n$th column.

