%!TEX root = ../Main.tex

\eject
% ---------------------------------------------------------
\section{Elements and Aggregates}
To allow incremental computation all Icicle queries must execute in a single pass over the input stream.
Of course, not all queries \emph{can} be executed in a single pass: the key examples are queries that require random access indexing, or otherwise need to access data in an order different to what the stream provides.
However, as we saw in the introduction, although a particular \emph{algorithm} may be impossible to evaluate in a streaming fashion, the desired \emph{value} may well be computable, if only we had a different algorithm.
Here is the unstreamable example from the introduction again:
\begin{code}
  table kvs { key : Date; value : Real }
  query avg = let k = last key
              in  filter (key == k) of mean value;
\end{code}

The problem with this is that the value of @last key@ is only availble once we have reached the end of the stream, but the @filter@ operation needs this value to process the very first element in the same stream.
We distinguish between these two access patterns by giving them different names: we say that @last key@ is an \emph{aggregate}, because to compute it we must have consumed the \emph{entire stream}, whereas the filter predicate is an \emph{element}-wise computation because it only needs access to the current element in the stream.

The trick to compute our average in an incremental fashion is to recognise that @filter@ is selecting a particular subset of values from the input, but the value computed from this subset depends only on the values in that subset, and no other information. Instead of computing the mean of a single subset whose identity is only known at the end of the stream, we can instead compute the mean of \emph{all possible subsets}, and return the required one once we know what that is:
\begin{code}
  table kvs { key : Date; value : Real } 
  query avg = let k    = last  key in
              let avgs = group key of mean value
              in  lookup k avgs
\end{code}

Here we use the @group@ construct to assign key-value pairs to groups as we obtain them, and compute running mean of the values of each group. The @avgs@ value becomes a map of group keys to their running means. Once we reach the end of the stream we will have access to the last key and can lookup the final result.


% ---------------------------------------------------------
\subsection{The Stage Restriction}
To ensure that Icicle queries can be evaluated in a single pass, we use a modal type system inspired by staged computation~\cite{davies2001modal}. We use two modalities, @Element@ and @Aggregate@. Values of type @Element@~$\tau$ are taken from input stream on a per-element basis, whereas values of type @Aggregate@~$\tau$ are available only once the entire stream has been consumed. In the expression @(filter (key == k) of mean value)@, the variable @key@ has type @Element Date@ while @k@ has type @Aggregate Date@. Attempting to compile the unstreamable query in Icicle will produce a type error complaining that elements cannot be compared with aggregates.

Note that the types of pure values such as constants are automatically promoted to the required modality, for example, if we have @open == 1@ and @open : Element Int@ then the constant @1@ is automatically promoted to have type @Element Int@ as well.


% ---------------------------------------------------------
\subsection{Finite Streams and Synchronous Data Flow}
In contrast to synchronous data flow languages such as {\sc Lustre}~\cite{halbwachs1991synchronous}, all streams processed by Icicle are conceptually finite in length. Icicle is fundamentally a query language, which queries finite tables of data held in a non-volatile store, but does so in a streaming manner. Lustre operates on conceptually infinite streams, such as those found in real-time control systems (like to fly airplanes). In Icicle, the ``last'' element in a stream is the last one that appears in the table on disk. In Lustre, the ``last'' element in a stream is the one that was most recently received. If the unstreamable query from \S2 was converted to Lustre syntax then it would execute, but the filter predicate would compare the last key with the most recent key from the stream, which is the key itself. The filter predicate would always be true, and the query would return the mean of the entire stream. Applying the Icicle type system to our queries imposes the natural stage restriction associated with finite streams, so there are distinct ``during'' (element) and ``after'' (aggregate) stages.


% ---------------------------------------------------------
\subsection{Incremental Update}
Suppose we query a large table and record the result. Tomorrow morning we receive more data and add it to the table. We would like to update the result without needing to process all data from the start of the table. We can do this by remembering the values of all intermediate aggregates that were computed in the query, and updating them as new data arrives. In the @avg@ example from \S2 these aggregates are @k@ and @avgs@. 

We can also provide impure contextual information to the query such as the current date, by assigning it an aggregate type. As element-wise computations cannot depend on aggregate computations, we ensure that reused parts of an incremental computation are the same regardless of which day they are executed.


% ---------------------------------------------------------
\subsection{Bounded buffer restriction}
\label{s:IcicleSource:bounded}
Icicle queries process tables of arbitrary size that may not fit in memory. Due to this, each query must execute without requiring buffer space proportional to the size of the input. As a counter example, here is a simple function which cannot be applied without reserving a buffer of the same size as the input:
\begin{code}
    unbounded (xs : Stream Int)
     = zip (filter (> 0) xs) (filter (< 0) xs)
\end{code}

This function takes an input stream @xs@, and pairs the elements that are greater than zero with those that are less than zero.This computation requires an unbounded buffer because if the stream contains $n$ positive values followed by $n$ negative values, then all the positive values must be retained before any output can be produced. 

Icicle is designed so that queries that would require unbounded buffering cannot be written, with one major caveat that we will discuss in a moment. In Icicle, the stream being processed (such as @xs@ above) is implicit in the defined query, and is never named explicitly. Constructs such as @filter@ and @fold@ do not take the name of the stream as an argument, but instead operate on the stream defined in the context. In the example Icicle queries presented so far, the name of the table (stream) is not mentioned in the body of the query, and serves as a comment only. Icicle language constructs describe \emph{how elements from the stream should be aggregated}, but the order in which those elements are aggregated is implicit, rather than being definable by the body of the query. In the expression @filter p of mean value@, the term @mean value@ is applied to stream values which satisfy the predicate @p@, but the values to consider are supplied by the context.

Finally, note that our major caveat is that the @group@ construct we used in \S2 uses space proportional to the number of distinct \emph{keys} in the input stream.
For our applications the keys are commonly company names, customer names, and days of the year.
Our production system knows that these types are bounded in size and that maps from keys to values will fit easily in memory.
Attempting to group by values of a type with an unbounded number of members, such as a @Real@ or @String@ results in a compile-time warning.

% Grouping by types with an unbounded number of members, such as @Real@ or @String@ can be undesirable, and we wish to outlaw this in a future version of our production compiler.

% BEN: "Can be undesirable" is too imprecise. What will happen is that an entry will be added to the map for every key, and if there are more keys than will fit in memory then the query will run out of memory. Surely adding the mentioned warning to the compiler would not be difficult? If it's easy then saying it's done sounds much better than "we intend to". We need to have a solid story about this point. One of the key contributions of Icicle is that it does not require ``unbounded buffering'', but if you're grouping by arbitrary values from the input stream then it clearly does.


\eject
% ---------------------------------------------------------
\section{Source Language}
\label{s:IcicleSource}

\input{figures/Source-Grammar.tex}
\input{figures/Source-Type.tex}
\input{figures/Source-Eval.tex}

The grammar for Icicle is given in Figure~\ref{fig:source:grammar}.
Value types $T$ include numbers, booleans or maps.
Modal types $\TauMode$ include the pure value types, and modalities associated with a value type.
Function types $\TauFun$ include non-function modal types, or a function from modal type to function type.
As Icicle is a first-order language, function types are not value types.

Table definitions $\mi{Table}$ define a table name and the names and types of columns.
Expressions $\mi{Exp}$ can be variable names, constants, applications of primitives or functions.
The @fold@ construct defines the name of an accumulator, the expression for the initial value, and the expression used to update the accumulator for each element of the stream.
The @filter@ construct defines a predicate and an expression to accumulate values for which the predicate is true.
The @group@ construct defines an expression used to determine the key for each element of the stream, and an expression to accumulate the values that share a common key.

$\mi{Prim}$ defines the primitive operators.
$\mi{V}$ defines values.
$\mi{Def}$ contains both function and query definitions.
$\mi{Top}$ is the top-level program, which specifies a table, the set of function bindings, and the set of queries.
All queries in a top-level program process the same table.


% ---------------------------------------------------------
\subsection{Type system}
The typing rules for Icicle are given in Figure~\ref{fig:source:type:exp}.
The judgment form $\Typecheck{\Gamma}{\mi{Exp}}{\TauMode}$ associates an expression $\mi{Exp}$ with its type $M$ under context $\Gamma$.
The judgment form $\TypecheckP{\mi{Prim}}{\TauFun}$ associates a primitive with its function type.
The judgment form $\TypecheckApp{\TauFun}{\ov{\TauMode}}{\TauMode}$ is used for automatically boxing and unboxing modalities in function application: a function type applied to a list of argument value types and modalities results in a single value type and modality.
The judgment form $\TypecheckS{\Gamma}{\mi{Def}}{\Gamma}$ takes an input environment and function or query, and returns an environment containing the function or query name and its type.
Finally, $\TypecheckS{}{\mi{Top}}{\Gamma}$ takes a top-level definition with a table, functions and queries, and returns a context containing only the types of the queries.

Rules TcNat, TcBool, TcMap and TcPair assign types to literal values.
Rule TcVar performs variable lookup in the context.
Rule TcBox assigns a pure expression either @Element@ or @Aggregate@ type. 

% shows that a pure value can be converted to an @Element@ or @Aggregate@, by either replicating it along the stream or returning it at the end of the stream.
% The premise $\tau~\in~T$ requires that $\tau$ is a pure value, rather than an @Element@ or an @Aggregate@.

Rules TcPrimApp and TcFunApp produce the type of the a primitive or function applied to its arguments. Rule TcLet is standard.

% find the result type of primitive and function application.
% They first find the type of the primitive or function, and the types of the arguments, then use the application boxing/unboxing judgment $\TypecheckApp{\TauFun}{\ov{\TauMode}}{\TauMode}$ to find the return type and modality of the application.
% The set-comprehension syntax $\{e_i\}$ means that this rule allows any number of arguments.
% Rule TcLet is a standard let rule, finding the type of the bound expression and inserting it into the context when typechecking the remaining expression.

In rule TcFold the initial value has value type $T$. The type of the current element from the stream is added to the context of $e_k$ as an @Element@, and the result of the overall fold is an @Aggregate@. Rules TcFilter and TcGroup are similar.

% The initial value of the fold must be pure.
% The update has the current value of the fold inserted in its context as an @Element@, and the update must be an @Element@.
% The final return type of the fold is an @Aggregate@.

% Rule TcFilter requires its predicate to be a stream of booleans ($@Element@~\BB$).
% The rest of the filter must be an @Aggregate@; returning an @Element@ stream with a different rate is not allowed, as explained in\sref{s:IcicleSource:bounded}.
% Rule TcGroup is similar to filter, except returning a @Map@.

The rules PrimArith, PrimRel, PrimLookup, PrimFst and PrimSnd assign types to primitives.
Rule AppArgs produces the type of a function or primitive applied to its arguments.
Rule AppRebox is used when the arguments have modal type $m$ --- applying a pure function to arguments of mode $m$ produces a result of the same mode.

Rule CheckFun builds the type of a user defined function, returning it as an element of the output context. Rule CheckQuery is similar, noting that all queries return values of @Aggregate@ type. Finally, rule CheckTop checks a whole top-level program.

% The next judgment shows how function application boxes and unboxes modalities. This judgment takes a function type and all its arguments, and returns the result type of the function.

% Rule AppArgs applies when a function is applied to exactly the right arguments, and simply returns the result of the function.

% Rule AppRebox is used when a pure function is applied to a non-pure value.
% If the arguments and the result type are all pure, then the function can be applied to arguments of a particular modality, and the return type becomes that modality too.
% Note that rule TcBox can also apply implicit boxing here; when only some of the arguments are non-pure, the pure ones can be boxed.
% These rules are tricky to get right; an earlier version allowed applying a modal argument to a pure argument if the return type fitted that mode, which can lead to giving the results of folds as initial values for folds.

% inserts the argument types into the context and returns a new context with the function's type, which is the type of the arguments to the result type.

% Rule CheckQuery checks a query's types, and makes sure it returns an @Aggregate@.

% It first creates a new context with the table columns bound to @Element@s, and typechecks each function.
% Then, each query is checked, with the table columns and all functions available.
% The final returned context is all query names and their types.


% ---------------------------------------------------------
\subsection{Evaluation}
The evaluation rules for Icicle are given in figure~\ref{fig:source:eval}.
Grammar $N$ defines the modes of evaluation, including pure computation.
Grammar $\Sigma$ defines a heap containing stream values.
Grammar $V'$ defines a different type of stream value for each evaluation mode:
\begin{itemize}
\item
@Pure@ computations are represented as a single value;
\item
@Element@ stream transformers are represented as a function applied to each element; and
\item
@Aggregate@ folds are represented as an initial (zero) state, an update (konstrukt) function applied to each stream element and current state, and an eject function applied to the final state.
\end{itemize}


The judgment form $\SourceStepX{N}{\Sigma}{e}{V'}$ defines a big-step evaluation relation: under evaluation mode $N$ with heap $\Sigma$, expression $e$ evaluates to stream value $V'$.
The evaluation mode is used to know when pure values should be converted to streams or folds.
We assume that all functions have been inlined into the expression before evaluation.


Rule EVal applies when the expression is already a stream value.
Rule EVar performs variable lookup in the heap.
Rule ELet uses the bound expression's type to find the evaluation mode, then evaluates the bound expression under that mode.
The bound expression's value is added to the heap, and the rest of the expression is evaluated in the original evaluation mode.

Rules EBoxStream and EBoxFold convert a pure value to a stream and fold respectively, when the evaluation mode is not pure.
Conversion to a stream transformer ignores the input stream and returns the pure value.
Conversion to a fold has no state, and the eject function returns the pure value.

Rules EPrimValue, EPrimStream and EPrimFold evaluate primitive applications.
For pure values, the values are unboxed and the primitive is applied.
For streams, a new stream is created and the input heap applied to all streams before applying the primitive.
For folds, the states of all the argument folds are joined together as tuples.
At each step, the states of the input folds are updated using their own update function.
The eject function extracts the ejected values of the input folds, and applies the primitive.

Rule EFold introduces recursion and memory to the streams.
It evaluates its initial to a pure value, $z'$, which is used as the initial state for the fold.
The update expression has mode @Element@, so it must be evaluated to a stream.
This stream expects the stream element as an argument, but we need to give it the current fold state as well.
In order to pass both as a pair, we modify all streams in the heap to use the second half of the pair.
We also add a stream for the fold state to the heap; this uses the first half of the pair.
The update function then calls the stream transformer with a pair of the state and the input element.
The eject function is the identity function.

Rule EFilter evaluates its predicate to a stream of booleans, and the rest to a fold.
The result is a fold which only applies the update function when the predicate stream is true.

Rule EGroup is rather similar to filter, except that it returns a map.
Here, we start with a map of every key to the fold initialiser.
At every update step, we find the key and look up the current accumulator for that key in the map.
We then apply the update function to the accumulator, and update that key in the map.
For the eject function, we simply apply the eject to each element of the map.

The judgment form $t~|~e~\Downarrow~V$ evaluates an expression over a table input: on input table $t$, aggregate expression $e$ evaluates to value $V$.
The input table $t$ is a map from column name to a list of all the values for that column.
Rule ETable creates an initial heap where each column is a stream transformer that pulls out the $n$th element of a nested tuple.
Tuples are constructed correspondingly, so that each row becomes a nested tuple where the $n$th element contains the value of the $n$th column.

