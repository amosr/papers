%!TEX root = ../Main.tex

\eject
% ---------------------------------------------------------
\section{Elements and Aggregates}

To allow incremental computation, all Icicle queries must execute in a single pass over the input stream. Of course, not all queries can be executed in a single pass: the key examples are anything that require random access indexing, or otherwise need to access data in an order that is different to what the stream will provide. However, as we saw in the introduction, although it my not be possible to evaluate a particular \emph{algorithm} in an streaming fashion, the desired \emph{value} may well be computable, if only we had a different algorithm. Here is the unstreamable example from the introduction:
\begin{code}
  table kvs { key : Text; value : Real }
  query avg = let k = last key
              in  filter (key == k) of mean value;
\end{code}

The problem with this is that the value of @last key@ is only availble once we have reached the end of the stream, but the @filter@ operation needs this value to process the very first element in the same stream. We distinguish between these two access patterns by giving them different names: we say that @last key@ is an \emph{aggregate} as to compute it we need to have consumed the \emph{entire stream}, whereas the filter predicate is an \emph{element}-wise computation that only needs access to the current element read from the stream.

The trick to compute our average in an incremental fashion is to recognise the @filter@ operation is serving to select a particular sub-set of values from the input, but the value computed from this sub-set depends only on the values in that sub-set, and no other information. Instead of computing the mean of a single subset whose identity is only known at the end of the stream, we can instead compute the mean of \emph{all possible subsets}, and return the required one once we know what that is:
\begin{code}
  table kvs { key : Text; value : Real } 
  query avg = let k    = last  key in
              let avgs = group key of mean value
              in  lookup k avgs
\end{code}

Here we use the @group@ construct to assign key-value pairs to groups as we obtain them, and to compute running mean of the values of each group. The @avgs@ value becomes a map of group keys to their running means. Once we have reached the end of the stream we then have access to the last key and can lookup the final result.


% ---------------------------------------------------------
\subsection{The Stage Restriction}
To ensure that Icicle queries can be evaluated in a single pass, we use a modal type system inspired by staged computation~\cite{davies2001modal}. We use two modalities, @Element@ and @Aggregate@. Values of type @Element@~$\tau$ are taken from input stream on a per-element basis, whereas values of type @Aggregate@~$\tau$ are only available once the entire stream has been consumed. In the expression @filter (key == k) of mean value@, the variable @key@ has type @Element Text@ while the variable @k@ has type @Aggregate Text@. Attempting to compile this query in Icicle will produce a type error complaining that elements cannot be compared with aggregates.


% ---------------------------------------------------------
\subsection{Finite Streams and Synchronous Data Flow}
As opposed to synchronous data flow languages such as {\sc Lustre}\cite{halbwachs1991synchronous}, all streams processed by Icicle are conceptually finite in length. Icicle is fundamentally a query language, which queries finite streams of data held in a non-volatile store. In contrast Lustre operates on conceptually infinite streams, such as those found in real-time control systems (like in airplanes). In Icicle, the ``last'' element in a stream is the last one that was in the file read from disk. In Lustre, the ``last'' element in a stream is the one that was most recently received. If the ``unstreamable'' version of the query from \S2 was converted into Lustre then it would execute, but the filter predicate would compare the last key with the most recent key from the stream, which is the key itself. This means the filter predicate would always be true, and the query would return the mean of the entire stream. Applying the Icicle type system to our queries imposes the natural stage restriction associated with finite streams, so there are distinct ``during'' (element) and ``after'' (aggregate) stages.


% ---------------------------------------------------------
\subsection{Incremental Update}

\TODO{Point out that query from S2 can be evaluated incrementally}

The modalities are automatically boxed and unboxed, so that if a function expecting a pure value is passed an @Element@ computation, the result of the function becomes an @Element@ computation too. For example, if @open : Element Int@, then @open == 1@ has type @Element Bool@. @Element@ and @Aggregate@ are mutually exclusive: a computation cannot be both an element and an aggregate.


% The @Element@ modality means that a computation is defined for each record in the table, or element in the stream. Each column in the table is @Element@; for example the @open@ column has type @Element Int@, meaning that for each record in the column there is an @Int@. This can be thought of as being represented by a stream of values.

% The @Aggregate@ modality means that a computation is available only after all records in the table have been seen, or after the end of the stream. These are used for the results of folds. When computing count, the final value is not known until all the records have been seen, so @count@ has type @Aggregate Int@.

% Hopefully our programmer is not too discouraged by the @Element /= Aggregate@ type error, and pushes on. They now know that their query, as formulated, requires multiple passes over the data: the problem now is to reformulate it as a single pass. With a little ingenuity, we can rewrite it as such: we can group by the key and perform the mean for each group. After the group, we can perform a lookup by the most recent key. This requires storing and computing the means for all keys despite only needing one at the end, so we are assuming that the number of keys are bounded in some way.



% ---------------------------------------------------------
\subsection{Bounded buffer restriction}
\label{s:IcicleSource:bounded}
\TODO{Point out that the group uses space proportional to the number of keys in the input, which may be as large as the number of elements in the stream}

As Icicle is designed to be a streaming language, the amount of data to be streamed may not necessarily fit in memory.
Any operation which requires a buffer must be bounded in size, as an unbounded buffer could potentially grow too large to fit in memory.

Here is an example stream program that requires unbounded buffering:
it takes an input stream @xs@, and filters it into those above zero, and those below zero.
These two filtered streams are then joined together pairwise, so the first positive element is paired with the first negative element, and so on.
The program, written in Haskell:

\begin{code}
zip (filter (>0) xs) (filter (<0) xs)
\end{code}

This program requires an unbounded buffer: if the input stream contains ten positive values followed by one negative value, all ten of the positive values must be held onto until the negative value is seen.
Similarly, if the entire stream is positive, all of the elements must be retained until the very end, just in case a negative value shows up.

In Icicle, we outlaw this kind of program by implicitly threading the input stream through operations.
The streams themselves are not materialised in the program: stream operations like @fold@ and @filter@ do not take parameters of the streams, but instead operate on the context stream.
By removing the explicit stream parameter, stream elements can only be joined from the same context, when both elements are available.

For example, in the query @filter p in mean value@, the @mean value@ is only applied to stream values which satisfy the predicate @p@.

This is a different approach than existing synchronous streaming languages\cite{mandel2010lucy} and flow fusion\cite{lippmeier2013data}, which perform clock analysis or `rate inference'.
Here, streams are given clock types denoting when the streams have elements available, and only streams with the same clock can be zipped together.
Filters produce a stream with a different output clock to its input, so different filters cannot be zipped together.
Our system requires no clock analysis, but is less expressive as streams are not `first class'.


\eject
% ---------------------------------------------------------
\section{Source Language}
\label{s:IcicleSource}

\input{figures/Source-Grammar.tex}
\input{figures/Source-Type.tex}
\input{figures/Source-Eval.tex}

The grammar for Icicle is given in figure~\ref{fig:source:grammar}.
Value types are given in $T$ and can be numbers, booleans or maps.
Modal types, $\TauMode$ can be a pure value type, or a modality associated with a value type.
Function types, $\TauFun$, can be either a non-function modal type, or a function from modal type to function type.
As Icicle is a first-order language, function types are not value types.

The table definition in $\mi{Table}$ gives a table name and the names and types of columns.
$\mi{Exp}$ defines the expressions used as query and function bodies.
$\mi{Prim}$ defines the primitive types.
Function and query definitions are given in $\mi{Def}$.
$\mi{Top}$ is the top-level program, which specifies a table, the set of function bindings, and the set of queries.

Expressions can be variable names, primitive operators such as addition and division, function application, let bindings, or query operations.
The query operations can define a fold such as a sum or a count, filtering according to a predicate, or grouping by a key.
Function application $\mi{x~Exp*}$ is the name of a top-level function applied to any number of arguments.
Primitive application $\mi{Prim~Exp*}$ is written prefix, but in the following we use infix-operator short-hand for convenience; for example, @(>) 0 1@ can be written as @0 > 1@.

% Let-bindings allow a name to be used in place of the expression, in the rest of some query.
% \begin{code}
% let diff = open - close
% in  mean diff
% \end{code}

The fold form takes the name of the fold binding, and two expressions: the initial value and the update value for each element.

% Count can be expressed by the following fold:
% \begin{code}
% fold count = 0 then count + 1
% \end{code}

Filters take a predicate, which can be thought of as a stream of booleans, and a query to perform for the satisfying values.

% The following query will count the number of entries where the open price exceeds the close price.
% \begin{code}
% filter open > close in count
% \end{code}

% Filters correspond to @WHERE@ clauses in SQL, except that the predicate does not apply to the entire top-level query, only to the subquery.
% This makes it slightly easier to define queries like the proportion of entities satisfying some predicate to all entities: 
% \begin{code}
% (filter open > close in count) / count
% \end{code}

Group takes a key to group by, and a query to perform on the values of each grouping.

% This query groups the entries into buckets of the difference between open and close, and counts the number of records in each bucket.
% \begin{code}
% group ((open - close) / 100) in count
% \end{code}

$\mi{Def}$ is used for function and query definitions.
% The @count@ function takes no arguments and returns a fold counting the number of elements.
% \begin{code}
% function count
%  = fold c = 0 then c + 1;
% \end{code}

% Sum can be defined taking a single argument, @value@, which is the elements to compute the sum of.
% It returns a fold that starts at zero and for every element, increases the old sum by @value@.
% \begin{code}
% function sum (value : Element Int)
%  = fold s = 0 then s + value;
% \end{code}

% The definition of mean is just the sum divided by the count.
% \begin{code}
% function mean (value : Element Int)
%  = sum value / count;
% \end{code}

% Queries must return a single value, and are given it a name:
% \begin{code}
% query count_all_records = count;
% \end{code}

Finally, $\mi{Top}$ puts all these together with a table definition, function definitions, and query definitions in one place.
All queries here operate over the same input table, and will be fused into a single loop over the input data.


% ---------------------------------------------------------
\subsection{Type system}
The typing rules for Icicle are given in figure~\ref{fig:source:type:exp}.
Judgment $\Typecheck{\Gamma}{\mi{Exp}}{\TauMode}$ means that under context $\Gamma$, the expression has a given value type and modality.
Judgment $\TypecheckP{\mi{Prim}}{\TauFun}$ associates a primitive with its function type.
Judgment $\TypecheckApp{\TauFun}{\ov{\TauMode}}{\TauMode}$ is used for automatically boxing and unboxing modalities in function application: a function type applied to a list of argument value types and modalities results in a single value type and modality.
Judgment $\TypecheckS{\Gamma}{\mi{Def}}{\Gamma}$ takes an input environment and function or query, and returns an environment containing the function or query name and its type.
Finally, $\TypecheckS{}{\mi{Top}}{\Gamma}$ takes a top-level definition with a table, functions and queries, and returns a context containing only the types of the queries.

Rule TcVar performs variable lookup in the context, while TcNat shows that number constants have type $\NN$.

Rule TcBox shows that a pure value can be converted to an @Element@ or @Aggregate@, by either replicating it along the stream or returning it at the end of the stream.
The premise $\tau~\in~T$ requires that $\tau$ is a pure value, rather than an @Element@ or an @Aggregate@.

Rules TcPrimApp and TcFunApp find the result type of primitive and function application.
They first find the type of the primitive or function, and the types of the arguments, then use the application boxing/unboxing judgment $\TypecheckApp{\TauFun}{\ov{\TauMode}}{\TauMode}$ to find the return type and modality of the application.
The set-comprehension syntax $\{e_i\}$ means that this rule allows any number of arguments.

Rule TcLet is a standard let rule, finding the type of the bound expression and inserting it into the context when typechecking the remaining expression.

Rule TcFold finds the type of a @fold@ expression.
The initial value of the fold must be pure.
The update has the current value of the fold inserted in its context as an @Element@, and the update must be an @Element@.
The final return type of the fold is an @Aggregate@.

Rule TcFilter requires its predicate to be a stream of booleans ($@Element@~\BB$).
The rest of the filter must be an @Aggregate@; returning an @Element@ stream with a different rate is not allowed, as explained in\sref{s:IcicleSource:bounded}.
Rule TcGroup is similar to filter, except returning a @Map@.

The rules PrimArith, PrimRel and PrimLookup give function types for each primitive.

The next judgment shows how function application boxes and unboxes modalities.
This judgment takes a function type and all its arguments, and returns the result type of the function.

Rule AppArgs applies when a function is applied to exactly the right arguments, and simply returns the result of the function.

Rule AppRebox is used when a pure function is applied to a non-pure value.
If the arguments and the result type are all pure, then the function can be applied to arguments of a particular modality, and the return type becomes that modality too.
Note that rule TcBox can also apply implicit boxing here; when only some of the arguments are non-pure, the pure ones can be boxed.
These rules are tricky to get right; an earlier version allowed applying a modal argument to a pure argument if the return type fitted that mode, which can lead to giving the results of folds as initial values for folds.



Rule CheckFun inserts the argument types into the context and returns a new context with the function's type, which is the type of the arguments to the result type.

Rule CheckQuery checks a query's types, and makes sure it returns an @Aggregate@.

Finally, rule CheckTop checks a whole top-level program.
It first creates a new context with the table columns bound to @Element@s, and typechecks each function.
Then, each query is checked, with the table columns and all functions available.
The final returned context is all query names and their types.

\subsection{Evaluation}

The evaluation rules for Icicle are given in figure~\ref{fig:source:eval}.

We define simple values $V$ as numbers, booleans, maps of values, or tuples of values.
Next, stream values $V'$ correspond to modalities: pure computations are represented as a single value;
@Element@s as a stream transformer from a heap to a value;
and @Aggregate@s as folds defining an initial state and update and extract functions.

The evaluation rules operate over a slightly modified expression type, $E'$, which is an $\mi{Exp}$ with $V'$ as values instead of just simple values and natural numbers.
This is to simplify typechecking over $V'$, and as $V'$ only appear in restricted form for evaluation.
We also assume that all functions have been inlined before evaluation.

The judgment $\SourceStepX{E'}{V'}$ defines a big-step evaluation relation.

(EVal) applies when the expression is alread a stream value.
This corresponds, roughly, to the (TcNat) typechecking rule.

(EBoxStream) and (EBoxFold) convert a pure value to a stream and fold, respectively.
The stream transformer ignores the input stream and returns the pure value.
The fold has a unit accumulator, and the extract function simply returns the pure value.

Next (EPrimValue), (EPrimStream) and (EPrimFold) evaluate primitive applications.
For pure values, the values are unboxed and the primitive is applied.
For streams, a new stream is created and the input heap applied to all streams before applying the primitive.
Folds are the most complicated: the fold accumulators are tupled together, for example $(\times_i~z_i)$ being the tuple of all the initial accumulators.
At each step, the accumulators for all the input folds are updated with their own update function, and the input heap.
Finally, the extract function extracts the final values of the input folds, and applies the primitive.

The (ELet) rule is fairly standard, evaluating the bound to a value, substituting it in, and evaluating the rest.

(EFold) is one of the most complex rules, as it introduces recursion to the streams.
It evaluates its initial to a pure value, $z'$, which is used as the initial state for the fold.
In the update expression, the fold binding $x$ is substituted with a stream that looks up $x$ in its input heap.
This action-at-a-distance is necessary because the value of $x$ depends on the value of the fold, which is not known yet.
Finally, the return fold is constructed, which binds $x$ to the current fold accumulator.
The extract function for this is the identity, simply returning the accumulator.

(EFilter) evaluates its predicate to a stream of booleans, and the rest to a fold.
The result is a fold which only applies the update function when the predicate stream is true.

(EGroup) is rather similar to filter, except that it returns a map.
Here, we start with an empty map of bottoms.
At every update step, we find the key and look up the current accumulator for that key in the map, or the fold initialiser if it is bottom.
We then apply the update function to the accumulator, and update that key in the map.
For the extract function, we simply apply the extract to each element of the map.

In order to execute these evaluation rules on an actual input table, a few steps are necessary.
First, variables referring to column names such as @open@ or @close@ must have stream values substituted in, so that the actual value will be looked up in the input heap.
For example, $e[@open@~:=~@Stream@~(\lam{\sigma} \sigma~@open@)]$.
Next, the query must be converted to a @Fold@.
Then, for each record, the update function would be called with an input heap binding the record values: $\{@open@ = 1, @close@ = 2\}$ and so on.
This occurs for every record in the table.
Finally, the extract function is called, which gives the result of the query.

