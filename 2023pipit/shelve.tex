%%%%%% BRAKE STUFF

We are interested in verifying an antilock braking system for a motorcycle \cite{huang2010design}.
Antilock brakes are designed to stop wheels from locking up in emergency braking events.
Antilock braking controllers generally work by computing the \emph{wheel slip} for the wheels, which is a ratio of the wheel's rotational speed compared to the vehicle's speed.
To compute the wheel slip, then, the controller must first estimate the vehicle's speed.
When the wheels are travelling freely with no braking pressure and no wheel slip, one can accurately estimate the vehicle's speed by multiplying the wheel rotational speed by the wheel radius.
Unfortunately, once the wheels begin to slip, it becomes harder to accurately estimate the wheel speed.
For this reason, brake controllers often use a combination of sensors.
Some brake controllers \cite{kobayashi1995estimation} incorporate both wheel speed sensors and accelerometer sensors; the readings are combined with a Kalman filter.

\begin{figure}
\begin{tabbing}
  @MM@\= @let @\= \kill
  @let@ veh\_speed\_estimate $\omega_F$ $\omega_R$ $a_z$ = \\
    \> @let@ $v_F$ = $\omega_F \cdot $ radius @in@ \\
    \> @let@ $v_R$ = $\omega_R \cdot $ radius @in@ \\
    \\
    \> @let rec@ $\floor{\hat{v}}$ = @if@ $v_F \approx_\epsilon v_R$ \\
    \> \> @then@ $\min v_F v_R$ \\
    \> \> @else@ $(\xthen{\min v_F v_R}{\xfby{0}{\floor{\hat{v}}}}) + a_z - \epsilon$ @in@ \\
    \> @let rec@ $\ceil{\hat{v}}$ = @if@ $v_F \approx_\epsilon v_R$ \\
    \> \> @then@ $\max v_F v_R$ \\
    \> \> @else@ $(\xthen{\max v_F v_R}{\xfby{0}{\ceil{\hat{v}}}}) + a_z + \epsilon$ @in@ \\
    \\
    \> $(\floor{\hat{v}}, \ceil{\hat{v}})$
\end{tabbing}

\caption{Implementation of \tt{veh\_speed\_estimate}.}\label{f:veh-speed-estimate}
\end{figure}


property ($\blacklozenge_{t} (v_F \approx_{\epsilon} v_R) \implies \lfloor \hat{v}' \rfloor \approx_{t\epsilon} \lceil \hat{v}' \rceil$)



%%%%% MODAL

\begin{tabbing}
  @MM@\= @MMMMMM@ \= \kill
  @let@ sofar ($p$: stream $\BB$): stream $\BB$ = \\
    \> @let rec@ $p'$ $= (\xfby{\top}{p'}) \wedge p$ \\
    \> @in @ $p'$
\end{tabbing}

%%% GRAMMAR

The grammar of Pipit is defined in \autoref{f:core-grammar}.
The expression form $e$ includes standard syntax for values ($v$), variables ($x$) and applications ($e~e'$); however, it does not include any form for defining functions other than reusing closed functions from the \fstar{} meta-language.
Most of the expression forms are equivalent to a simplified, clock-free primitives from standard Lustre-style languages \cite{caspi1995functional}.
The expression syntax for delayed streams ($\xfby{v}{e}$) denotes the previous value of the stream $e$, with an initial value of $v$ when there is no previous value.
Streams can be composed together using the \emph{then} notation ($\xthen{e}{e'}$) which denotes that the value of stream $e$ is used for the very first step, followed by the latest values from stream $e'$ for subsequent steps.

Recursive streams, which can refer to previous values of the stream itself, are defined using the fixpoint operator ($\xrec{x}{e[x]}$); the syntax $e[x]$ means that the variable $x$ can occur in $e$.
To ensure that streams are productive, recursive equations can only refer to their previous values and must be \emph{guarded} by a delay; this restriction is formalised by the causality check in \REF{}.
This form of recursion differs somewhat from standard Lustre, which uses a set of mutually recursive bindings.
In \autoref{ss:operational-semantics} we will see that this form of recursion allows a syntax-directed semantics, but at the cost of potentially duplicating work.

Let-expressions ($\xlet{x}{e}{e'}$) are standard.
Finally, check-expressions ($\xcheck{e}$) are used to describe properties that the program should satisfy.
This operation corresponds roughly to the @assert@ primitive in \fstar{}; however we avoid this name, as @assert@ is historically treated as an unchecked assumption in many Lustre languages.

The grammar for values $v$ includes natural numbers, integers and functions embedded from the \fstar{} meta-language.
We denote functions in the meta-language by the explicit meta-lambda notation ($\mlamX{}$) to avoid any potential ambiguity between Pipit expressions ($e$) and meta-expressions ($\metafy{e}$).

%%% OPERATIONAL SEMANTICS
The operational semantics, expressed as a bigstep relation, are defined in \autoref{f:core-bigstep}.
The judgment form $\bigstep{\Sigma}{e}{v}$ takes a \emph{stream history} ($\Sigma$), which is a non-empty sequence of stores, as well as an expression to evaluate ($e$) and the final value ($v$).

Rule Value denotes that a value evaluates to itself under any streaming history.
Rule Var denotes that evaluating a variable requires looking it up in the right-most (most recent) store; the syntax $\Sigma_\bot; \sigma$ means that this rule applies to any streaming history with one or more steps.
Rule App-Meta allows applying functions on the meta-level; the syntax $(\mlamX{}) v'$ refers to meta-level application of some meta-term.

The rules $\mbox{Fby}_1$ and $\mbox{Fby}_S$ describe the semantics of delayed streams.
Rule $\mbox{Fby}_1$ denotes that when a delay $\xfby{v}{e}$ is evaluated in a context with exactly one step --- that is, at the very start of program execution --- it simply returns the initial value $v$.
Rule $\mbox{Fby}_S$ applies when the same delay is evaluated in a context with strictly more than one step ($\Sigma; \sigma$), in which case, the most recent step is discarded, and the original expression $e$ is evaluated under the previous history.

Next, rules ($\xthenarrow_1$) and ($\xthenarrow_S$) describe the semantics of streams composed by \emph{then}-expressions; as with the rules for delayed streams, the first rule applies when the streaming history contains exactly one step, while the second applies for histories of strictly more than one step.

Rule ($\mu{}$) describes the semantics of recursive streams.
This rule performs a single unfolding of a recursive expression $\xrec{x}{e[x]}$ so that all occurrences of $x$ inside $e$ are replaced with the recursive expression itself.
This rule is not trivially terminating, but so long as any occurrences of the recursive binder are guarded by a delay, then all occurrences of the recursive binder will have a shorter stream history.
This intuition is formalised in \REF{}.

Rule Let uses a standard substitution-based semantics for let-expressions.
Finally, rule Check evaluates a property and requires it to be true ($\top$).

The semantics here, particularly the recursive rule, differ from previous semantics of Lustre.
In the reactive semantics of \citet{caspi1995functional}, as well as the coinductive semantics of VÃ©lus \cite{bourke2017formally} (\CITEME{find best paper}), the semantics for mutually recursive definitions is locally non-deterministic, in that the semantics does not define which particular order mutual definitions are evaluated in.
This local non-determinism complicates certain proofs, even though the overall evaluation \emph{is} deterministic \TODO{vague}.

In contrast, the semantics presented here is syntax-directed and completely deterministic.
We have a mechanised proof of variant of progress theorem for well-formed (\emph{causal}) programs as well as closure under substitution and determinism, which is described in \autoref{ss:meta-theory}.
However, the substitution-based semantics here can duplicate expressions, and encoding mutually recursive definitions requires multiple substitutions.
For this reason, the semantics here is not suitable for actual execution.


%%% TYPING RULES

\subsection{Typing rules}
\label{ss:typing-rules}

The typing rules of Pipit are defined in \autoref{f:core-typing}, with the judgment form $\typing{\Gamma}{e}{\tau}$ that checks expression $e$ under streaming context $\Gamma$.
% The grammar of types (\autoref{f:core-grammar}) distinguishes between bounded-size primitive types ($\primty$) and potentially higher-order types ($\tau$), which allows us to restrict streaming operations to only require bounded buffers.
% \TODO{Not sure if this restriction is useful, as arbitrary functions can still use however much memory and time as they want.}

For values (rule TValue), we reuse the \fstar{} meta-language's typing judgment ($\mtyping{}{v}{\tau}$) for typing closed values $v$.
Otherwise, most of the rules are standard.

%%% META-THEORY


\begin{lemma}[no dependency, no difference]
  If $e$ does not have a direct depend on $x$, then any evaluation of $e$ cannot depend on the current value of $x$.
    
  For all expressions $e$ and well-scoped variables $x$,
  if $\neg \mbox{directly} ~e~ x$ and
  $\bigstep{\Sigma; (\sigma, x \mapsto v_x)}{e}{v}$
  then for any $v_x'$, evaluation is unchanged
  $\bigstep{\Sigma; (\sigma, x \mapsto v_x')}{e}{v}$
  \end{lemma}
  
  We also need:
  \begin{lemma}[Bigstep recursive XMu]
    If a recursive expression $\xrec{x}{e}$ evaluates to some sequence of values $v$, then evaluating the recursive expression doesn't depend on the last value in the sequence:
  
    if $\bigsteps{\Sigma}{\xrec{x}{e}}{v_0 v_1 \cdots v_{n-1} v_n }$
    then for any $v'$,
    $\bigsteps{\Sigma \triangleright^{\uparrow} (v_0 v_1 \cdots v_{n-1} v')}{e}{v_0 v_1 \cdots v_{n-1} v_n}$
  \end{lemma}
  
  % let bigstep_recursive_XMu (#outer #inner: nat) (e: exp)
  %   (streams: C.table (outer + 1) inner)
  %   (vs: C.vector value outer) (v v': value)
  %   (hBSmu: bigstep streams (XMu e) (v :: vs)):
  %     bigstep (C.table_map_append (C.table_of_values (v' :: vs)) streams) e (v :: vs) =
  
  \begin{lemma}[progress]
    if expression is causal, then for any valid stream history it should evaluate to a value:
  
    if $\typing{\Gamma}{e}{\tau}$ and $e \mbox{causal}$ and $\Gamma \vdash* \Sigma$, then exists $v$ such that
    $\bigstep{\Sigma}{e}{v}$ and $\mtyping{}{v}{\tau}$
  \end{lemma}
  
  \begin{lemma}[monotonic progress]
    if an expression $e$ evaluates to a sequence $vs$ under a stream history $\Sigma$ and a new stream store $\sigma$ is valid, then
    there exists some $v'$ such that
    $\bigsteps{\Sigma; \sigma}{e}{vs; v}$
  \end{lemma}
  
  \subsection{Meta-theory}
  \label{ss:meta-theory}
  
  We use a typed representation, which ensures an intrinsic variant of preservation.
  For programs that satisfy the causality restriction, we have proved a variant of the progress theorem.
  
  \begin{code}
  let bigstep_deterministic
    (#streams: list (C.row 'c))
    (#e: exp 'c 'a)
    (#v1 #v2: 'a)
    (hBS1: bigstep streams e v1) (hBS2: bigstep streams e v2):
      Lemma (ensures (v1 == v2)) (decreases hBS1) =
    bigstep_proof_equivalence hBS1 hBS2
  \end{code}
  
  Monotonicity
  
  Substitution-closure
  \begin{code}
  let rec bigstep_substitute_as_var (e p: exp)
    (streams1: C.table outer inner1)
    (streams2: C.table outer inner2)
    (vsp vsep: C.vector value outer)
    (hBSp: bigstep (C.table_map_append streams1 streams2) p vsp)
    (hBSep: bigstep (C.table_map_append streams1 streams2) (subst e inner1 p) vsep):
      Tot (bigstep (C.table_map_append streams1 (C.table_map_append (C.table_of_values vsp) streams2)) e vsep) (decreases hBSep) =
  
  \end{code}
  
  
  
  \section{Proving it with transition systems}
  
  Describe the translation from Pipit expressions to labelled transition systems.
  
  K-induction
  
  Statement of LTS soundness:
  \begin{code}
  let system_eval_complete'
      (#outer: nat) (#vars: nat)
      (e: exp { causal e /\ wf e vars })
      (streams: C.table outer vars)
      (vs: C.vector value outer)
      (hBS: bigstep streams e vs):
        Lemma (exists (s': option (state_of_exp e)).
          system_stepn'
            (system_of_exp e vars)
            (C.Table?._0 streams) vs s') =
      match outer with
      | 0 -> assert
        (system_stepn'
          (system_of_exp e vars)
          (C.Table?._0 streams) vs None)
      | _ -> system_eval_complete e streams vs hBS
  \end{code}
  