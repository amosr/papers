%!TEX root = ../Main.tex
\section{Benchmarks}
\label{s:Benchmarks}
\ben{Use the larger programs as benchmarks, or as running examples. We only need small, simple programs to demonstrate how the algorithm works.}

\begin{figure*}
$$\begin{array}{c}

\begin{tabular}{lrrrrrrrr}
                &   \multicolumn{2}{c}{Unfused}         & \multicolumn{2}{c}{Stream}
                & \multicolumn{2}{c}{Megiddo} &\multicolumn{2}{c}{\textbf{Ours}} \\
                & Time & Loops   & Time & Loops      & Time & Loops & Time & Loops   \\
\hline
Normalize2      & 1.88s & 5      & 1.64s & 4          & 1.82s & 3  & \textbf{1.59s} & \textbf{2}\\
Closest pair    & 3.83s & 6      & 3.33s & 5          & 2.92s & 3  & \textbf{2.92s} & \textbf{3}\\
QuadTree        & 5.22s & 8      & 5.22s & 8          & 4.72s & 2  & \textbf{4.72s} & \textbf{2}\\
\end{tabular}

\end{array}$$
\caption{Benchmark results}
\label{f:BenchResults}
\end{figure*}

Notes:
\begin{itemize}
% \item
% Normalize2 tested with around 1gb input data. This should be small enough that all intermediates fit in memory, but large enough not to fit in cache.
% \item
% ClosestPoints only tested with 80mb data.
\item
In some cases, the clusterings generated by the different methods were the same. In this case, the results are also the same. 
\item
The stream fusion benchmarks use the clustering that stream fusion \emph{would} use, but hand-fused and written in C.
\item
Programs were run five times with the same input data, and the fastest run was used.
\item
ILP solutions were created by hand-fusing based on the clustering of the implementation. In the future, this will be integrated to use data flow fusion.
\item
Benchmark programs are available at \url{https://github.com/amosr/papers/tree/master/2014betterfusionforfilters/benches}
\end{itemize}

\subsection{Example}
To take the normalize2 example, and convert it to combinator normal form:
\begin{code}
 normalize2 :: Array Int -> Array Int
 normalize2 xs
  = let sum1 = fold   (+)  0   xs
        gts  = filter (> 0)    xs
        sum2 = fold   (+)  0   gts
        ys1  = map    (/ sum1) xs
        ys2  = map    (/ sum2) xs
    in (ys1, ys2)
\end{code}

Split:
\begin{code}
split(sum1, gts)    = T
split(sum1, sum2)   = T
split(sum1, ys2)    = T

split(gts, sum2)    = T
split(gts, ys1)     = T

split(sum2, ys1)    = T

split(ys1, ys2)     = T
\end{code}

\begin{tabbing}
MMMMM   \= MMM \= M \= MMM \= M \= MMM \= \kill
Minimise   \>     \> $\Sigma_{(i,j) \in E} W_{ij} x_{ij}$   \\
           \> (if $split(i,j)$)         \\
           \> $+$ \> $\Sigma_{i \in V} N c_i$  \\
Subject to \\
    \> $-N x_{sum1, gts}$
\end{tabbing}



\subsection{Quickhull}
Is Quickhull any better? Seems like it's just one cluster; @filterMax@. And we don't have append (@++@), anyway.
\begin{code}
quickhull :: Vec Pt -> Vec Pt
quickhull pts
 = let top  = fold getTop pts
       bot  = fold getBot pts
       tops = hull (top,bot) pts
       bots = hull (bot,top) pts
   in  tops ++ bots

hull :: (Pt,Pt) -> Vec Pt -> Vec Pt
hull line@(l,r) pts
 = let pts' = filter (above   line) pts
       ma   = fold   (maxFrom line) pts'
       hl   = hull   (l, ma)        as
       hr   = hull   (ma, r)        as
   in  hl  ++ hr
\end{code}
