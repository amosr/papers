%!TEX root = ../Main.tex
\section{Size inference}
Before performing fusion proper, we must infer the relative sizes of each array in the program. We achieve this with a simple constraint based inference algorithm, which we discuss in this section. Size inference has been previously described in the context of array fusion by Chatterjee~\cite{chatterjee1991size}. In constrast to our algorithm, \cite{chatterjee1991size} does not support size changing functions such as filter.

Although our constraint based formulation of size inference is reminiscent of type inference for HM(X)~\cite{odersky1999type}, there are important differences. Firstly, our type schemes include existential quantifiers, which represent the fact that the sizes of arrays produced by filter operations are unknown in general. This is also the case for @generate@, where the result size is data dependent. HM(X) style type inferences uses the $\exists$ quantifier to bind local type variables in constraints, and existential quantifiers do not appear in type schemes. Secondly, our types are first order only, as program graphs cannot take other program graphs as arguments. Provided we generate the constraints in the correct form, solving them is straightforward.


% Our formulation of size inference is very similar to type inference, particularly the exposition of HM(X). First, constraints are generated for the bindings, such as equality among two sizes, the conjunction of two constraints, and existentials. If these constraints can be solved, the equality constraints are used to group the sizes into equivalence classes. Otherwise if the constraints are unable to be solved, the program cannot be assured to require no runtime size checks and will not be fused by our system. After the constraints are generated and solved, each combinator is given an iteration size. Two loops with the same iteration size can be fused together.

% While it \emph{is} technically possible to fuse loops of different sizes, it requires extra complexity to find the maximum of the loop sizes, and additional branches are required to only execute the smaller loop fewer times. For simplicity, we do away with this added complexity and only support fusion of equal sized loops. \emph{Size inference} is performed on the combinators to infer as much information as possible about the sizes of the resulting loops.

% A more in-depth analysis has also been explored by Jay~\cite{jay1996shape} in the form of shape inference, which is built from primitives such as @cons@ and @nil@. Since we have fewer primitives and simpler goals, our size inference does not need to be as complicated as Jay's shape inference.

% The $@map@_n$ combinators require all input arrays to be the same size, and their output is the same. Since @fold@s do not produce arrays, they have no constraints. @gather@ takes two arrays; the data and the indices. Its output size is the size of the indices. The size of a @filter@'s output is most interesting; the exact size is not known until after it has been executed, only that it is less than or equal to the input size. Similarly, the size of @external@ outputs is not known at all, and thus cannot be constrained.


% -----------------------------------------------------------------------------
\begin{figure}
\begin{tabbing}
MMMMMMMM \= MM  \= MM \= MMMMMM \= \kill
\textbf{Size Type}
\> $\tau$   \> @::=@  \> $k$                  \> (size variable)       \\
\>          \> $~|$   \> $\tau \times \tau$   \> (cross product)
\end{tabbing}

\begin{tabbing}
MMMMMMMM \= MM  \= MM \= MMMMMM \= \kill
\textbf{Size Constraint}
\> $C$      \> @::=@  \> $true$               \> (trivially true)      \\
\>          \> $~|$   \> $\tau = \tau$        \> (equality constraint) \\
\>          \> $~|$   \> $C \wedge C$         \> (conjunction)
\end{tabbing}

\begin{tabbing}
MMMMMMMM \= MM  \= MM \= MMMMMM \= \kill
\textbf{Size Scheme}
\> $\sigma$ \> @::=@  
        \> $\forall \ov{k}.~ \exists \ov{k}.~ (\ov{ x : \tau }) \to (\ov{x : \tau})$
\end{tabbing}

\caption{Sizes, Constraints and Schemes}
\label{f:constraints}
\end{figure}


\newcommand{\constr}[1]{\llbracket #1 \rrbracket}


% -----------------------------------------------------------------------------
\subsection{Size types, constraints and schemes}
Figure~\ref{f:constraints} shows the grammar for size types, constraints and schemes. A size scheme is like a type constraint from Hindley-Milner type systems, except that it only mentions the size of each input array, instead of the element types as well.

A size may either be a variable $k$, or a cross product of two sizes. We use the latter to represent the result size of the @cross@ operator discussed in the previous section. Constraints maybe either be trivially $true$, an equality $\tau = \tau$, or a conjunction of two constraints $C \wedge C$. We refer to the trivially true and equality constraints as \emph{atomic constraints}. Size schemes relate the sizes of each input and output array. For example, the size scheme for the @normalize2@ example from Figure~\ref{f:normalize2-clusterings} is as follows:
$$@normalize2@ ~:_s \forall k. (xs : k) \to (ys_1 : k,~ ys_2 : k)
$$

We write $:_s$ to distinguish size schemata from type schemata.

The existential quantifier appears in size schemes when the array produced by a filter or similar operator appears in the result. For example:
\begin{alltt}
   filterLeft \(:\sb{s}\,\forall\,k\sb{1}.\,\exists\,k\sb{2}.\,(xs\,:\,k\sb{1})\;\to\;(ys\sb{1}\,:\,k\sb{1},\,ys\sb{2}\,:\,k\sb{2})\)
   filterLeft xs
     = let ys1 = map (+ 1)   xs
           ys2 = filter even xs
       in (ys1, ys2)
\end{alltt}

The size scheme of @filterLeft@ shows that it works for input arrays of all sizes. The first result array has the same size as the input, and the second has some unrelated size.

Finally, note that size schemes form but one ``layer'' of the type information that would be expressible in a full dependently typed language. For example, in Coq or Agda~\CITE we could write something like:
\begin{alltt}
filterLeft : \(\forall\,k\sb{1}:\,\)Nat\(.\,\exists\,k\sb{2}:\,\)Nat\(.\) 
  Array \(k\sb{1}\) Float \(\to\) (Array \(k\sb{1}\) Float, Array \(k\sb{2}\) Float)
\end{alltt}

However, the type inference systems for fully higher order dependently typed languages typically require quantified types to be provided by the user, and do not perform the type generalization process. In our situation we need automatic type generalization, but for a first order language only.


% -----------------------------------------------------------------------------
\subsection{Constraint Generation}
The rules for constraint generation are shown in Figure~\ref{f:ConstraintGeneration}. The top level judgment ~~$\SizeF{function}{\sigma}$~~ assigns a size scheme to a function. It does this by extracting size constraints and them solving them. This rule, along with the constraint solving process is discussed in the next section. The judgment ~~$\SizeB{\Gamma_1}{zs}{b}{\Gamma_2}{C}$ reads: ``Under environment~$\Gamma_1$, array variable $zs$ binds the result of $b$, producing a new environment $\Gamma_2$ and size constraints $C$''. The remaining judgment that extracts constraints from a list of bindings is similar. The environment $\Gamma$ has the following grammar:
$$
\Gamma~ @::=@ ~~\cdot ~~|~~ \Gamma,~ \Gamma ~~|~~ zs : k ~~|~~ k ~~|~~ \exists k
$$

As usual, $\cdot$ represents the empty environment and  $\Gamma,~ \Gamma$ environment concatenation. The element $zs : k$ records the size $k$ of some array variable $zs$. A plain $k$ indicates that $k$ can be unified with other size types when solving constraints, whereas $\exists k$ indicates a ``rigid'' size variable that cannot be unified with other sizes. We use the $\exists k$ syntax because this variable will also be existentially quantified if it appears in the size scheme of the overall function.

Note that the constraints are generated in a specific form to make the constraint solving process easy. For each array variable in the program we generate a new size variable, like size $k_{zs}$ for array variable $zs$. These new size variables always appear on the \emph{left} of atomic equality constraints. For each array binding we may also introduce unification or rigid variables, and these appear on the \emph{right} of atomic equality constraints.

For example, the final environment and constraints generated for the @normalize2@ example from Section~\ref{s:Introduction} are as follows:
$$
\begin{array}{ll}
       & x : k_{xs},~ gts : k_{gts},~ \exists k_1,~ k_2,~ k_3 
\\
\vdash & true 
        ~\wedge~  k_{gts} = k_1
        ~\wedge~  true
\\     &~~~~~~~~ 
          \wedge~  k_{xs}  ~= k_2
        ~ \wedge~  k_{ys1}  = k_2 
        ~ \wedge~  k_{xs}   = k_3
        ~ \wedge~  k_{ys2}  = k_3
\end{array}
$$


% -------------------------------------------------------------------
\subsection{Constraint Solving and Generalization}
The top-level rule in Figure~\ref{f:ConstraintGeneration} assigns a size scheme to a function by first extracting size constraints, before solving them and generalizing the result. In the rule, the solving process is indicated by $\textrm{SOLVE}$, and takes and environment and constraint, producing a solved environment and constraint. As the constraint solving process is both standard and straightforward, we only describe it informally.

Recall from the previous section that in our generated constraints all the size variables named after program variables are on the left of atomic equality constraints, while all the unification and existential variables are on the right. To solve the constraints we keep finding pairs of atomic equality constraints where the same variable appears on the left, unify the right of both of these constraints, and apply the resulting substitution to both the environment and original constraints. When there are no more pairs of constraints with the same variable on the left then the constraints are in solved form and we are finished.

During constraint solving, all unification variables mentioned in the environment can have other sizes substituted for them. In contrast, the rigid variables marked by the $\exists$ symbol cannot. For example, if we consider the constraints for @normalize2@ mentioned before:
$$
\begin{array}{ll}
       & x : k_{xs},~ gts : k_{gts},~ \exists k_1,~ k_2,~ k_3 
\\
\vdash & true 
        ~\wedge~  k_{gts} = k_1
        ~\wedge~  true
\\     &~~~~~~~~ 
          \wedge~  k_{xs}  ~= k_2
        ~ \wedge~  k_{ys1}  = k_2 
        ~ \wedge~  k_{xs}   = k_3
        ~ \wedge~  k_{ys2}  = k_3
\end{array}
$$

Note that $k_xs$ is mentioned twice on the right of an atomic equality constraint, so we can substitute $k_2$ for $k_3$. Eliminating the duplicates, as well as the trivially $true$ terms then yields:
$$
\begin{array}{ll}
       & x : k_{xs},~ gts : k_{gts},~ \exists k_1,~ k_2 
\\
\vdash & k_{gts} = k_1
        ~\wedge~  k_{xs}  ~= k_2
        ~\wedge~  k_{ys1}  = k_2 
        ~\wedge~  k_{ys2}  = k_2
\end{array}
$$

To produce the final size scheme we lookup the sizes of the input and output variables of the original function from the solved constraints, and generalize appropriately. In this case no rigid size variables appear in the result, so we can universally quantify all of them:
$$@normalize2@ ~:_s \forall k. (xs : k) \to (ys_1 : k,~ ys_2 : k)
$$


\input{figures/Size-env.tex}

% -----------------------------------------------------------------------------
\subsection{Existentially quantified sizes}
\TODO{Describe a well typed example that does a filter, and where the filtered result is returned. Then discuss the two mistyped examples and how our generalization rule rejects them.}


This example is disallowed, as it would require a runtime check on the size of the @flt@ array.
\begin{tabbing}
@MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM@  \= \kill
@bad1 vs@                           \> $\exists k_{vs}.$ \\
@ = let flt   = filter p vs@        \> $\forall k_{flt}.$ \\
@       wrong = map2   f flt vs@    \> $\exists k_{wrong}.\ k_{wrong} = k_{flt}$ \\
                                    \> $\wedge k_{wrong} = k_{vs} \wedge$ \\
@   in  wrong@                      \> $true$
\end{tabbing}
This constraint is invalid, as by transitivity it can be simplified to $\exists k_{vs}.\ \forall k_{flt}.\ k_{vs} = k_{flt}$.
Obviously, there exists no sole size such that all sizes are equal to it.
As a result, no equivalence classes are generated for this example, and no fusion is performed.


Similarly, this example is not allowed, as it would require a runtime check to determine that the output of two filters @flt@ and @flt2@ are the same size.
\begin{tabbing}
@MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM@  \= \kill
@bad2 vs@                           \> $\exists k_{vs}.$ \\
@ = let flt  = filter p  vs@        \> $\forall k_{flt}.$ \\
@       flt2 = filter p' vs@        \> $\forall k_{flt2}.$ \\
@       mix  = map2   f  flt flt2@  \> $\exists k_{mix}.\ k_{mix} = k_{flt}$ \\
                                    \> $\wedge k_{mix} = k_{flt2} \wedge$ \\
@   in  mix@                        \> $true$                               \\
\end{tabbing}
Again, by transitivity of equality this constraint can be simplified to $\forall k_{flt}.\ \forall k_{flt2}.\ k_{flt} = k_{flt2}$.
It is easy to see that this constraint is invalid.

\TODO{Cite work on clock inference for data flow languages. Eg http://www.irisa.fr/prive/talpin/papers/hldvt05.pdf}



\newcommand{\eqclasses}[1]{
    \begin{tabbing}
        MM \= M \= \kill
        #1
    \end{tabbing}}

\newcommand{\eqclass}[2]{$#1$ \> $\in$ \> $\{#2\}$ \\}

% As an example of constraint generation, here is the @normalize2@ program from earlier.
% \begin{tabbing}
% @MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM@  \= \kill
% @normalize2 us@                     \> $\exists k_{us}.$      \\
% @ = let sum1 = fold   (+) 0 us@     \>                      \\
% @       gts  = filter (>0)  us@     \> $\forall k_{gts}.$ \\
% @       sum2 = fold   (+) 0 gts@    \> \\
% @       nor1 = map  (/sum1) us@     \> $\exists k_{nor1}.\ k_{nor1} = k_{us} \wedge$ \\
% @       nor2 = map  (/sum2) us@     \> $\exists k_{nor2}.\ k_{nor2} = k_{us} \wedge$ \\
% @   in (nor1, nor2)@                \> $true$ \\
% \end{tabbing}
% This constraint is valid, with the equivalence classes being:
% \eqclasses{
%     \eqclass{k_{us}}{k_{us}, k_{nor1}, k_{nor2}}
%     \eqclass{k_{gts}}{k_{gts}}
% }


% The next example involves two filters using the same predicate.
% Despite using the same predicate and input data, we produce different output sizes for each filter.
% \begin{tabbing}
% @MMMMMMMMMMMMMMMMMMMMMMMMMMMMMMMM@  \= \kill
% @diff xs@                           \> $\exists k_{xs}.$ \\
% @ = let ys1 = filter p xs@          \> $\forall k_{ys1}.$       \\
% @       ys2 = filter p xs@          \> $\forall k_{ys2}.$       \\
% @   in (ys1, ys2)@                  \> $true$                   \\
% \end{tabbing}
% 
% This constraint is valid, with the equivalence classes being:
% \eqclasses{
%     \eqclass{k_{xs}}    {k_{xs}}
%     \eqclass{k_{ys1}}   {k_{ys1}}
%     \eqclass{k_{ys2}}   {k_{ys2}}
% }




% -----------------------------------------------------------------------------
\subsection{Iteration size}
After the constraints are validated and equivalence classes generated, each combinator is assigned a $size$ as an iteration size -- the number of iterations in the loop required to generate the output.
It is important to note that for filters, the iteration size is not the output size, but is instead the size of the input.
The output size of a filter is, however, a \emph{subsize} of the input's size, as not only is it known to be less than or equal to its input in size, it is also generated depending on the input.
The iteration sizes, $\tau_n$, are used to check whether two loops may be fused.
Any two iteration sizes in the same equivalence class are the same size, and so are fusible.
The difference from previous work is that loops of different iteration sizes \emph{can} be fused, if one is a subsize of the other, and the subsize's \emph{generator} is fused together it as well.
Basically, operations on filtered data can be fused with operations on the original data, if it is fused with the filter as well.
External computations are treated separately, as they cannot be fused with any other nodes.

\begin{tabbing}
MMMMM       \= MM \= MMMMMMMMMMM \= \kill
$T$          \> @::=@ \> $size$                                  \> (known size) \\
             \> $~|$  \> @external@                              \> (external and unfusible) \\
\end{tabbing}

Once the constraints are solved, known to be valid, and sorted into equivalence classes, each combinator is assigned a size.
Note that for a filter, the size of the output array $k_o$ is some existential that is less than or equal to $k_n$, but the actual loop size of the \emph{combinator} is equal to $k_n$.
This is because, in order to produce the filtered output, all elements of the input $n$ must be considered.


\begin{tabbing}
MM \= MM \= MMMMMMMMM \= MMMM \= MM \= \kill
$\tau$  \>$::$\> $binds \rightarrow name \rightarrow T$ \\
\\
$\tau_{bs,o}$    
            \> $|$ \> $o = @fold@~f~n$      \> $\in bs$ \> $=$ \> $k_n$ \\
            \> $|$ \> $o = @map@_n~f~ns$    \> $\in bs$ \> $=$ \> $k_o$ \\
            \> $|$ \> $o = @filter@~f~n$    \> $\in bs$ \> $=$ \> $k_n$ \\
            \> $|$ \> $o = @generate@~s~f$  \> $\in bs$ \> $=$ \> $k_o$ \\
            \> $|$ \> $o = @gather@~i~d$    \> $\in bs$ \> $=$ \> $k_i$ \\
            \> $|$ \> $o = @cross@~a~b$     \> $\in bs$ \> $=$ \> $k_a \times k_b$ \\
            \> $|$ \> $o = @external@~ins$  \> $\in bs$ \> $=$ \> $@external@$ \\
\end{tabbing}

After the generated equality constraints are solved, and sizes are grouped into equivalence classes, the combinators with iteration sizes in the same equivalence class can be fused together.

\subsection{Transducers}
Unlike previous work, we do allow combinators with different iteration sizes to be fused together.
For example, an operation on filtered data may be fused with the filter operation that generates the data, even though the iteration sizes are different.
More generally, if the output size of a combinator is different to its iteration size, it is a \emph{transducer} from the iteration size to the output size.
As usual, a transducer may fuse with other nodes of the same iteration size,
but transducers may also fused with nodes with iteration size the same as the transducer's output size.
For our set of combinators, the only transducer is @filter@.


\begin{tabbing}
MMMM \= MM \= MMMMMMMMM \= MMMM \= MM \= \kill
$trans$  \>$::$\> $binds \rightarrow name \rightarrow \{name\}$ \\
$trans(bs,o)$    \\
            \> $|$ \> $o = @fold@~f~n$      \> $\in bs$ \> $=$ \> $\emptyset$ \\
            \> $|$ \> $o = @map@_n~f~ns$    \> $\in bs$ \> $=$ \> $\bigcup_{x \in ns} trans(bs, x)$ \\
            \> $|$ \> $o = @filter@~f~n$    \> $\in bs$ \> $=$ \> $\{o\}$       \\
            \> $|$ \> $o = @generate@~s~f$  \> $\in bs$ \> $=$ \> $\emptyset$ \\
            \> $|$ \> $o = @gather@~i~d$    \> $\in bs$ \> $=$ \> $trans(bs,i)$ \\
            \> $|$ \> $o = @cross@~a~b$     \> $\in bs$ \> $=$ \> $\emptyset$ \\
            \> $|$ \> $o = @external@~ins$  \> $\in bs$ \> $=$ \> $\emptyset$ \\
\end{tabbing}

%\begin{lemma}
\textbf{Lemma: unique transducers}.
For some bindings $bs$, each name $n$ will have at most one transducer.
\[
valid(\constr{bs}) \implies \forall n.\ |trans(bs, n)| \le 1
\]
\textbf{Proof:} by induction on $bs$. If $n = @map@_n~f~ns$,
then $trans(bs,n) = \bigcup_{x \in ns} trans(bs,x)$.
As @map@ requires its arguments to have the same size, and @filter@ introduces a fresh size for its output,
if any of the $trans(bs,x)$ are non-empty, they will refer to the same @filter@.
The other cases are trivial.
%\end{lemma}

