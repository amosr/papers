%!TEX root = ../Main.tex

\section{Pipit for time-triggered networks}
\label{s:motivation}

\TODO{provide a better description of the TTCAN protocol and driver, as the current one is too terse. It may make sense to move some of the description of the driver from S6 to S2.}

% Pure streaming languages like Lustre lie in an uneasy space somewhere between pure functions and imperative programs.
% Like pure functions, pure streaming languages are equational and support reasoning by unfolding and rewriting.
% Like imperative programs, they describe how state evolves over time.
% Additionally, Lustre programs tend to be composed of many nested recursive loops.
% When verifying both pure and imperative programs, recursion or loops generally require explicit loop invariants.
% Requiring an explicit invariant for each recursive stream quickly becomes unwieldy for Lustre programs.

To introduce Pipit, we consider a driver with a static schedule of \emph{triggers}, or actions to be performed at a particular time; this driver is a simplification of the time-triggered Controller Area Network (CAN) bus specification \cite{fuehrer2001time} which we will discuss further in \autoref{s:evaluation}.
% In this system, time is partitioned into a sequence of \emph{cycles}; at the start of each new cycle, the time is reset to zero.
% Triggers also have a cycle offset and a repeat factor, which together determine the cycles in which the trigger is active.

\subsection{Deferring and proving properties}

The schedule of our time-triggered driver is determined by a constant array of triggers, sorted by their associated time-mark.
The driver maintains an index that refers to the current trigger.
At each instant in time, the driver checks if the current trigger has expired or is inactive, and if so, it increments the index.
We first implement a streaming function \emph{count_when} to maintain the index; the function takes a constant natural number \emph{max} and a stream of booleans \emph{inc}.
At each time step, \emph{count_when} checks whether the current increment flag is true; if so, it increments the previous counter, saturating at the maximum; otherwise, it leaves the previous counter as-is.

\begin{tabbing}
  @MM@\= @MM@ \= \kill
  @let@ count_when ($\textit{max}$: $\NN$) ($\textit{inc}$: stream $\BB$): stream $\NN$ = \\
    \> $@rec@~\rawbind{\textit{count}}{}$ \\
    \> \> $\xcheckP{\PSUnknown}{(0 \le \textit{count} \le \textit{max})}$; \\
    \> \> @let@ $\textit{count'}$ @=@ $(0~@fby@~\textit{count}) + (@if@~\textit{inc}~@then@~1~@else@~0)$ @in@ \\
    \> \> @if @ $\textit{count'} \ge \textit{max}$ @then@ $\textit{max}$  @else@ $\textit{count'}$
\end{tabbing}

The implementation of \emph{count_when} first defines a recursive stream, \emph{count}, which states an invariant about the count before defining the incremented stream \emph{count'}.
Inside \emph{count'}, the syntax $0~@fby@~\textit{count}$ is read as ``the initial value of zero \emph{followed by} the previous count''.

The syntax $\xcheckP{\PSUnknown}{(0 \le \textit{count} \le \textit{max})}$ asserts that the count is within the range $[0, \textit{max}]$.
The subscript $\PSUnknown$ on the check is the \emph{property status}, which in this case denotes that the assertion has been stated, but it is not yet known whether it holds.
A property status of $\PSValid$, on the other hand, denotes that a property has been proved to hold.
These property statuses are used to defer checking properties until enough is known about the environment, and to avoid rechecking properties that have already been proven.
In practice, the user does not explicitly specify property statuses in the source language.
The stated property $(0 \le \textit{count} \le \textit{max})$ is a stream of booleans which must always be true.
% \footnote{We limit our scope to safety properties: in real-time systems, liveness properties tend to be easily restated as bounded liveness properties, which are a form of safety property \cite{manna2012temporal}}
Non-streaming operations such as $\le$ are implicitly lifted to streaming operations, and non-streaming values such as $0$ and $\textit{max}$ are implicitly lifted to constant streams.

We defer the proof of the property here because, at the point of stating the property inside the @rec@ combinator, we don't yet have a concrete definition for the count variable.
In this case, we could have instead deferred the \emph{statement} of the property by introducing a let-binding for the recursive count and putting the @check@ outside of the @rec@ combinator.
However, it is not always possible to defer property statements: for example, when calling other streaming functions that have their own preconditions, it may not be possible to move the function call outside of its enclosing @rec@.
% In such cases, it is necessary to defer the proof of the precondition.

Pipit is an embedded domain-specific language.
The program above is really syntactic sugar for an \fstar{} program that takes a natural number and constructs a Pipit core expression with a free boolean variable.
We will discuss the details of the core language in \autoref{s:core}, but for now we focus on the source program with some minor embedding details omitted.

To actually prove the property above, we use the meta-language \fstar{}'s tactics to translate the program into a transition system and prove the property inductively on the system.
Finally, we \emph{bless} the expression, which marks the properties as valid ($[\PSUnknown := \PSValid]$).
Blessing is an intensional operation that traverses the expression and updates the internal metadata, but does not affect the runtime semantics.

\begin{tabbing}
  @MM@\= @MM@ \= \kill
  @let@ $\mbox{count_when}_{\PSValid}$ ($\textit{max}$: $\NN$): stream $\BB$ $\to$ stream $\NN$ = \\
    \> @let@ $\textit{system} = \mbox{System.translate}_1 (\mbox{count_when}~\textit{max})$ @in@ \\
    \> @assert@ (System.inductive_check $\textit{system}$) @by@ (pipit_simplify ()); \\
    \> $@bless@_1$ $(\mbox{count_when}~\textit{max})$
\end{tabbing}

The subscript 1 in the translation to transition system and blessing operations refers to the fact that the stream function has one stream parameter.
The \emph{pipit_simplify} tactic in the assertion performs normalisation-by-evaluation to simplify away the translation to a first-order transition system; \fstar{}'s proof-by-SMT can then solve the inductive check directly.
% This proof does require some boilerplate; in the future we hope to minimise this.

Callers of \emph{count_when} can now use the validated variant without needing to re-prove the count-range property.
In a dedicated model-checker such as Kind2 \cite{champion2016kind2} or Lesar \cite{raymond2008synchronous}, this kind of bookkeeping would all be performed under-the-hood.
By embedding Pipit in a general-purpose theorem prover, we move some of the bookkeeping burden onto the user; however, we have increased confidence that the compiled code matches the verified code and, as we shall see, we also have access to a rich specification language.
% As an embedded language, we also benefit from writing our programs in a rich metalanguage.

\subsection{The time-triggered system matrix}

The schedule of the time-triggered network is abstractly described by a \emph{system matrix}, consisting of rows of \emph{basic cycles}, columns of \emph{transmission columns}, and cells of optional messages.
Each basic cycle is identified by its cycle index and each transmission column has an associated time-mark.

\autoref{f:tt-systemmatrix-ok} (left) shows an example system matrix with cycles @C0@ and @C1@ and transmission columns at time-marks 0, 1 and 2.
For this example, we assume that one message can be sent per clock cycle. % , though in practice a message could take on the order of ten microseconds
To execute this system matrix, we synchronise the local time to zero at the start of basic cycle @C0@.
After a basic cycle completes, the nodes on the network synchronise before execution continues to the next basic cycle.

\autoref{f:tt-systemmatrix-ok} (right) shows the corresponding configuration for the triggers array.
The enabled set denotes the basic cycles for which a trigger is active.

The system has strict timing requirements which restrict how triggers can be defined.
In this example, each trigger has a unique time; in general, trigger times can overlap, but they need to be enabled on distinct cycles.
Additionally, the schedule must allow sufficient time for the driver to skip over the disabled triggers.
Concretely, we could postpone trigger 1 to send message @B@ at time-mark 2, as triggers 1 and 2 have distinct cycles.
However, we could not bring forward trigger 2 to send message @C@ at time-mark 1: the driver can only process one trigger per tick, and it takes two steps to reach trigger 2 from the start of the array.

\begin{figure}
  \begin{minipage}{0.38\textwidth}
\begin{tabular}{r|ccc}
   & TM0 & TM1 & TM2 \\
  \hline
  C0 & MSG A & MSG B & - \\
  C1 & MSG A & - & MSG C
\end{tabular}
\end{minipage}
\begin{minipage}{0.6\textwidth}
\small
\begin{verbatim}
  0: { time_mark = 0; enabled = {C0,C1}; msg = A; }
  1: { time_mark = 1; enabled = {C0};    msg = B; }
  2: { time_mark = 2; enabled = {C1};    msg = C; }
\end{verbatim}
\end{minipage}
  
\caption{Left: system matrix; right: corresponding triggers array configuration}
\label{f:tt-systemmatrix-ok}
\end{figure}

% The time-marks are strict deadlines on the order of microseconds, which prohibits the driver from looping through the whole array at each time step to find the next active trigger.
% Instead, the driver maintains an index that refers to the current trigger; at each instant in time, the driver checks if the current trigger has expired or is inactive, and if so, it increments the index.
% Multiple triggers can have the same time-mark, as long as they are active in different cycles; triggers that are active on the same cycle must have a sufficiently wide gap in their time-marks to allow the driver time to iterate through the inactive triggers between them and reach the next active trigger before it starts.
% The implementation itself is simple, but formalising exactly what constitutes a ``sufficiently wide gap'' and proving that the schedule is never late requires care.

We impose three restrictions on the triggers array: the time-marks must be sorted; there must be an adequate time-gap between any two triggers that are enabled on the same cycle index; and each trigger's time-mark must be greater-than-or-equal to its index.

With these restrictions in place, we prove a lemma \emph{lemma_can_reach_next}, which states that for all valid cycle indices and trigger indices, if the current trigger is enabled in the current cycle and there is another enabled trigger scheduled to occur somewhere in the array after the current one, then there is an adequate time-gap to allow the driver to skip over any disabled triggers in-between.
These properties are straightforward in a theorem prover, but are difficult to state in a model-checker with a limited specification language.

% \begin{figure}
%   \begin{minipage}{0.38\textwidth}
% \begin{tabular}{r|c}
%    & TM0 \\
%   \hline
%   C0 & MSG A \\
%   C1 & MSG B
% \end{tabular}
% \end{minipage}
% \begin{minipage}{0.6\textwidth}
%   \small
%   \begin{verbatim}
%     { time_mark =  0; enabled = {C0}; msg = A; }
%     { time_mark =  0; enabled = {C1}; msg = B; }
%   \end{verbatim}
%   \end{minipage}
  
% \caption{Invalid trigger configuration}
% \label{f:tt-systemmatrix-bad}
% \end{figure}

\subsection{Instantiating lemmas and defining contracts}
\label{s:motivation:contract}

% The trigger-fetch logic requires such a combination of automatic and manual proofs.
We can now implement the trigger-fetch logic, which keeps track of the current trigger.
The trigger-fetch logic uses the \emph{count_when} streaming function to define the index of the current trigger; we tell \emph{count_when} to increment the index whenever the previous index has expired or is inactive in the current basic cycle.
We simplify our presentation here and only consider a single cycle in isolation: the real system presented in \autoref{s:evaluation} has some extra complexity such as resetting the index, incrementing the cycle index at the start of a new cycle, and using machine integers.

\begin{tabbing}
  @MM@\= @MM@ \= @let index@ \= \kill
  @let@ trigger_fetch ($\textit{cycle}$: $\NN$) ($\textit{time}$: stream $\NN$): stream $\NN$ = \\
    \> $@rec @ \textit{index}.$ \\
    \> \> $@let @ \textit{inc} = \text{false} @ fby @ ((\text{time_mark}~\textit{index}) \le \textit{time} ~\vee~ \neg (\text{enabled}~\textit{index}~\textit{cycle})) @ in@$\\
    \> \> $@let @ \textit{index} = \mbox{count_when}_{\PSValid}~\text{trigger_count}~\textit{inc} @ in@$ \\
    \> \> $\text{pose}_1~(\text{lemma_can_reach_next}~\textit{cycle})~\textit{index}$; \\
    \> \> $\xcheckP{\PSUnknown}{(\text{can_reach_next_active}~\textit{cycle}~\textit{time}~\textit{index})}$; \\
    \> \> $\textit{index}$
\end{tabbing}

The \emph{trigger_fetch} function takes a static cycle index and a stream denoting the current time.
The increment flag and the index are mutually dependent --- the increment flag depends on the previous value of the index, while the index depends on the current value of the increment flag --- so we introduce a recursive stream for the index.
We allow the index to go one past the end of the array to denote that there are no more triggers.

We use the $\textit{pose}_1$ helper function to lift the \emph{lemma_can_reach_next} lemma to a streaming context and instantiate it; the subscript 1 indicates that the lemma is being applied to one streaming argument (the index).
% The lemma requires a non-streaming cycle and a non-streaming index; we apply it to the static cycle and the combinator lifts the application to the streaming index.
% The $\textit{pose}$ function is a helper function implemented using the @check@ and @bless@ functions from earlier.
% The property we state here is that if the trigger at the current index is active, then there is a sufficient time gap to be able to reach the next active trigger after the current index.
We then state an invariant as a deferred property.
Informally, the invariant states that, either the current active trigger is not late, or the next active trigger after the current index is in the future and we can reach it in time.

With the explicitly instantiated lemma, we can prove the streaming invariant by straightforward induction on the transition system.
To help compose this function with the rest of the system, we also abstract over the details of the trigger-fetch mechanism by introducing a rely-guarantee contract for \emph{trigger_fetch}.
The contract we state is that if the environment ensures that the time progresses as expected --- that is, we are called once per microsecond --- then we guarantee that we never encounter a late trigger.

\begin{tabbing}
  @MM@\= @MM@ \= @MMMMMMMMMMMMM@ \= \kill
  @let@ $\text{trigger_fetch}_{\PSValid}$ ($\textit{cycle}$: $\NN$): $\stream \NN \to \stream \NN$ = \\
  \> @let@ $\textit{contract} = \text{Contract.contract_of_stream}_1$ \{ \\
  \> \> @rely@ = $(\lambda \textit{time}.~ \textit{time} = \xfby{0}{(\textit{time} + 1)});$ \\
  \> \> @guar@ = $(\lambda \textit{time index}.~ (\text{index_valid}~\textit{index} \wedge \text{enabled}~\textit{index}~\textit{cycle})$ \\
  \> \> \> $\implies (\text{time_mark}~\textit{index}) \ge \textit{time});$ \\
  \> \> @body@ = $(\lambda \textit{time}.~ \text{trigger_fetch}~\textit{cycle}~\textit{time} );$ \\
  \> \} @in@ \\
  \> @assert@ $(\text{Contract.inductive_check}~\textit{contract})$ @by@ (pipit_simplify ()); \\
  \> $\text{Contract.stream_of_contract}_1~\textit{contract}$
\end{tabbing}

In the implementation of the validated variant of \emph{trigger_fetch}, we first construct the contract from streaming functions.
The $\text{Contract.contract_of_stream}_1$ combinator describes a contract with one input (the time stream), and takes stream transformers for each of the rely, guarantee and body.
The combinator transforms the surface syntax into core expressions.
The assertion $(\text{Contract.inductive_check}~\textit{contract})$ then translates the expressions into a transition system, and checks that if the rely always holds then the guarantee always holds, and that the as-yet-unchecked subproperties hold.
Finally, $\text{Contract.stream_of_contract}_1$ blesses the core expression and converts it back to a stream transformer, so it can be easily used by other parts of the program.

When this function is used in other parts of the program, the caller must ensure that the environment satisfies the rely clause.
In the core language, this is tracked by another deferred property status attached to the contract; we will discuss this further in \autoref{s:core}.
% Deferring the proof of the rely clause is crucial for function calls where satisfying the precondition at a particular point in time somehow depends on the value of the output at a previous step.
% These kinds of self-dependencies and mutual-dependencies are fairly common in Lustre-style programs: for example, \emph{trigger_fetch}'s invocation of \emph{count_when}, whose input $\textit{inc}$ depends on the previous output $\textit{index}$.

The key distinction between these streaming rely-guarantee contracts and imperative pre-post contracts is that the rely and guarantee are both \emph{streams} of booleans, rather than instantaneous predicates.
In this case, the rely $(\textit{time} = \xfby{0}{(\textit{time} + 1)})$ checks that the current time is exactly one microsecond after the time at the previous tick of computation.
Expressing such a rely in an imperative setting requires some extra encoding, as imperative specification languages do not generally have an innate notion of discrete time steps.
