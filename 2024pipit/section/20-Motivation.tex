%!TEX root = ../Main.tex

\section{Pipit for time-triggered networks}
\label{s:motivation}

To introduce Pipit, we consider a \emph{time-triggered} network driver, which has a static schedule dictating the network traffic, and which all nodes on the network must adhere to.
This driver is a simplification of the Time-Triggered Controller Area Network (TTCAN) bus specification \cite{fuehrer2001time} which we will discuss further in \autoref{s:evaluation}.

At a high level, the network schedule is described by a \emph{system matrix} which consists of rows of \emph{basic cycles}.
Each basic cycle consists of a sequence of actions to be performed at specific time-marks.
Actions in the schedule may not be relevant to all nodes; the node's \emph{node matrix} contains only the relevant actions.
The node matrix is represented in memory by a \emph{triggers array} containing triggers sorted by their time-marks; trigger actions include sending and receiving application-specific messages, sending reference messages, and triggering `watch' alerts.
Reference messages start a new basic cycle; a subset of nodes, designated as leaders, send reference messages to synchronise the network.
Watch alerts are generally placed after an expected reference message to signal an error if no reference message is received.

\autoref{f:tt-systemmatrix-ok} (left) shows an example node matrix for a non-leader node.
The matrix consists of two basic cycles C0 and C1 with messages sent at time-marks 0, 1 and 2.
The node expects to receive a reference message at time-mark 7; the watch at time-mark 9 allows a grace period before triggering an error if the reference message is not received.
\autoref{f:tt-systemmatrix-ok} (right) shows the corresponding triggers array.

\begin{figure}
  \begin{minipage}{0.5\textwidth}
% \begin{table}
\resizebox{\textwidth}{!}{
\begin{tabular}{r|ccccc}
   & TM0 & TM1 & TM2 & $\cdots$ & TM9 \\
  \hline
  C0 & SEND A & SEND B & - & $\cdots$ & WATCH \\
  C1 & SEND A & - & SEND C & $\cdots$ & WATCH
\end{tabular}}
% \end{table}
\end{minipage}
\begin{minipage}{0.49\textwidth}
\scriptsize
\begin{verbatim}
 0:{ time = 0; enabled = {C0,C1}; action = SEND(A); }
 1:{ time = 1; enabled = {C0};    action = SEND(B); }
 2:{ time = 2; enabled = {C1};    action = SEND(C); }
 3:{ time = 9; enabled = {C0,C1}; action = WATCH;   }
\end{verbatim}
\end{minipage}

\caption{Left: node matrix; right: corresponding triggers array configuration}
\label{f:tt-systemmatrix-ok}
\end{figure}

The network has strict timing requirements which prohibit the driver from looping through the entire triggers array at each time-mark.
Instead, the driver maintains an index that refers to the current trigger.
At each time-mark, the driver checks if the current trigger has expired or is inactive, and if so, it increments the index.

\subsection{Deferring and proving properties}

We implement a streaming function \emph{count_when} to maintain the index into the triggers array; the function takes a constant natural number \emph{max} and a stream of booleans \emph{inc}.
At each step, \emph{count_when} checks whether the current increment flag is true; if so, it increments the previous counter, saturating at the maximum; otherwise, it leaves the counter as-is.

\begin{tabbing}
  @MM@\= @MM@ \= \kill
  @let@ count_when ($\textit{max}$: $\NN$) ($\textit{inc}$: stream $\BB$): stream $\NN$ = \\
    \> $@rec@~\rawbind{\textit{count}}{}$ \\
    \> \> $\xcheckP{\PSUnknown}{(0 \le \textit{count} \le \textit{max})}$; \\
    \> \> @let@ $\textit{count'}$ @=@ $(0~@fby@~\textit{count}) + (@if@~\textit{inc}~@then@~1~@else@~0)$ @in@ \\
    \> \> @if @ $\textit{count'} \ge \textit{max}$ @then@ $\textit{max}$  @else@ $\textit{count'}$
\end{tabbing}

The implementation of \emph{count_when} first defines a recursive stream, \emph{count}, which states an invariant about the count before defining the incremented stream \emph{count'}.
Inside \emph{count'}, the syntax $0~@fby@~\textit{count}$ is read as ``the initial value of zero \emph{followed by} the previous count''.

The syntax $\xcheckP{\PSUnknown}{(0 \le \textit{count} \le \textit{max})}$ asserts that the count is within the range $[0, \textit{max}]$.
The subscript $\PSUnknown$ on the check is the \emph{property status}, which in this case denotes that the assertion has been stated, but it is not yet known whether it holds.
A property status of $\PSValid$, on the other hand, denotes that a property has been proved to hold.
These property statuses are used to defer checking properties until enough is known about the environment, and to avoid rechecking properties that have already been proven.
In practice, the user does not explicitly specify property statuses in the source language.
The stated property $(0 \le \textit{count} \le \textit{max})$ is a stream of booleans which must always be true.
% \footnote{We limit our scope to safety properties: in real-time systems, liveness properties tend to be easily restated as bounded liveness properties, which are a form of safety property \cite{manna2012temporal}}
Non-streaming operations such as $\le$ are implicitly lifted to streaming operations, and non-streaming values such as $0$ and $\textit{max}$ are implicitly lifted to constant streams.

We defer the proof of the property here because, at the point of stating the property inside the @rec@ combinator, we don't yet have a concrete definition for the count variable.
In this case, we could have instead deferred the \emph{statement} of the property by introducing a let-binding for the recursive count and putting the @check@ outside of the @rec@ combinator.
However, it is not always possible to defer property statements: for example, when calling other streaming functions that have their own preconditions, it may not be possible to move the function call outside of its enclosing @rec@.
% In such cases, it is necessary to defer the proof of the precondition.

Pipit is an embedded domain-specific language.
The program above is really syntactic sugar for an \fstar{} program that takes a natural number and constructs a Pipit core expression with a free boolean variable.
We will discuss the details of the core language in \autoref{s:core}, but for now we focus on the source program with some minor embedding details omitted.

To actually prove the property above, we use the meta-language \fstar{}'s tactics to translate the program into a transition system and prove the property inductively on the system.
Finally, we \emph{bless} the expression, which marks the properties as valid ($[\PSUnknown := \PSValid]$).
Blessing is an intensional operation that traverses the expression and updates the internal metadata, but does not affect the runtime semantics.

\begin{tabbing}
  @MM@\= @MM@ \= \kill
  @let@ $\mbox{count_when}_{\PSValid}$ ($\textit{max}$: $\NN$): stream $\BB$ $\to$ stream $\NN$ = \\
    \> @let@ $\textit{system} = \mbox{System.translate}_1 (\mbox{count_when}~\textit{max})$ @in@ \\
    \> @assert@ (System.inductive_check $\textit{system}$) @by@ (pipit_simplify ()); \\
    \> $@bless@_1$ $(\mbox{count_when}~\textit{max})$
\end{tabbing}

The subscript 1 in the translation to transition system and blessing operations refers to the fact that the stream function has one stream parameter.
The \emph{pipit_simplify} tactic in the assertion performs normalisation-by-evaluation to simplify away the translation to a first-order transition system; \fstar{}'s proof-by-SMT can then solve the inductive check directly.
% This proof does require some boilerplate; in the future we hope to minimise this.

Callers of \emph{count_when} can now use the validated variant without needing to re-prove the count-range property.
In a dedicated model-checker such as Kind2 \cite{champion2016kind2} or Lesar \cite{raymond2008synchronous}, this kind of bookkeeping would all be performed under-the-hood.
By embedding Pipit in a general-purpose theorem prover, we move some of the bookkeeping burden onto the user; however, we have increased confidence that the compiled code matches the verified code and, as we shall see, we also have access to a rich specification language.
% As an embedded language, we also benefit from writing our programs in a rich metalanguage.

\subsection{Restrictions on the triggers array}

Our driver may fall behind when trying to execute certain schedules, as the driver only processes one trigger per time-mark.
To ensure that the schedule can be executed on time, the triggers array must allow sufficient time for the driver to skip over any disabled triggers before the next enabled trigger starts.

Recall our concrete triggers array from \autoref{f:tt-systemmatrix-ok}, which contained trigger 1 (SEND B at time-mark 1 on cycle C0), and trigger 2 (SEND C at time-mark 2 on cycle C1).
We could postpone trigger 1 to send B at time-mark 2, as the corresponding cell in the node matrix is empty.
However, we \emph{cannot} bring the trigger at index 2 forward to send message C at time-mark 1, as it takes two steps to reach trigger 2 from the start of the array.

We impose three restrictions on \emph{valid} triggers arrays: the time-marks must be sorted; there must be an adequate time-gap between any two triggers that are enabled on the same cycle index; and each trigger's time-mark must be greater-than-or-equal to its index, so that it is reachable in time from the start of the array.

With these restrictions in place, we prove a lemma \emph{lemma_can_reach_next}, which states that for all valid cycle indices and trigger indices, if the current trigger is enabled in the current cycle and there is another enabled trigger scheduled to occur somewhere in the array after the current one, then there is an adequate time-gap to allow the driver to skip over any disabled triggers in-between.
These properties are straightforward in a theorem prover, but are difficult to state in a model-checker with a limited specification language.

\subsection{Instantiating lemmas and defining contracts}
\label{s:motivation:contract}

% The trigger-fetch logic requires such a combination of automatic and manual proofs.
We can now implement the trigger-fetch logic, which keeps track of the current trigger.
We use the \emph{count_when} streaming function to define the index of the current trigger; we tell \emph{count_when} to increment the index whenever the previous index has expired or is inactive in the current basic cycle.
We simplify our presentation here and only consider a constant cycle: the real system presented in \autoref{s:evaluation} has some extra complexity such as resetting the index, incrementing the cycle index at the start of a new cycle, and using machine integers.

\begin{tabbing}
  @MM@\= @MM@ \= @let index@ \= \kill
  @let@ trigger_fetch ($\textit{cycle}$: $\NN$) ($\textit{time}$: stream $\NN$): stream $\NN$ = \\
    \> $@rec @ \textit{index}.$ \\
    \> \> $@let @ \textit{inc} = \text{false} @ fby @ ((\text{time_mark}~\textit{index}) \le \textit{time} ~\vee~ \neg (\text{enabled}~\textit{index}~\textit{cycle})) @ in@$\\
    \> \> $@let @ \textit{index} = \mbox{count_when}_{\PSValid}~\text{trigger_count}~\textit{inc} @ in@$ \\
    \> \> $\text{pose}~(\text{lemma_can_reach_next}~\textit{cycle}~\textit{index})$; \\
    \> \> $\xcheckP{\PSUnknown}{(\text{can_reach_next_active}~\textit{cycle}~\textit{time}~\textit{index})}$; \\
    \> \> $\textit{index}$
\end{tabbing}

The \emph{trigger_fetch} function takes a static cycle index and a stream denoting the current time.
The increment flag and the index are mutually dependent --- the increment flag depends on the previous value of the index, while the index depends on the current value of the increment flag --- so we introduce a recursive stream for the index.
We allow the index to go one past the end of the array to denote that there are no more triggers.

We use the $\textit{pose}$ helper function to lift the \emph{lemma_can_reach_next} lemma to a streaming context and instantiate it.
% The lemma requires a non-streaming cycle and a non-streaming index; we apply it to the static cycle and the combinator lifts the application to the streaming index.
% The $\textit{pose}$ function is a helper function implemented using the @check@ and @bless@ functions from earlier.
% The property we state here is that if the trigger at the current index is active, then there is a sufficient time gap to be able to reach the next active trigger after the current index.
We then state an invariant as a deferred property.
Informally, the invariant states that, either the current active trigger is not late, or the next active trigger after the current index is in the future and we can reach it in time.

With the explicitly instantiated lemma, we can prove the streaming invariant by straightforward induction on the transition system.
To help compose this function with the rest of the system, we also abstract over the details of the trigger-fetch mechanism by introducing a rely-guarantee contract for \emph{trigger_fetch}.
The contract we state is that if we are called once per time-mark then we guarantee that we never encounter a late trigger.
% The contract we state is that if the environment ensures that the time progresses as expected --- that is, we are called once per time-mark --- then we guarantee that we never encounter a late trigger.

\begin{tabbing}
  @MM@\= @MM@ \= @MMMMMMMMMMMMM@ \= \kill
  @let@ $\text{trigger_fetch}_{\PSValid}$ ($\textit{cycle}$: $\NN$): $\stream \NN \to \stream \NN$ = \\
  \> @let@ $\textit{contract} = \text{Contract.contract_of_stream}_1$ \{ \\
  \> \> @rely@ = $(\lambda \textit{time}.~ \textit{time} = \xfby{0}{(\textit{time} + 1)});$ \\
  \> \> @guar@ = $(\lambda \textit{time index}.~ (\text{index_valid}~\textit{index} \wedge \text{enabled}~\textit{index}~\textit{cycle})$ \\
  \> \> \> $\implies (\text{time_mark}~\textit{index}) \ge \textit{time});$ \\
  \> \> @body@ = $(\lambda \textit{time}.~ \text{trigger_fetch}~\textit{cycle}~\textit{time} );$ \\
  \> \} @in@ \\
  \> @assert@ $(\text{Contract.inductive_check}~\textit{contract})$ @by@ (pipit_simplify ()); \\
  \> $\text{Contract.stream_of_contract}_1~\textit{contract}$
\end{tabbing}

In the implementation of the validated variant of \emph{trigger_fetch}, we first construct the contract from streaming functions.
The $\text{Contract.contract_of_stream}_1$ combinator describes a contract with one input (the time stream), and takes stream transformers for each of the rely, guarantee and body.
The combinator transforms the surface syntax into core expressions.
The assertion $(\text{Contract.inductive_check}~\textit{contract})$ then translates the expressions into a transition system, and checks that if the rely always holds then the guarantee always holds, and that the as-yet-unchecked subproperties hold.
Finally, $\text{Contract.stream_of_contract}_1$ blesses the core expression and converts it back to a stream transformer, so it can be easily used by other parts of the program.

The key distinction between our streaming rely-guarantee contracts and imperative pre-post contracts is that the rely and guarantee are both \emph{streams} of booleans, rather than instantaneous predicates.
In this case, the rely $(\textit{time} = \xfby{0}{(\textit{time} + 1)})$ checks that the current time is exactly one time-mark after the time at the previous \emph{tick} of computation.
Expressing such a rely in an imperative setting would require extra encoding, as preconditions in imperative languages do not generally have an innate notion of the previous value with respect to a global shared clock.

When \emph{trigger_fetch} is used in other parts of the program, the caller must ensure that the environment satisfies the rely clause.
In the core language, this is tracked by another deferred property status attached to the contract; we will discuss this further in \autoref{s:core}.
% Deferring the proof of the rely clause is crucial for function calls where satisfying the precondition at a particular point in time somehow depends on the value of the output at a previous step.
% These kinds of self-dependencies and mutual-dependencies are fairly common in Lustre-style programs: for example, \emph{trigger_fetch}'s invocation of \emph{count_when}, whose input $\textit{inc}$ depends on the previous output $\textit{index}$.
