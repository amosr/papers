%!TEX root = ../Main.tex
\section{Related work}

Existing systems for combinator fusion only support a subset of combinators, and only in limited cases.
Pull fusion supports joins where one combinator pulls from multiple inputs, but not splits where one output is used my multiple combinators.
Pull can thus express @merge@, but not @partition@.
Push fusion supports splits (@partition@), but not joins (@merge@).
Polarised fusion~\cite{lippmeier2016polarized} addresses these shortcomings by separating the computation into pull producers and push consumers, with explicit drain loops to convert between the two sections. However this requires manual plumbing.

The duality between pull and push arrays has also been explored in Obsidian by \citep{claessen2012expressive} and later in \citep{svensson2014defunctionalizing}, by explicitly separating the types of pull and push arrays.
Here the distinction is made for the purpose of code generation for GPUs rather than fusion, as operations like append on pull arrays require conditionals inside the loop, whereas using push arrays moves these conditionals outside the loop.
% Here push arrays are `defunctionalized' and represented as a datatype containing the combinator and its arguments, which allows specialised and efficient code generation.
% However this work only supports a limited number of baked-in push combinators such as append, mapping, interleaving and reversing.

Streaming IO libraries have blossomed in the Haskell ecosystem, generally based on Iteratees \cite{kiselyov2012iteratees}.
Libraries such as @conduit@ \cite{hackage:conduit}, @enumerator@ \cite{hackage:enumerator}, @machines@ \cite{hackage:machines} and @pipes@ \cite{hackage:pipes} are all designed to write stream computations with bounded buffers.
However, these libraries are not designed for absolute performance and programs tend to be written to operate over streams of chunks rather than streams of values.
For the most part they support only simple straight-line computations.

Another way to characterise fusion systems is whether they are \emph{local} (shortcut) or \emph{global} fusion.
Local fusion systems such as stream fusion~\cite{coutts2007stream} use local rewrite rules to remove intermediate arrays, and tend to rely on general purpose compiler optimisations to expose opportunities for these rewrites to occur.
Generally, the local rewrite rule can only be applied once the producer has been inlined into the consumer.
Because of the local nature of these rewrites and the reliance on inlining, local fusion can only perform producer-consumer fusion with a single consumer, as inlining the producer into multiple consumers would duplicate work.
Local fusion is fragile because heuristics are used to determine whether inlining occurs~\cite{lippmeier2013data}.
This fragility poses serious problems to programmers who require fusion for adequate performance, as one must have deep knowledge of the internal compiler phases and library design in order to predict whether fusion will occur -- or worse yet, they must scour the intermediate code to count the number of loops produced. 
In contrast, global fusion systems such as those traditionally used in imperative compilers make use of specific optimisations which must be implemented separately, but are able to perform horizontal fusion and are less prone to the fragility of local fusion.

This local/global distinction is not a hard classification, as some systems fit somewhere in between.
For example, {\bf strymonas}~\cite{kiselyov2016stream} uses staged compilation for introspection of the code and to ensure appropriate inlining, but only performs producer-consumer fusion with a single local rule.
While not explicitly mentioned in the paper, Kiselyov et al~\cite{kiselyov2016stream}'s {\bf strymonas} system only allows streams to be used once.
Furthermore, the entire stream computation must be terminated with a single fold which takes a single stream.
This means multiple outputs with different rates cannot be treated, for example @partition@ which returns multiple arrays filtered with different predicates.

This innocent-looking yet useless program, which should pair each line with itself, actually pairs each line with the successive line.
\begin{code}
let lines = linesFromFile filename
in  zip lines lines
\end{code}

One would expect the above program to have the same behaviour as the following - or at least produce an error otherwise:
\begin{code}
zip (linesFromFile filename) (linesFromFile filename)
\end{code}

The one feature they support that we do not is concatMap/flatMap, which concatenates all produced substreams.
This is a limitation in the \emph{conversion} to process calculus, not in the process calculus itself.
Our process calculus can handle concrete instantiations of concatMap when specialised to a particular subprocess, but not the general case where the subprocess is statically unknown.
By using a staging restriction as they do, we could modify the conversion to create a specialised version of concatMap for the given argument.


\subsection{The problem with synchronised product}
\label{s:Synchro}
Related work on Network Fusion~\cite{fradet2004network} allows fusion of Kahn Process Networks using synchronised product to fuse pairs of processes together.
Synchronised product is: both machines can take independent steps so long as it is not in the alphabet of the other, but have to agree on any shared actions.
So if both machines pull from @xs@, the @pull xs@ message can only be executed when both machines agree.

This sort of coordination is a bit too coarse and causes deadlocks.
This example cannot be fused by synchronised product: one zip is trying to pull from @as@ and the other from @bs@, but neither can proceed without the other.
Note that while this contrived example is unlikely to be written by hand, it is plausible that it would be part of a larger program after inlining has occurred.

\begin{code}
zips :: [a] -> [b] -> [a*b] * [b*a]
zips as bs =
  let abs = zip as bs
      bas = zip bs as
  in  abs, bas
\end{code}

When stream programs are encoded as labelled transition systems, some fusion can be done by computing the synchronised product of two transition systems, but this suffers deadlock when the two programs share multiple inputs and read them in different orders.
By annotating transition states with the status of each input channel, our fusion algorithm works for these cases where synchronised product does not.


% After inlining the definition of zip, we have:
% \begin{code}
% zips :: [a] -> [b] -> [a*b] * [b*a]
% zips as bs =
%   let abs = process abs.
%        let loop1 =
%           a <- pull as
%           b <- pull bs
%           push abs (a,b)
%           drop as
%           drop bs
%           jump loop1
%        in jump loop1
%       bas = process bas.
%        let loop2 =
%           b <- pull bs
%           a <- pull as
%           push abs (b,a)
%           drop bs
%           drop as
%           jump loop2
%        in jump loop2
%   in  abs, bas
% \end{code}
% 
% Here, in order to compute the synchronised product of these two, we need to know which are the common or shared actions.
% Shared are: @pull as@, @pull bs@, @drop as@ and @drop bs@.
% So both processes have to execute these together: if one wants to @pull as@, it can only act when the other one wants to @pull as@ as well.
% Thus, the two machines are deadlocked, waiting for the other one to agree.
% 
% For this case, a simple solution suffices to fix this: adding extra processes for splits. So we would add a new combinator @dup@ which takes one input stream and creates two output streams. It reads a single element from the input and pushes it to both outputs.
% 
% \begin{code}
% dup = stream_1_2 \is ols ors.
%   letrec
%     p1   = pull is p2
%     p2 i = push ols i (p3 i)
%     p3 i = push ors i p4
%     p4   = drop is p1
%   in p1
% \end{code}
% And the modified zip uses this like so:
% 
% \begin{code}
% zips :: [a] -> [b] -> [a*b] * [b*a]
% zips as bs =
%   let as1, as2 = dup as
%       bs1, bs2 = dup bs
%       abs = zip as1 bs1
%       bas = zip bs2 as2
%   in  abs, bas
% \end{code}
% 
% This has removed the deadlock, allowing a trace such as:
% \begin{code}
% as, as1, bs, bs1, bs2, as2
% \end{code}
% 
% However it is not hard to modify the program so that the deadlock still exists.
% By changing the each zip to pull from @as2@ and @bs2@ first, the streams are still used linearly, but deadlock occurs as @as1@ cannot be produced until after @bs2@ has been consumed, and vice versa.
% \begin{code}
% zips :: [a] -> [b] -> [a*b] * [b*a]
% zips as bs =
%   let as1, as2 = dup as
%       bs1, bs2 = dup bs
%       abs = zip as2 bs1
%       bas = zip bs2 as1
%   in  abs, bas
% \end{code}
% 
% Using @dup@ we can concoct a simpler example with two processes and one input stream where synchronised product deadlocks.
% \begin{code}
% zipself :: [a] -> [a*a]
% zipself as =
%   let as1, as2 = dup as
%       aas = zip as2 as1
%   in  aas
% \end{code}
% Here @dup@ is attempting to push to @as1@, but cannot until @zip@ pulls, while @zip@ is attempting to pull from @as2@, which cannot proceed until the @dup@ pushes.


\subsection{Scratch: dataflow}
Synchronous languages (LUSTRE, Lucy-n, SIGNAL) view streams as -- abstractly -- functions from time to values.
(Or time to maybe values, if they allow holes).
Synchrony is described as ``time advances in lockstep with one or more clocks'' \cite{benveniste2003synchronous}.
This forces them into an inherently \emph{push} based system, but what is pushing here is the procession of time.
If you have two streams, you cannot pull from one and the other: when time advances, it advances for all streams.
Thus, synchronous languages cannot encode value-dependent pulling - nor can they encode append.
Append could be seen as a special kind of value-dependent access pattern, if you treat the end of the stream as a special kind of value.

Contrast between our case, where we have \emph{active} processes which perform the pulling and pushing, with synchronous cases which are more passive, in that they don't request input - the values trickle in from outside.


Non-synchronous streaming languages, such as Lucid, may allow some kind of value-dependent pulling, because they do not enforce causality.
However, they rely on dynamic scheduling.

Do not to confuse regular dataflow, also known as \emph{synchronous data flow}, with synchronous languages.
Regular dataflow graphs are dataflow graphs where each edge is annotated with the rate.
The closest thing to fusion in dataflow computation is static scheduling, where the order in which different actors are fired at runtime is chosen statically.
This is somewhat similar to fusion, in fusion we are also interested in merging the separate actors into a single one that computes them all.
Choosing a static schedule is required to fuse actors together, but it alone is not fusion.
In our system, we are performing both static scheduling and fusion at the same time.

Dataflow languages:
\begin{itemize}
\item Lucid Synchrone
``takes advantage of the (first-order) functional aspect of Lustre so as to generalize it to higher order constructs in an ML-like style. In particular, the Lustre clock calculus is extended and inferred as an ML-type system.'' \cite{benveniste2003synchronous}
\item LUSTRE \cite{halbwachs1991synchronous}.
Dataflow language: causal analysis, clock calculus, synchronous.
Uses more or less syntactic equality to check equivalence of clocks.
\item Lucy-n: extension of LUSTRE with periodic clocks to ensure static scheduling \cite{mandel2010lucy}
\item SIGNAL \cite{le2003polychrony}
causal, clocks, synchronous
\item StreaMIT \cite{thies2002streamit}:
Regular/synchronous dataflow, ie statically known rates.
Only allows limited splits and joins: round robin and duplication for splits, round robin and combination for joins. 
Does not support fully general graphs - instead using combinators to introduce a (split/join) and a combinator for a feedback loop.
\item Ptolemy (II)
\end{itemize}

Models:
\begin{itemize}
\item Synchronous dataflow (SDF):
all rates are statically known,
\item Cyclo-static dataflow (CSDF) where the number of produced/consumed tokens varies periodically, sounds very similar to Lucy-n's periodic clocks \cite{mandel2010lucy}
\item Boolean dataflow (BDF), generally undecidable to statically schedule, so must fall back to dynamic scheduling \cite{buck1993scheduling}
\item Integer dataflow (IDF), (also falls back to dynamic) \cite{buck1994static}
Clustering to find control structure: tries to recover structures like ifs, cases and loops from the dataflow graph.
Extends previous BDF \cite{buck1993scheduling} with loops that repeat some number of times, and multi-way ifs.
Very rigid and only supports limited control flow structures.
Unclear how a merge or append would be clustered by this system.
\item Parameterized dataflow (PDF),  \cite{bhattacharya2001parameterized}
\item Schedulable parametric dataflow (SPDF),  \cite{fradet2012spdf}
\item Scenario aware dataflow (FSM-SADF) \cite{stuijk2011scenario}
Somehow use a separate finite state machine, which can control the rates of dataflows.
Apparently more expressive/succinct than boolean dataflow (BDF) but also easier to analyze.
`General SADF' must fall back to runtime scheduling, while FSM-SADF can be done statically.
In FSM-SADF, however, the currently executing scenario can only be switched in between iterations of the whole graph.
So after the whole graph executes one scenario, the FSM is used to find the next scenario to execute.
This means that the currently executing scenario cannot depend on values read during the current scenario - which rules out paritioning, for example, because the choice of whether to emit on the true or false branch cannot be made until after the value has been emitted.
It is possible to indirectly encode this by storing the value to emit in a buffer, and deferring the emit until next scenario - however this loses locality benefits of fusion.
General SDF could describe a partition, but uses runtime scheduling.
The focus is more about analysing worst-case execution time in order to ensure real time deadlines can be met \cite{van2015scenario}.

Basically each node of the FSM is a dataflow graph. After the current dataflow graph is executed, the FSM can take a step based on the output of that graph. Then the graph at the new node is executed, and so on.
Because the FSM is separate to the dataflow graph, it is not as composable as a combinator-based approach: adding the equivalent to a new combinator could require modifying many of the dataflow graphs, and the FSM, in non-trivial ways.
\end{itemize}

Dataflow languages tend to fall back on less performant dynamic scheduling, when programs cannot be statically scheduled.
For example \citet{bouakaz2013real} uses static scheduling for special cases like cyclo-static dataflow graphs, but otherwise uses dynamic earliest deadline first (EDF) scheduling.

When dataflow languages talk about a `merge' operator, they are talking about \emph{non-deterministic merge}. These are not Kahn processes.
