%!TEX root = ../Main.tex
\section{Processes}
\label{s:Processes}


\input{figures/ProcessDef.tex}

The grammar for processes is shown in figure~\ref{fig:Process:Def}.
Channels, labels and variables are specified by some external, globally unique set of names.
We assume that values and expressions are specified externally to the core calculus.
The actual details of the external computation are not important, except that there should be an evaluation form taking a heap and an expression and producing a value, as well as some way to destruct booleans.

\TODO{Settle on a terminology for channels / streams. Are both necessary?}
Streams are the abstract data flowing through while channels are particular endpoints, so a stream can have multiple channels.
A stream can have at most one output channel, and any number of input channels.

A process defines a stream computation, taking any number of input streams and producing at least one output stream.
Processes have an optional name in parentheses used only for decsriptive purposes, and does not need to be unique.
The input streams are paired with an input state which is used for coordinating multiple processes during evaluation; in process definitions before any evaluation has occurred this should be @none@.
The input states are explained in detail later in \S\ref{s:Process:Eval}.

The output streams are in some sense ``owned'' by the process that produces them.
While a stream may be consumed by any number of processes, each stream can only appear as the output for one process.
This ensures a sort of determinism in the scheduling of multiple processes; if different processes could push to the same stream, the order of values would depend on the scheduled order.
A process may, however, produce multiple output streams.

The heap is used for evaluation - it is used when evaluating the external value calculus.
Each process has its own private heap, meaning that the only communication between processes occurs by streams.

The label is the current block, and each block is the instruction to be executed in the current state.
Instructions can pull from a stream, drop an already pulled value, push a value, perform an if/case analysis on a boolean, or perform an internal jump.

Pulling from a stream is blocking, and as usual with Kahn processes~\cite{kahn1976coroutines}, there is no way to tell whether a stream currently has a value.
Pull takes as arguments the channel to read from, the variable to put the read value in, and the next label state to jump to after a successful pull.

After values have been pulled, they must be disposed of with @drop@.
This has no real evaluation semantics other than for coordination between processes.

All instructions take as an argument the next label state to jump to, which includes any variable updates that should be performed on the private heap at the same time.
Combining variable update with stream instructions simplifies the fusion process in~\S\ref{s:Fusion}, as some parts of fusion need to perform both at once.


A process network is a set of multiple processes that can be evaluated concurrently.
The intersection of all process outputs should be empty - there should be no overlap.
Any inputs that are not mentioned as outputs of processes are assumed to be external inputs - their values will be provided by the environment.
Processes form the essence of stream computation, and a single process can be given a straightforward sequential semantics by mapping to an imperative language.
By fusing multiple processes into a single one, we are effectively giving a sequential interpretation for concurrent processes.


\subsection{Map/map}
\label{s:Process:MapMap}

One of the simplest combinators is @map@.
This might need to go elsewhere.
As well as needing a better example than map/map.
Let's start with the process definition for @map@.
The inputs here is actually a map with @as=none@, but we leave the value off when it is @none@.
The next labels for the instructions are also shortened as @map0@ instead of writing the empty heap update afterwards.
Mention that the initial heap has the names but no values, but they could be initialised to whatever.
It doesn't matter since they'll be written before anything is read.

\begin{code}
map f = process (map f)
     ins: as
    outs: bs
    heap: {a = 0}
   label: map0
  blocks: map0 = pull as    a  map1
          map1 = push bs (f a) map2
          map2 = drop as       map0
\end{code}

As well as a ``combinator network'', a function comprised exclusively of process combinators.
The input streams are supplied as arguments, and output streams as return values.
\begin{code}
mapMap f g xs
 = let ys = map f xs
       zs = map g ys
   in  zs
\end{code}

It is not hard to assume that, given the process definitions and a combinator network, we can produce a process network.
This is simple enough for a paragraph prose description.
It's just a bit of inlining and renaming everything to be unique.

\begin{code}
process (map f)
     ins: xs
    outs: ys
    heap: {x}
   label: p0
  blocks: p0 = pull xs    x  p1
          p1 = push ys (f x) p2
          p2 = drop xs       p0
process (map g)
     ins: ys
    outs: zs
    heap: {y}
   label: q0
  blocks: q0 = pull ys    y  q1
          q1 = push zs (g y) q2
          q2 = drop ys       q0
\end{code}

Now we can perform some kind of fusion on this network, resulting in one process that computes, as output, both @ys@ and @zs@.
Later, when producing imperative code for this, the output pushes to @ys@ can be ignored and changed to jumps, as the original combinator network did not return them.

\begin{code}
process (map f / map g)
     ins: xs
    outs: ys zs
    heap: {x, y, _ys}
   label: p0q0
  blocks: p0q0            = pull xs    x  p1q0
          p1q0            = push ys (f x) p2q0-pending-ys { _ys = f x }
          p2q0-pending-ys = drop xs       p0q0-pending-ys
          p0q0-pending-ys = jump          p0q1-have-ys    { y = _ys }
          p0q1-have-ys    = push zs (g y) p0q2-have-ys
          p0q2-have-ys    = jump          p0q0
\end{code}

\subsection{Evaluation}
\label{s:Process:Eval}

\input{figures/ProcessEval.tex}
\input{figures/ProcessFeed.tex}

We use the ``inject and shake'' method of evaluation. (This isn't a real thing.)

Rules in figure~\ref{fig:Process:Eval:Inject} are about injecting values into a process; these are the values used when the process performs a @pull@.
The injected values may be pushed values from other processes for internal streams, or may come from an external source for the overall network's input streams.
For the map/map example, the values for @xs@ would be injected externally, but the values for @ys@ will be injected into the second process from the first process.
Injection is just about orchestrating values between processes, and no actual computation happens here; it just makes values available to be pulled.

Injection can only happen when a process is ready to receive more input.
A process has a single element buffer for each input, stored in its input state.
This can be either @none@ meaning an empty buffer, @pending@ meaning a single value has been added to the buffer but has not been read yet, or @have@ meaning the value was added and in the process of being used.

(InjectValue) allows a value to be injected only when the input state is @none@, meaning the buffer is empty.
An attempt to inject a value while the buffer is @pending@ or @have@ would require an unbounded (or at least multiple element) buffer.
Injecting the value puts the value as @pending@ in the buffer.

(InjectIgnore) allows processes that do not use a particular input stream to ignore an injected input.

(ProcessesInject) performs injection over a process network.
Every process in the network must have the value injected into it.
This means if multiple processes read from that stream, all input buffers for that stream must be empty.

The rules in figure~\ref{fig:Process:Eval:Shake} are the `shake' part of evaluation, where actual computation occurs. 
As usual, $\alpha$ denotes the message type, with $\tau$ being an internal message. The \Push~ message is a single value being output on a channel.


The judgment form for shaking a single instruction $\ProcBlockShake{b}{i}{\Sigma}{\alpha}{l'}{i'}{u'}$
executes an instruction $b$ with the input states $i$ and the heap $\Sigma$.
The output message $\alpha$ can be an internal state change or an emitted value.
The result also has the new label, the new input state buffers, and the substitution to apply to the heap.

The two judgment forms for shaking processes are $\ProcShake{p}{\alpha}{p'}$ and $\ProcsShake{\sgl{p}}{\alpha}{\sgl{p}}$.
The process shaking just shakes a single instruction and updates the process.
Shaking a process network chooses a single process to shake, then if the result is an emitted value, that value is injected into all the other processes in the network.

(Pull) takes an already injected value from the input buffer, which changes its state from @pending@ to @have@.
The result substitution sets the variable to the pulled value, as well as any substitutions in the \Next~ of the instruction.

(Drop) changes the input buffer state from @have@ to @none@. A drop can only be executed after pull.

(Push) evaluates the push expression $e$ under the heap, and sends the value as the message.

(Jump) simply returns the new label and substitution.

(CaseT) and (CaseF) evaluate the case expression $e$ and jump to the true or false label depending on the value.

(Shake) unwraps a single process and evaluates the instruction.
The instruction updates are evaluated and updated in the process heap.
It updates the process with the new label, input state and heap.

(ProcessesInternal) chooses one process from the network and evaluates it.
When the process evaluates with an internal message ($\tau$), the entire network evaluates by replacing that process.

(ProcessesPush) chooses one process from the network and evaluates it, where the process evaluates with a push message.
The emitted push message is then injected into all other processes in the network, which means they must either ignore the channel or be ready to add it to their buffer.
If the process tries to emit a push message but it cannot be injected into all other processes, the push fails and another process will be tried.
The entire network then emits the same message.

The rules in figure~\ref{fig:Process:Eval:Feed} are the `feed' part of evaluation, where external input values are fed into a process network and output values are accumulated.
The judgment form for feeding is $\ProcsFeed{\ti{inputs}}{\ti{network}}{\ti{streams}}{\ti{network}'}$.
The input map $\ti{inputs}$ contains values for the network inputs: network outputs are not allowed, but ignored channels can have values.
The result $\ti{streams}$ contains the original inputs as well as accumulated output values.
Feeding evaluates the process network until all input values have been injected.

Note that the result stream and network are not canonical, as an infinite @push@ loop has an infinite number of evaluations.
The feed form does not ensure that the processes themselves have finished evaluating, only that all input values have been injected.

(FeedStart) is the axiom form where all input values have been injected and there are no input values left.
This is the start of evaluation.

(FeedInternal) first recursively feeds its input accumulator and process network, then allows the resulting network to take an internal step.
The internal step does not affect the accumulators.
The recursive closure is performed \emph{before} the internal step rather than after for proof engineering reasons: it allows an extra step to be added to the end of a feed evaluation relatively easily.

(FeedPush) works similarly to (FeedInternal) except that the process network emits a push message.
The pushed value is added to the end of the accumulator for that channel.

(FeedExternal) allows inputs to be injected into the process network.
For any channel $c$ which is not an output of one of the processes, we take the last value off its list.
The recursive feed is evaluated with the last value removed from the accumulators.
The last value is then injected into the network, and added back to the result accumulators.

