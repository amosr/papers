%!TEX root = ../Main.tex
\section{Processes}
\label{s:Processes}


\input{figures/ProcessDef.tex}

The grammar for processes is shown in figure~\ref{fig:Process:Def}.
Channels, labels and variables are specified by some external, globally unique set of names.
We assume that values and expressions are specified externally to the core calculus.
The actual details of the external computation are not important, except that there should be an evaluation form taking a heap and an expression and producing a value, as well as some way to destruct booleans.

A process defines a stream computation, taking any number of input streams and producing at least one output stream.
The process name is just for fun.
The input streams are paired with an input state which is used for coordinating multiple processes during evaluation; in process definitions before any evaluation has occurred this should be @none@.
The input states are explained in detail later in \S\ref{s:Process:Eval}.

The output streams are in some sense ``owned'' by the process that produces them.
While a stream may be consumed by any number of processes, each stream can only appear as the output for one process.
This ensures a sort of determinism in the scheduling of multiple processes; if different processes could push to the same stream, the order of values would depend on the scheduled order.
A process may, however, produce multiple output streams.

The heap is used for evaluation - it is used when evaluating the external value calculus.
Each process has its own private heap, meaning that the only communication between processes occurs by streams.

The label is the current block, and each block is the instruction to be executed in the current state.
Instructions can pull from a stream, drop an already pulled value, push a value, perform an if/case analysis on a boolean, or perform an internal jump.

Pulling from a stream is blocking, and as usual with Kahn processes~\cite{kahn1976coroutines}, there is no way to tell whether a stream currently has a value.
Pull takes as arguments the channel to read from, the variable to put the read value in, and the next label state to jump to after a successful pull.

After values have been pulled, they must be disposed of with @drop@.
This has no real evaluation semantics other than for coordination between processes.

All instructions take as an argument the next label state to jump to, which includes any variable updates that should be performed on the private heap at the same time.
Combining variable update with stream instructions simplifies the fusion process~\REF, as some parts of fusion need to perform both at once.


A process nest is a set of multiple processes that can be evaluated concurrently.
The intersection of all process outputs should be empty - there should be no overlap.
Any inputs that are not mentioned as outputs of processes are assumed to be external inputs - their values will be provided by the environment.
Processes form the essence of stream computation, and a single process can be given a straightforward sequential semantics by mapping to an imperative language.
By fusing multiple processes into a single one, we are effectively giving a sequential interpretation for concurrent processes.


\subsection{Map/map}
\label{s:Process:MapMap}

One of the simplest combinators is @map@.
This might need to go elsewhere.
As well as needing a better example than map/map.
Let's start with the process definition for @map@.
The inputs here is actually a map with @as=none@, but we leave the value off when it is @none@.
The goto labels for the instructions are also shortened as @map0@ instead of writing the empty heap update afterwards.
Mention that the initial heap has the names but no values, but they could be initialised to whatever.
It doesn't matter since they'll be written before anything is read.

\begin{code}
map f = process
    name: (map f)
     ins: as
    outs: bs
    heap: {a = 0}
   label: map0
  blocks: map0 = pull as    a  map1
          map1 = push bs (f a) map2
          map2 = drop as       map0
\end{code}

As well as a ``combinator nest'', a function comprised exclusively of process combinators.
The input streams are supplied as arguments, and output streams as return values.
\begin{code}
mapMap f g xs
 = let ys = map f xs
       zs = map g ys
   in  zs
\end{code}

It is not hard to assume that, given the process definitions and a combinator nest, we can produce a process nest.
This is simple enough for a paragraph prose description.
It's just a bit of inlining and renaming everything to be unique.

\begin{code}
process
    name: (map f)
     ins: xs
    outs: ys
    heap: {x}
   label: p0
  blocks: p0 = pull xs    x  p1
          p1 = push ys (f x) p2
          p2 = drop xs       p0
process
    name: (map g)
     ins: ys
    outs: zs
    heap: {y}
   label: q0
  blocks: q0 = pull ys    y  q1
          q1 = push zs (g y) q2
          q2 = drop ys       q0
\end{code}

Now we can perform some kind of fusion on this nest, resulting in one process that computes, as output, both @ys@ and @zs@.
Later, when producing imperative code for this, the output pushes to @ys@ can be ignored and changed to jumps, as the original combinator nest did not return them.

\begin{code}
process
    name: (map f / map g)
     ins: xs
    outs: ys zs
    heap: {x, y, _ys}
   label: p0q0
  blocks: p0q0            = pull xs    x  p1q0
          p1q0            = push ys (f x) p2q0-pending-ys { _ys = f x }
          p2q0-pending-ys = drop xs       p0q0-pending-ys
          p0q0-pending-ys = jump          p0q1-have-ys    { y = _ys }
          p0q1-have-ys    = push zs (g y) p0q2-have-ys
          p0q2-have-ys    = jump          p0q0
\end{code}

\subsection{Evaluation}
\label{s:Process:Eval}

\input{figures/ProcessEval.tex}

We use the ``inject and shake'' method of evaluation. (This isn't a real thing.)

Rules in figure~\ref{fig:Process:Eval:Inject} are about injecting values into a process; these are the values used when the process performs a @pull@.
The injected values may be pushed values from other processes for internal streams, or may come from an external source for the overall nest's input streams.
For the map/map example, the values for @xs@ would be injected externally, but the values for @ys@ will be injected into the second process from the first process.
Injection is just about orchestrating values between processes, and no actual computation happens here; it just makes values available to be pulled.

Injection can only happen when a process is ready to receive more input.
A process has a single element buffer for each input, stored in its input state.
This can be either @none@ meaning an empty buffer, @pending@ meaning a single value has been added to the buffer but has not been read yet, or @have@ meaning the value was added and in the process of being used.

(InjectValue) allows a value to be injected only when the input state is @none@, meaning the buffer is empty.
An attempt to inject a value while the buffer is @pending@ or @have@ would require an unbounded (or at least multiple element) buffer.
Injecting the value puts the value as @pending@ in the buffer.

(InjectIgnore) allows processes that do not use a particular input stream to ignore an injected input.

(ProcessesInject) perform injection over a process nest.
Every process in the nest must have the value injected into it.
This means if multiple processes read from that stream, all input buffers for that stream must be empty.

The rules in figure~\ref{fig:Process:Eval:Shake} are the `shake' part of evaluation, where actual computation occurs. 
As usual, $\alpha$ denotes the message type, with $\tau$ being an internal message. The \Push~ message is a single value being output on a channel.


The judgment form for shaking a single instruction $\ProcBlockShake{b}{i}{\Sigma}{\alpha}{l'}{i'}{\phi'}$
executes an instruction $b$ with the input states $i$ and the heap $\Sigma$.
The output message $\alpha$ can be an internal state change or an emitted value.
The result also has the new label, the new input state buffers, and the substitution to apply to the heap.

The two judgment forms for shaking processes are $\ProcShake{p}{\alpha}{p'}$ and $\ProcsShake{\sgl{p}}{\alpha}{\sgl{p}}$.
The process shaking just shakes a single instruction and updates the process.
Shaking a process nest chooses a single process to shake, then if the result is an emitted value, that value is injected into all the other processes in the nest.

(Pull) takes an already injected value from the input buffer, which changes its state from @pending@ to @have@.
The result substitution sets the variable to the pulled value, as well as any substitutions in the \Goto~ of the instruction.

(Drop) changes the input buffer state from @have@ to @none@. A drop can only be executed after pull.

(Push) evaluates the push expression $e$ under the heap, and sends the value as the message.

(Jump) simply returns the new label and substitution.

(CaseT) and (CaseF) evaluate the case expression $e$ and jump to the true or false label depending on the value.

(Shake) unwraps a single process and evaluates the instruction.
It updates the process with the new label, input state and heap.
The shorthand $\Sigma[\phi]$ is used to denote the heap with the substitution simultaneously applied.

(ProcessesInternal) chooses one process from the nest and evaluates it.
When the process evaluates with an internal message ($\tau$), the entire nest evaluates by replacing that process.

(ProcessesPush) chooses one process from the nest and evaluates it, where the process evaluates with a push message.
The emitted push message is then injected into all other processes in the nest, which means they must either ignore the channel or be ready to add it to their buffer.
The entire nest then emits the same message.

