%!TEX root = ../Main.tex
\section{Introduction}
\label{s:Introduction}

Fusion for array programs is important for removing intermediate arrays, reducing memory traffic as well as allocations.
However, when dealing with data too large to fit in memory such as tables on disk, removing intermediate arrays becomes essential rather than just desirable.
Attempting to create an intermediate array of such amounts of data would lead to thrashing and swapping to disk, or perhaps even running out of swap.
For these situations, some sort of assurance of total fusion is required: either the program can be fused with no intermediate arrays or unbounded buffers, or it will not compile at all.

Furthermore, existing systems for combinator fusion only support a subset of combinators, and only in limited cases.
Pull fusion supports joins where one combinator pulls from multiple inputs, but not splits where one output is used my multiple combinators.
Pull can thus express @merge@, but not @partition@.
Push fusion supports splits (@partition@), but not joins (@merge@).
Polarised fusion~\cite{lippmeier2016polarized} addresses these shortcomings by separating the computation into pull producers and push consumers, with explicit drain loops to convert between the two sections. However this requires manual plumbing.

We make the following contributions:
\begin{itemize}
\item a process calculus for streaming programs (\S\ref{s:Process});
\item some common combinators implemented as processes (\S\ref{s:Combinators});
\item and even more exotic combinators such as segmented operations (\S\ref{s:Combinators});
\item an algorithm for fusing pairs of processes (\S\ref{s:Fusion});
\item and a Coq proof of soundness (\S\ref{s:Proofs});
\end{itemize}

\section{Streams vs Push/Pull}

Types
\begin{code}
Stream  : Data -> Static
Source  : Data -> Static
Sink    : Data -> Static
Process :         Static
\end{code}

Streams have the advantage of being able to be passed between producer and consumer.
Stream combinators are easily composed as normal functions.

The polar representation of Source/Sink has the advantage of having obvious bufferless execution semantics.
Composition is harder.



\section{Processes}
\label{s:Process}
We will start by looking at a combinator that increments each value.
Given an input stream @ins@, @increment ins@ returns a new stream with the incremented values.
The function @stream_1_1@ takes a process program with one pull input and one push output, and converts it to a stream program.

The process blocks reading the value from @ins@.
After reading the value @i@, it pushes @i + 1@ to the @out@ stream.
The pulled value must be dropped or released before another value can be performed.
Operationally this is a no-op, but is used for coordinating between producer and consumer.
Finally, the process loops back to the start.

\begin{code}
increment : Stream Int -> Stream Int
increment = stream_1_1 \ins out.
  letrec
    p1   = pull ins       p2
    p2 i = push out (i+1) p3
    p3   = drop ins       p1
  in p1
\end{code}

What is interesting here?
Streams are named and infinite.
Output streams are owned by a particular process and can only be written to by it.
Pushes and pulls are blocking.
Pulls can be performed anywhere.
Drops are required for coordination.
This can be thought of as yielding control back to the producer after the value has been used.

\begin{code}
stream_1_1 : (Source a -> Sink b
              -> Process)
          -> Stream a -> Stream b
stream_2_1 : (Source a -> Source b -> Sink c
              -> Process)
          -> Stream a -> Stream b -> Stream c
stream_1_2 : (Source a -> Sink b -> Sink c
              -> Process)
          -> Stream a -> (Stream b, Stream c)

pull : Source a -> (a -> Process) -> Process
push : Sink   a ->  a -> Process  -> Process
drop : Source a ->       Process  -> Process
case : Bool -> Process -> Process -> Process
\end{code}

Put in some evaluation rules.

\section{Combinators}
\label{s:Combinators}

Some simple combinator definitions.
Map 

\begin{code}
map f = stream_1_1 \is os.
  letrec
    p1   = pull is p2
    p2 i = push os (f i) p3
    p3   = drop is p1
  in p1
\end{code}

\begin{code}
filter f = stream_1_1 \is os.
  letrec
    p1   = pull is p2
    p2 i = case (f x) (p3 i) p4
    p3 i = push os i p4
    p4   = drop is p1
  in p1
\end{code}

\begin{code}
partition f = stream_1_2 \is ots ofs.
  letrec
    p1   = pull is p2
    p2 i = case (f x)
            (push ts i p3)
            (push fs i p3)
    p3   = drop is p1
  in p1
\end{code}

\begin{code}
zip = stream_2_1 \xs ys xys.
  letrec
    p1     = pull xs        p2
    p2 x   = pull ys        p3
    p3 x y = push xys (x,y) p4
    p4     = drop xs        p5
    p5     = drop ys        p1
  in p1
\end{code}

\begin{code}
merge = stream_2_1 \xs ys xys.
  letrec
    go x y = case (x < y)
             (pX x y)
             (pY x y)
    pX x y = push xys x
            (drop xs
            (pull xs (\x'. go x' y)))
    pY x y = push xys y
            (drop ys
            (pull ys (\y'. go x y')))
  in pull xs (\x. pull ys (\y. go x y))
\end{code}


\section{Fusion}
\label{s:Fusion}

\begin{code}
channels : Process -> ({Source}, {Sink})
channels (pull i   p) = ({i}, {})  U channels p
channels (drop i   p) = ({i}, {})  U channels p
channels (push o _ p) = ({}, {o})  U channels p
channels (case _ p q) = channels p U channels q
\end{code}



\section{Proofs}
\label{s:Proofs}
Proof of soundness is formalised in Coq.


\section{The problem with synchronised product}
Related work on Network Fusion~\cite{fradet2004network} allows fusion of Kahn Process Networks using synchronised product to fuse pairs of processes together.
Synchronised product is: both machines can take independent steps so long as it is not in the alphabet of the other, but have to agree on any shared actions.
So if both machines pull from @xs@, the @pull xs@ message can only be executed when both machines agree.

This sort of coordination is a bit too coarse and causes deadlocks.
This example cannot be fused by synchronised product: one zip is trying to pull from @as@ and the other from @bs@, but neither can proceed without the other.
Note that while this contrived example is unlikely to be written by hand, it is plausible that it would be part of a larger program after inlining has occurred.

\begin{code}
zips :: [a] -> [b] -> [a*b] * [b*a]
zips as bs =
  let abs = zip as bs
      bas = zip bs as
  in  abs, bas
\end{code}

After inlining the definition of zip, we have:
\begin{code}
zips :: [a] -> [b] -> [a*b] * [b*a]
zips as bs =
  let abs = process abs.
       let loop1 =
          a <- pull as
          b <- pull bs
          push abs (a,b)
          drop as
          drop bs
          jump loop1
       in jump loop1
      bas = process bas.
       let loop2 =
          b <- pull bs
          a <- pull as
          push abs (b,a)
          drop bs
          drop as
          jump loop2
       in jump loop2
  in  abs, bas
\end{code}

Here, in order to compute the synchronised product of these two, we need to know which are the common or shared actions.
Shared are: @pull as@, @pull bs@, @drop as@ and @drop bs@.
So both processes have to execute these together: if one wants to @pull as@, it can only act when the other one wants to @pull as@ as well.
Thus, the two machines are deadlocked, waiting for the other one to agree.

For this case, a simple solution suffices to fix this: adding extra processes for splits. So we would add a new combinator @dup@ which takes one input stream and creates two output streams. It reads a single element from the input and pushes it to both outputs.

\begin{code}
dup = stream_1_2 \is ols ors.
  letrec
    p1   = pull is p2
    p2 i = push ols i (p3 i)
    p3 i = push ors i p4
    p4   = drop is p1
  in p1
\end{code}
And the modified zip uses this like so:

\begin{code}
zips :: [a] -> [b] -> [a*b] * [b*a]
zips as bs =
  let as1, as2 = dup as
      bs1, bs2 = dup bs
      abs = zip as1 bs1
      bas = zip bs2 as2
  in  abs, bas
\end{code}

This has removed the deadlock, allowing a trace such as:
\begin{code}
as, as1, bs, bs1, bs2, as2
\end{code}

However it is not hard to modify the program so that the deadlock still exists.
By changing the each zip to pull from @as2@ and @bs2@ first, the streams are still used linearly, but deadlock occurs as @as1@ cannot be produced until after @bs2@ has been consumed, and vice versa.
\begin{code}
zips :: [a] -> [b] -> [a*b] * [b*a]
zips as bs =
  let as1, as2 = dup as
      bs1, bs2 = dup bs
      abs = zip as2 bs1
      bas = zip bs2 as1
  in  abs, bas
\end{code}

Using @dup@ we can concoct a simpler example with two processes and one input stream where synchronised product deadlocks.
\begin{code}
zipself :: [a] -> [a*a]
zipself as =
  let as1, as2 = dup as
      aas = zip as2 as1
  in  aas
\end{code}
Here @dup@ is attempting to push to @as1@, but cannot until @zip@ pulls, while @zip@ is attempting to pull from @as2@, which cannot proceed until the @dup@ pushes.

\section{Fully abstract case interpretation}

This cannot be fused because it requires an unbounded buffer.
\begin{code}
zipltgts :: [a] -> [a*a]
zipltgts as =
  let as1 = filter (<0) as
      as2 = filter (>0) as
      aas = zip as1 as2
  in  aas
\end{code}

You might think this can be fused.
It cannot because we treat @case@ conditions as fully abstract and make no attempt to filter out impossible combinations.
So while it cannot be true that the first filter reaches @>0 = true@ case and the second filter reaches @>0 = false@, we try both combinations and treat it as unfusable.
\begin{code}
zipgts :: [a] -> [a*a]
zipgts as =
  let as1 = filter (>0) as
      as2 = filter (>0) as
      aas = zip as1 as2
  in  aas
\end{code}

\section{Finite streams}
So far we have only treated infinite streams.
Finite streams could easily be encoded as infinite streams padded with a sentinel "end of file" element.
However, this plays poorly with the fully abstract case statements, as we would require a case for each element read to check whether it is the end of stream.
Adding these cases, we would end up with similar problems as @zipgts@ above.

One solution is to embed this special case into @pull@ itself, by giving it two actions to perform; one after successful read, one after end of stream.
It may be simpler and more useful to instead perform more sophisticated tracing of the @case@ conditionals though, as this would also solve the @zipgts@ example above.



