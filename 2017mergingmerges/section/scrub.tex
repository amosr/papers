%!TEX root = ../Main.tex
\section{Introduction}
\label{s:Introduction}

Fusion for array programs is important for removing intermediate arrays, reducing memory traffic as well as allocations.
However, when dealing with data too large to fit in memory such as tables on disk, removing intermediate arrays becomes essential rather than just desirable.
Attempting to create an intermediate array of such amounts of data would lead to thrashing and swapping to disk, or perhaps even running out of swap.
For these situations, some sort of assurance of total fusion is required: either the program can be fused with no intermediate arrays or unbounded buffers, or it will not compile at all.

Furthermore, existing systems for combinator fusion only support a subset of combinators, and only in limited cases.
Pull fusion supports joins where one combinator pulls from multiple inputs, but not splits where one output is used my multiple combinators.
Pull can thus express @merge@, but not @partition@.
Push fusion supports splits (@partition@), but not joins (@merge@).

We make the following contributions:
\begin{itemize}
\item a process calculus for streaming programs (\S\ref{s:Process});
\item some common combinators implemented as processes (\S\ref{s:Combinators});
\item and even more exotic combinators such as segmented operations (\S\ref{s:Combinators});
\item an algorithm for fusing pairs of processes (\S\ref{s:Fusion});
\item and a Coq proof of soundness (\S\ref{s:Proofs});
\end{itemize}


\section{Processes}
\label{s:Process}
Actually this is the process calculus version.

We will start by looking at a simple combinator that increments each value.
Given an input stream @ins@, @increment ins@ creates a new process with one output stream called @outs@.
The process blocks reading the value from @ins@.
After reading the value @i@, it pushes @i + 1@ to the @outs@ stream.
The pulled value must be dropped or released before another value can be performed.
Operationally this is a no-op, but is used for coordinating between producer and consumer.
Finally, the process loops back to the start.

\begin{code}
increment ins = process outs.
  let loop =
     i <- pull ins
     push outs (i + 1)
     drop ins
     jump loop
  in jump loop
\end{code}

What is interesting here?
Streams are named and infinite.
Output streams are owned by a particular process and can only be written to by it.
Pushes and pulls are blocking.
Pulls can be performed anywhere.
Drops are required for coordination.
This can be thought of as yielding control back to the producer after the value has been used.

\begin{code}
V := Scalar
C := Channel

Process :=
  | V <- pull C
  | push C Exp
  | drop C
  | skip
  | case Exp then Process else Process
  | jump F V*

Program :=
  process C*.
  let F V* = Process
  in  Process
\end{code}

Put in some evaluation rules.

\section{Combinators}
\label{s:Combinators}

Some simple combinator definitions.
Map 

\begin{code}
map f xs = process ys.
  let loop =
     x <- pull xs
     push ys (f x)
     drop xs
     jump loop
  in jump loop
\end{code}

\begin{code}
filter f xs = process ts.
  let loop =
     x <- pull xs
     case f x
       then push ys x
       else skip
     drop xs
     jump loop
  in jump loop
\end{code}

\begin{code}
partition f xs = process ts fs.
  let loop =
     x <- pull xs
     case f x
       then push ts x
       else push fs x
     drop xs
     jump loop
  in jump loop
\end{code}

\begin{code}
zip xs ys = process xys.
  let loop =
     x <- pull xs
     y <- pull ys
     push xys (x,y)
     drop xs
     drop ys
     jump loop
  in jump loop
\end{code}

\begin{code}
merge xs ys = process xys.
  let loop x y =
     case x < y
       then push xys x
            drop xs
            x' <- pull xs
            jump loop x' y
       else push xys y
            drop ys
            y' <- pull ys
            jump loop x y'
  in x <- pull xs
     y <- pull ys
     jump loop x y
\end{code}


\section{Fusion}
\label{s:Fusion}

\section{Proofs}
\label{s:Proofs}
Proof of soundness is formalised in Coq.


\section{The problem with synchronised product}
Synchronised product is: both machines can take independent steps so long as it is not in the alphabet of the other, but have to agree on any shared actions.
So if both machines pull from @xs@, the @pull xs@ message can only be executed when both machines agree.

This sort of coordination is a bit too coarse and causes deadlocks.
This example cannot be fused by synchronised product: one zip is trying to pull from @as@ and the other from @bs@, but neither can proceed without the other.
Note that while this contrived example is unlikely to be written by hand, it is plausible that it would be part of a larger program after inlining has occurred.

\begin{code}
zips :: [a] -> [b] -> [a*b] * [b*a]
zips as bs =
  let abs = zip as bs
      bas = zip bs as
  in  abs, bas
\end{code}

After inlining the definition of zip, we have:
\begin{code}
zips :: [a] -> [b] -> [a*b] * [b*a]
zips as bs =
  let abs = process abs.
       let loop1 =
          a <- pull as
          b <- pull bs
          push abs (a,b)
          drop as
          drop bs
          jump loop1
       in jump loop1
      bas = process bas.
       let loop2 =
          b <- pull bs
          a <- pull as
          push abs (b,a)
          drop bs
          drop as
          jump loop2
       in jump loop2
  in  abs, bas
\end{code}

Here, in order to compute the synchronised product of these two, we need to know which are the common or shared actions.
Shared are: @pull as@, @pull bs@, @drop as@ and @drop bs@.
So both processes have to execute these together: if one wants to @pull as@, it can only act when the other one wants to @pull as@ as well.
Thus, the two machines are deadlocked, waiting for the other one to agree.

For this case, a simple solution suffices to fix this: adding extra processes for splits. So we would add a new combinator @dup@ which takes one input stream and creates two output streams. It reads a single element from the input and pushes it to both outputs.

\begin{code}
dup ins = process l r.
  let loop =
     i <- pull ins
     push l i
     push r i
     drop ins
     jump loop
  in jump loop
\end{code}
And the modified zip uses this like so:

\begin{code}
zips :: [a] -> [b] -> [a*b] * [b*a]
zips as bs =
  let as1, as2 = dup as
      bs1, bs2 = dup bs
      abs = zip as1 bs1
      bas = zip bs2 as2
  in  abs, bas
\end{code}

This has removed the deadlock, allowing a trace such as:
\begin{code}
as, as1, bs, bs1, bs2, as2
\end{code}

However it is not hard to modify the program so that the deadlock still exists.
By changing the each zip to pull from @as2@ and @bs2@ first, the streams are still used linearly, but deadlock occurs as @as1@ cannot be produced until after @bs2@ has been consumed, and vice versa.
\begin{code}
zips :: [a] -> [b] -> [a*b] * [b*a]
zips as bs =
  let as1, as2 = dup as
      bs1, bs2 = dup bs
      abs = zip as2 bs1
      bas = zip bs2 as1
  in  abs, bas
\end{code}

Using @dup@ we can concoct a simpler example with two processes and one input stream where synchronised product deadlocks.
\begin{code}
zipself :: [a] -> [a*a]
zipself as =
  let as1, as2 = dup as
      aas = zip as2 as1
  in  aas
\end{code}
Here @dup@ is attempting to push to @as1@, but cannot until @zip@ pulls, while @zip@ is attempting to pull from @as2@, which cannot proceed until the @dup@ pushes.

\section{Fully abstract case interpretation}

This cannot be fused because it requires an unbounded buffer.
\begin{code}
zipltgts :: [a] -> [a*a]
zipltgts as =
  let as1 = filter (<0) as
      as2 = filter (>0) as
      aas = zip as1 as2
  in  aas
\end{code}

You might think this can be fused.
It cannot because we treat @case@ conditions as fully abstract and make no attempt to filter out impossible combinations.
So while it cannot be true that the first filter reaches @>0 = true@ case and the second filter reaches @>0 = false@, we try both combinations and treat it as unfusable.
\begin{code}
zipgts :: [a] -> [a*a]
zipgts as =
  let as1 = filter (>0) as
      as2 = filter (>0) as
      aas = zip as1 as2
  in  aas
\end{code}

\section{Finite streams}
So far we have only treated infinite streams.
Finite streams could easily be encoded as infinite streams padded with a sentinel "end of file" element.
However, this plays poorly with the fully abstract case statements, as we would require a case for each element read to check whether it is the end of stream.
Adding these cases, we would end up with similar problems as @zipgts@ above.

One solution is to embed this special case into @pull@ itself, by giving it two actions to perform; one after successful read, one after end of stream.
It may be simpler and more useful to instead perform more sophisticated tracing of the @case@ conditionals though, as this would also solve the @zipgts@ example above.



