%!TEX root = ../Main.tex
\section{Introduction}
\label{s:Introduction}

% Fusion for array programs is important for removing intermediate arrays, reducing memory traffic and reducing allocations.
% However, when dealing with data too large to fit in memory such as tables on disk, removing intermediate arrays becomes essential rather than just desirable.
% Attempting to create an intermediate array of such amounts of data would lead to thrashing and swapping to disk, or perhaps even running out of swap.
% For these situations, some sort of assurance of total fusion is required: either the program can be fused with no intermediate arrays or unbounded buffers, or it will not compile at all.

Suppose we have two large files containing identifiers, and wish to perform some analysis on them.
Both files are sorted, but may contain duplicates.
We wish to retrieve the unique set from the first file, as well as the union of both files.
Can we perform both of these tasks at once, without reading the input files multiple times?

\begin{code}
uniquesUnion (file1 file2 : Stream Id) : (Stream Id, Stream Id)
 = let uniques = group file1
       union   = group (merge file1 file2)
   in (uniques, union)
\end{code}

In this example the @group@ combinator removes consecutive duplicates leaving only the first value, while @merge@ concatenates two sorted inputs such that the output remains sorted.
There are a few interesting things about this example.
First, the access pattern of @merge@ is \emph{value-dependent}: the order in which @merge@ reads values from @file1@ or @file2@ depends on the values in the files.
If all the values in @file1@ are smaller than the values in @file2@, then @merge@ will pull values from @file1@ before pulling from @file2@, and vice versa.
Second, note that @file1@ is used twice.
If we wish to ensure that each value is only read from the file once, we must coordinate between the two use sites: when @uniques@ requires a new value it must ensure that @union@ is ready to receive a new value, and vice versa.
It is important to note that we cannot just execute @uniques@ while storing the read values in a buffer, as this may require more memory than is available.


We make the following contributions:
\begin{itemize}
\item a process calculus for encoding infinite streaming programs (\S\ref{s:Processes});
\item an algorithm for fusing processes, the first which supports splits, joins and arbitrary combinators (\S\ref{s:Fusion});
\item a formalisation and proof of soundness in Coq (\S\ref{s:Proofs});
\item an informal description of the required extensions to support finite streams (\S\ref{s:Finite});
\item and show that our calculus is general enough for many combinators, including segmented operations (\S\ref{s:Combinators}).
\end{itemize}


