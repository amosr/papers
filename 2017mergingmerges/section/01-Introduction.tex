%!TEX root = ../Main.tex
\section{Introduction}
\label{s:Introduction}

Suppose we have two input streams of numeric identifiers, and wish to perform some analysis on these identifiers. The identifiers from both streams arrive sorted, but may include duplicates. We wish to produce an output stream of unique identifiers from the first input stream, as well as produce the unique union of identifiers from both streams. Can we perform both of these tasks at once, without needing to read through the stream data multiple times, and without needing unbounded buffering? Here is how we might write the source code, where @S@ is for @S@-tream.
\begin{code}
  uniquesUnion : S Nat -> S Nat -> (S Nat, S Nat)
  uniquesUnion sIn1 sIn2
   = let  sUnique = group sIn1
          sMerged = merge sIn1 sIn2
          sUnion  = group sMerged
     in   (sUnique, sUnion)
\end{code}

In this implementation the @group@ operator filters out consecutive duplicates, while @merge@ combines two sorted streams so that the output remains sorted. This example has a few interesting properties. Firstly, the data-access pattern of @merge@ is \emph{value-dependent}, meaning that the order in which this operator pulls values from @sIn1@ and @sIn2@ depends on the values themselves. If all the values from @sIn1@ are smaller than the values in @sIn2@, then @merge@ will pull all values from @sIn1@ before pulling the rest from @sIn2@, and vice versa. Secondly, although @sIn1@ occurs twice in the program, at runtime we only want to handle the elements of each stream once. To achieve this, the compiled program must coordinate between the two uses of @sIn1@, so that values are only read when both the @group@ and @merge@ operators are ready to receive a new value. Finally, as the stream length is assumed to be unbounded, we cannot buffer an arbitrary number of elements read from either stream, or risk running out of local storage space.

For an implementation which does \emph{not} use stream fusion, we might implement each of the operators as a separate concurrent process, and send each identifier value using an intra-process communication mechanism. Developing such an implementation could be easy or hard, depending on what language features are available for concurrency. However, worrying about the \emph{performance tuning} of such a system, such as whether we need back-pressure, or how to chunk the stream data to reduce the amount of communication overhead, is invariably a headache. 

We might instead define some sort of uniform interface for data sources, with a single `pull' function that provides the next value in each stream. Each operator could be given this interface, so that the next value from each result stream is computed on demand. This is approach is commonly taken with implementations of physical operators in data base systems. However, this `pull only' model does not support operators with multiple outputs, such as our derived @uniquesUnion@ operator, at least not without unbounded buffering. Suppose a consumer pulls many elements from the result @sUnique@ stream. The implementation needs to pull the corresponding source elements from @sIn1@ \emph{as well} as buffering an arbitrary number of matching elements from @sIn2@. It needs to buffer an aribrary number of elements from @sIn2@ because there is no guarantee of when a consumer will also pull from the @sUnion@ result stream. Once that happens the elements from @sIn2@ no longer need to be retained, but not before.

Instead, for a single threaded program, we want to perform \emph{stream fusion}, which takes the dataflow network and produces a simple sequential loop that gets the job done without requiring extra process-control abstractions and without requiring unbounded buffering. Sadly, existing stream fusion transformations cannot handle our example. As observed by \citet{kay2009you}, both pull-based and push-based fusion have fundamental limitations. Pull-based systems such as short cut stream fusion~\cite{coutts2007stream} cannot handle cases where a particular stream or intermediate result is used by multiple consumers. We refer to this situation as a \mbox{\emph{split} --- in the} dataflow network the flow from input stream @sIn1@ is split into both the @group@ and @merge@ consumers. 

% Leave this to related work. We've already mentioned a canonical pull-based system.
% Recent work on stream fusion by \citet{kiselyov2016stream} uses staged computation to ensure all combinators are inlined, but for splits this causes excessive inlining which duplicates work, due to values of the source arrays being read multiple times.

Push-based systems such as foldr/build fusion~\cite{gill1993short} also cannot fuse our example because they do not support operators with multiple inputs. We refer to such a situation as a \emph{join} --- in our example the @merge@ operator expresses a join in the data-flow graph. Some systems support both pull and push: data flow inspired array fusion~\cite{lippmeier2013data} allows both splits and joins but only for a limited, predefined set of operators. More recent work on polarized data flow fusion~\cite{lippmeier2016polarized} \emph{is} able to fuse our example, but requires the program to be rewritten to use explicitly polarized stream types. 

% The mechanism that combines the implementations of both operators, to yield efficient imperative code also depends on the general purpose compiler optimisations implemented by GHC, and it can be difficult to tell if these have ``worked'' without inspecting the intermediate representations of the compiler.

Synchronous dataflow languages such as Lucy-n~\cite{mandel2010lucy} reject value-dependent operators such as @merge@, while general dataflow languages fall back on less performant dynamic scheduling for these cases \cite{bouakaz2013real}. The polyhedral array fusion model~\cite{feautrier2011polyhedron} is used for loop transformations in imperative programs, but operates at a much lower level. The polyhedral model is based around affine loops, which makes it difficult to support filter-like operators such as @group@ and @merge@.

In our new system we still view the program as a concurrent process network. Each operator is a separate process, and the stream data flows through communication channels between the processes. Each operator is expressed as a restricted, sequential imperative program with commands that include both @pull@ for reading from an input stream and @push@ for writing to an output stream. The fusion transform takes the concurrent process network and \emph{sequentializes} it into a single process by choosing a particular evaluation order that requires no unbounded intermediate buffers. When the fusion transformation succeeds we know it has worked. There is no need to inspect intermediate representations of the compiler to debug poor performance, which is a common problem in systems based on general purpose program transformations \cite{lippmeier2012:guiding}.

In summary, we make the following contributions:
\begin{itemize}
\item a process calculus for encoding infinite streaming programs (\S\ref{s:Processes});
\item an algorithm for fusing these processes, the first to support arbitrary splits and joins (\S\ref{s:Fusion});
\item numerical results that demonstrate that the algorithm is well behaved when the number of fused processes is large. The size of the fused result program is not excessive. \TODO{Ref}
\item a formalization and proof of soundness for the core fusion algorithm in Coq (\S\ref{s:Proofs});
\end{itemize}

Our fusion transformation for infinite stream programs could also serve as the basis for an \emph{array} fusion system, using a natural extension to finite streams. We discuss this extension in \S\ref{s:Finite}.

% TODO: We can't make the appendix a contribution because the reviewers are not required to read appendices.
% \item and show our processes are general enough for many combinators, including segmented operations (\S\ref{s:Combinators}).

% \ben{Add a few more sentences on related work. Explain how this work extends the old flow fusion paper. It is not short-cut fusion like Oleg's recent work. We are not in the same space as Fortran style array fusion transformations like polyhedral}

% BL: describe this later.
% Furthermore, the data-flow fusion system of~\cite{lippmeier2013data} only deals with a fixed set of baked-in combinators. 

% BL: Shift the detailed description into a later section.
% The example above has three combinators, so the process network has three processes.
% The two @writeFile@s outputs are treated as sinks that values can be pushed to at any time, and are not converted to processes.
% During code generation, any output values from the @uniques@ and @union@ streams are sent to the corresponding @writeFile@ sink, but we do not address code generation in this paper.

% The process for @uniques@ is defined by the @group@ combinator, and can be thought of as an imperative loop: first it reads from its input stream @file1@ and stores that in a local variable.
% It also keeps track of the last pulled value, and compares that against the newly read value.
% If they are different, it pushes the new value to its output stream @uniques@.
% In either case, it updates the last pulled value and loops back to the start to pull from @file1@ again.

% The process for @merged@ is defined by the @merge@ combinator, which starts by reading from both @file1@ and @file2@ and storing these in local variables.
% It then compares its two values to see which is the smaller.
% If the value from @file1@ is smaller, it pushes that value and pulls a new value from @file1@, otherwise it pushes the value from @file2@ and pulls from @file2@.
% This is performed in a loop.

% We fuse these two processes by interleaving the two such that the shared input @file1@ is only pulled from when both processes agree.
% The new process pulls from @file1@, which is copied to the variables for both processes.
% The @uniques@ process now has all it needs to execute, so it checks the value against the last pulled value, pushes if necessary, and goes back to try to pull from @file1@ again.
% At this stage the @merged@ process still has a value from @file1@ that it has pulled but not used, so @uniques@ cannot pull from @file1@ again.
% We now let @merged@ run, pulling from @file2@ and checking which is smaller.
% If the value from @file1@ is smaller, the value is emitted and @merged@ wishes to pull a new value from @file1@.
% Both processes now agree on pulling from @file1@ again, so the new value is pulled and @uniques@ can run again.
% Otherwise if the value from @file1@ is not smaller, the value from @file2@ is emitted and @merged@ pulls from @file2@ with no coordination required.

% If we wish to ensure that each value is only read from the file once, we must coordinate between the two use sites: when @uniques@ requires a new value it must ensure that @union@ is ready to receive a new value, and vice versa. Note that we cannot just execute @uniques@ while storing the read values in a buffer, as this may require more memory than is available.
% In order to fuse this example, we require both pull \emph{and} push streams.
% The input streams must be pull streams since the order values are required is determined by the @merge@ combinator.
% For the same reason, the outputs sent to each @writeFile@ must be push streams.

% Fusion for array programs is important for removing intermediate arrays, reducing memory traffic and reducing allocations.
% However, when dealing with data too large to fit in memory such as tables on disk, removing intermediate arrays becomes essential rather than just desirable.
% Attempting to create an intermediate array of such amounts of data would lead to thrashing and swapping to disk, or perhaps even running out of swap.
% For these situations, some sort of assurance of total fusion is required: either the program can be fused with no intermediate arrays or unbounded buffers, or it will not compile at all.


% Fusion eliminates intermediate array buffers and converts pipelines of array combinators into low-level iteration based loop code. Different fusion systems can handle 

% When comparing fusion systems, three important criteria to consider are: whether the system supports splits, where a stream is used multiple times; whether it supports joins, where a combinator has multiple inputs; and whether arbitrary combinators such as @merge@ and segmented appends can be encoded. Existing fusion systems support one or two of these, but not three. We present a fusion system based on process calculus that supports all three: splits, joins and arbitrary combinators.

% Our system has been formalised in Coq where we have proved soundness of the fusion algorithm. It is expressive enough to encode a wide range of combinators including operations on segmented arrays.

% \amos{``Arbitrary combinators'' is not quite true. How can we distinguish combinators we support from 2013 data flow fusion paper? Perhaps by mentioning value-dependent input / access patterns.}

% Leave this to the description of the algorithm, not the abstract.
% We encode each combinator as a separate process with any number of input and output channels. Each process is sequential but multiple processes can be executed concurrently. We give a concurrent execution semantics for multiple processes, but these are used only as a specification for how the fused program must behave. The fused program itself is sequential and can easily be converted to simple imperative code.

% Our fusion algorithm takes two concurrently executable processes and creates a sequential interleaving of the two such that they execute with no unbounded buffers.
% If fusion would require unbounded buffers (or the fusion algorithm wrongly infers that it would) then fusion fails.
% If fusion fails, the user can be presented with an error message telling them which combinators could not be fused.
% For scenarios where fusion is required, this is a great advantage over fragile shortcut fusion systems.

% BL: leave the apologies to the conclusion.
% The version presented here deals with infinite streams, and we informally describe the extensions required to support finite streams.

% BL: leave this to the main intro.
% optimising high-level array and streaming computations, as it reduces memory traffic and intermediate arrays. The benefits of removing intermediate arrays are even more important as data sizes approach the size of memory.
